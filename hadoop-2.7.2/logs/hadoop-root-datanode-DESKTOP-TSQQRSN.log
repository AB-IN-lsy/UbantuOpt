2021-05-25 14:22:24,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-25 14:22:24,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-25 14:22:27,286 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-25 14:22:27,455 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-25 14:22:27,455 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-25 14:22:27,504 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-25 14:22:27,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-25 14:22:27,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-25 14:22:27,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-25 14:22:27,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-25 14:22:27,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-25 14:22:28,219 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-25 14:22:28,240 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-25 14:22:28,254 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-25 14:22:28,268 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-25 14:22:28,271 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-25 14:22:28,272 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-25 14:22:28,272 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-25 14:22:28,297 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 64338
2021-05-25 14:22:28,297 INFO org.mortbay.log: jetty-6.1.26
2021-05-25 14:22:28,818 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:64338
2021-05-25 14:22:30,526 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-25 14:22:31,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-25 14:22:31,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-25 14:22:31,797 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-25 14:22:31,853 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-25 14:22:32,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-25 14:22:32,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-25 14:22:33,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-25 14:22:33,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2021-05-25 14:22:33,451 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-25 14:22:33,451 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-25 14:22:37,423 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 338@DESKTOP-TSQQRSN.localdomain
2021-05-25 14:22:37,430 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-root/dfs/data is not formatted for BP-1959751182-127.0.1.1-1621923621884
2021-05-25 14:22:37,430 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-05-25 14:22:37,521 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1959751182-127.0.1.1-1621923621884
2021-05-25 14:22:37,522 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-root/dfs/data/current/BP-1959751182-127.0.1.1-1621923621884
2021-05-25 14:22:37,525 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-root/dfs/data/current/BP-1959751182-127.0.1.1-1621923621884 is not formatted for BP-1959751182-127.0.1.1-1621923621884
2021-05-25 14:22:37,525 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-05-25 14:22:37,525 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1959751182-127.0.1.1-1621923621884 directory /tmp/hadoop-root/dfs/data/current/BP-1959751182-127.0.1.1-1621923621884/current
2021-05-25 14:22:37,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=283474137;bpid=BP-1959751182-127.0.1.1-1621923621884;lv=-56;nsInfo=lv=-63;cid=CID-3d2fddef-6667-4fb7-81ab-9d11c7b2c2e6;nsid=283474137;c=0;bpid=BP-1959751182-127.0.1.1-1621923621884;dnuuid=null
2021-05-25 14:22:37,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 41a0dad7-3f26-4b72-8e6f-6b063a25eb76
2021-05-25 14:22:38,958 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-ff0c6f61-06a2-4db2-a868-33b42a7b5a6a
2021-05-25 14:22:38,958 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-root/dfs/data/current, StorageType: DISK
2021-05-25 14:22:38,982 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-25 14:22:38,983 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1959751182-127.0.1.1-1621923621884
2021-05-25 14:22:38,986 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1959751182-127.0.1.1-1621923621884 on volume /tmp/hadoop-root/dfs/data/current...
2021-05-25 14:22:39,321 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1959751182-127.0.1.1-1621923621884 on /tmp/hadoop-root/dfs/data/current: 333ms
2021-05-25 14:22:39,321 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1959751182-127.0.1.1-1621923621884: 338ms
2021-05-25 14:22:39,323 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1959751182-127.0.1.1-1621923621884 on volume /tmp/hadoop-root/dfs/data/current...
2021-05-25 14:22:39,325 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1959751182-127.0.1.1-1621923621884 on volume /tmp/hadoop-root/dfs/data/current: 2ms
2021-05-25 14:22:39,326 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 4ms
2021-05-25 14:22:40,754 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1959751182-127.0.1.1-1621923621884 on volume /tmp/hadoop-root/dfs/data
2021-05-25 14:22:40,758 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-ff0c6f61-06a2-4db2-a868-33b42a7b5a6a): finished scanning block pool BP-1959751182-127.0.1.1-1621923621884
2021-05-25 14:22:40,760 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1621942158760 with interval 21600000
2021-05-25 14:22:40,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1959751182-127.0.1.1-1621923621884 (Datanode Uuid null) service to localhost/127.0.0.1:9000 beginning handshake with NN
2021-05-25 14:22:41,121 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-ff0c6f61-06a2-4db2-a868-33b42a7b5a6a): no suitable block pools found to scan.  Waiting 1814399633 ms.
2021-05-25 14:22:41,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1959751182-127.0.1.1-1621923621884 (Datanode Uuid null) service to localhost/127.0.0.1:9000 successfully registered with NN
2021-05-25 14:22:41,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-25 14:22:42,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1959751182-127.0.1.1-1621923621884 (Datanode Uuid 41a0dad7-3f26-4b72-8e6f-6b063a25eb76) service to localhost/127.0.0.1:9000 trying to claim ACTIVE state with txid=1
2021-05-25 14:22:42,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1959751182-127.0.1.1-1621923621884 (Datanode Uuid 41a0dad7-3f26-4b72-8e6f-6b063a25eb76) service to localhost/127.0.0.1:9000
2021-05-25 14:22:42,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xa9508a3730,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 15 msec to generate and 296 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-25 14:22:42,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1959751182-127.0.1.1-1621923621884
2021-05-25 14:41:30,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-25 14:41:30,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-25 14:41:31,171 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-25 14:41:31,292 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-25 14:41:31,292 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-25 14:41:31,842 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-25 14:41:31,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-25 14:41:31,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-25 14:41:32,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-25 14:41:32,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-25 14:41:32,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-25 14:41:32,442 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-25 14:41:32,461 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-25 14:41:32,473 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-25 14:41:32,484 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-25 14:41:32,488 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-25 14:41:32,488 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-25 14:41:32,488 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-25 14:41:32,522 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50208
2021-05-25 14:41:32,522 INFO org.mortbay.log: jetty-6.1.26
2021-05-25 14:41:32,863 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:50208
2021-05-25 14:41:35,085 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-25 14:41:35,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-25 14:41:35,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-25 14:41:36,000 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-25 14:41:36,039 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-25 14:41:36,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-25 14:41:36,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-25 14:41:36,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-25 14:41:37,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2021-05-25 14:41:37,170 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-25 14:41:37,171 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-25 14:41:38,127 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 539@DESKTOP-TSQQRSN.localdomain
2021-05-25 14:41:38,197 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1959751182-127.0.1.1-1621923621884
2021-05-25 14:41:38,197 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-root/dfs/data/current/BP-1959751182-127.0.1.1-1621923621884
2021-05-25 14:41:38,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=283474137;bpid=BP-1959751182-127.0.1.1-1621923621884;lv=-56;nsInfo=lv=-63;cid=CID-3d2fddef-6667-4fb7-81ab-9d11c7b2c2e6;nsid=283474137;c=0;bpid=BP-1959751182-127.0.1.1-1621923621884;dnuuid=41a0dad7-3f26-4b72-8e6f-6b063a25eb76
2021-05-25 14:41:38,395 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-ff0c6f61-06a2-4db2-a868-33b42a7b5a6a
2021-05-25 14:41:38,395 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-root/dfs/data/current, StorageType: DISK
2021-05-25 14:41:38,476 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-25 14:41:38,477 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1959751182-127.0.1.1-1621923621884
2021-05-25 14:41:38,479 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1959751182-127.0.1.1-1621923621884 on volume /tmp/hadoop-root/dfs/data/current...
2021-05-25 14:41:39,410 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1959751182-127.0.1.1-1621923621884 on /tmp/hadoop-root/dfs/data/current: 931ms
2021-05-25 14:41:39,410 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1959751182-127.0.1.1-1621923621884: 933ms
2021-05-25 14:41:39,410 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1959751182-127.0.1.1-1621923621884 on volume /tmp/hadoop-root/dfs/data/current...
2021-05-25 14:41:39,411 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1959751182-127.0.1.1-1621923621884 on volume /tmp/hadoop-root/dfs/data/current: 1ms
2021-05-25 14:41:39,411 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-05-25 14:41:41,262 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-ff0c6f61-06a2-4db2-a868-33b42a7b5a6a): no suitable block pools found to scan.  Waiting 1813259493 ms.
2021-05-25 14:41:41,266 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1621935239266 with interval 21600000
2021-05-25 14:41:41,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1959751182-127.0.1.1-1621923621884 (Datanode Uuid null) service to localhost/127.0.0.1:9000 beginning handshake with NN
2021-05-25 14:41:42,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1959751182-127.0.1.1-1621923621884 (Datanode Uuid null) service to localhost/127.0.0.1:9000 successfully registered with NN
2021-05-25 14:41:42,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-25 14:41:42,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1959751182-127.0.1.1-1621923621884 (Datanode Uuid 41a0dad7-3f26-4b72-8e6f-6b063a25eb76) service to localhost/127.0.0.1:9000 trying to claim ACTIVE state with txid=11
2021-05-25 14:41:42,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1959751182-127.0.1.1-1621923621884 (Datanode Uuid 41a0dad7-3f26-4b72-8e6f-6b063a25eb76) service to localhost/127.0.0.1:9000
2021-05-25 14:41:42,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xa2e3f7039c,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 366 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-25 14:41:42,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1959751182-127.0.1.1-1621923621884
2021-05-25 15:17:55,502 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 48792ms
No GCs detected
2021-05-25 17:33:59,283 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1959751182-127.0.1.1-1621923621884 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2021-05-25 19:30:16,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x106217943d40,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 386 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-25 19:30:16,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1959751182-127.0.1.1-1621923621884
2021-05-25 21:24:14,473 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN.localdomain/127.0.1.1"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-25 21:24:17,485 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-25 21:24:17,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-25 21:26:35,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-25 21:26:35,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-25 21:26:36,110 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-25 21:26:36,175 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-25 21:26:36,176 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-25 21:26:36,182 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-25 21:26:36,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-25 21:26:36,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-25 21:26:36,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-25 21:26:36,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-25 21:26:36,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-25 21:26:36,362 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-25 21:26:36,371 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-25 21:26:36,376 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-25 21:26:36,381 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-25 21:26:36,383 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-25 21:26:36,383 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-25 21:26:36,383 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-25 21:26:36,394 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 52962
2021-05-25 21:26:36,394 INFO org.mortbay.log: jetty-6.1.26
2021-05-25 21:26:36,517 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:52962
2021-05-25 21:26:36,630 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-25 21:26:36,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-25 21:26:36,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-25 21:26:41,992 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-25 21:26:42,004 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-25 21:26:42,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-25 21:26:42,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-25 21:26:42,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-25 21:26:42,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-25 21:26:42,121 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-25 21:26:42,122 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-25 21:26:42,673 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 7373@DESKTOP-TSQQRSN.localdomain
2021-05-25 21:26:42,675 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /opt/hadoop-2.7.2/data/tmp/dfs/data is not formatted for BP-23928727-127.0.1.1-1621943893047
2021-05-25 21:26:42,675 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-05-25 21:26:42,701 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-23928727-127.0.1.1-1621943893047
2021-05-25 21:26:42,701 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-23928727-127.0.1.1-1621943893047
2021-05-25 21:26:42,702 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-23928727-127.0.1.1-1621943893047 is not formatted for BP-23928727-127.0.1.1-1621943893047
2021-05-25 21:26:42,702 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-05-25 21:26:42,703 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-23928727-127.0.1.1-1621943893047 directory /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-23928727-127.0.1.1-1621943893047/current
2021-05-25 21:26:42,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=858105615;bpid=BP-23928727-127.0.1.1-1621943893047;lv=-56;nsInfo=lv=-63;cid=CID-669bb093-4aad-46db-a358-5084b3d20f48;nsid=858105615;c=0;bpid=BP-23928727-127.0.1.1-1621943893047;dnuuid=null
2021-05-25 21:26:42,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID b59d0002-a15c-41fc-8cc2-e7259ea1fe64
2021-05-25 21:26:42,742 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-e02acc24-e10d-435a-912c-807057c6d093
2021-05-25 21:26:42,742 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-25 21:26:42,747 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-25 21:26:42,747 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-23928727-127.0.1.1-1621943893047
2021-05-25 21:26:42,748 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-23928727-127.0.1.1-1621943893047 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-25 21:26:42,784 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-23928727-127.0.1.1-1621943893047 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 36ms
2021-05-25 21:26:42,784 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-23928727-127.0.1.1-1621943893047: 37ms
2021-05-25 21:26:42,785 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-23928727-127.0.1.1-1621943893047 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-25 21:26:42,785 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-23928727-127.0.1.1-1621943893047 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 0ms
2021-05-25 21:26:42,785 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-05-25 21:26:42,899 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-23928727-127.0.1.1-1621943893047 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data
2021-05-25 21:26:42,900 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-e02acc24-e10d-435a-912c-807057c6d093): finished scanning block pool BP-23928727-127.0.1.1-1621943893047
2021-05-25 21:26:42,901 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1621950113901 with interval 21600000
2021-05-25 21:26:42,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-23928727-127.0.1.1-1621943893047 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 beginning handshake with NN
2021-05-25 21:26:42,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-23928727-127.0.1.1-1621943893047 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 successfully registered with NN
2021-05-25 21:26:42,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-25 21:26:42,965 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-e02acc24-e10d-435a-912c-807057c6d093): no suitable block pools found to scan.  Waiting 1814399934 ms.
2021-05-25 21:26:43,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-23928727-127.0.1.1-1621943893047 (Datanode Uuid b59d0002-a15c-41fc-8cc2-e7259ea1fe64) service to DESKTOP-TSQQRSN/127.0.1.1:9000 trying to claim ACTIVE state with txid=1
2021-05-25 21:26:43,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-23928727-127.0.1.1-1621943893047 (Datanode Uuid b59d0002-a15c-41fc-8cc2-e7259ea1fe64) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-25 21:26:43,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x16bccd1ef690,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 81 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-25 21:26:43,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-23928727-127.0.1.1-1621943893047
2021-05-25 21:41:53,914 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-23928727-127.0.1.1-1621943893047 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2021-05-25 22:04:32,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-23928727-127.0.1.1-1621943893047:blk_1073741825_1001 src: /127.0.0.1:54127 dest: /127.0.0.1:50010
2021-05-25 22:04:32,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:54127, dest: /127.0.0.1:50010, bytes: 42, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-190079206_1, offset: 0, srvID: b59d0002-a15c-41fc-8cc2-e7259ea1fe64, blockid: BP-23928727-127.0.1.1-1621943893047:blk_1073741825_1001, duration: 42404200
2021-05-25 22:04:32,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-23928727-127.0.1.1-1621943893047:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-25 22:05:48,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-23928727-127.0.1.1-1621943893047:blk_1073741826_1002 src: /127.0.0.1:54157 dest: /127.0.0.1:50010
2021-05-25 22:05:48,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:54157, dest: /127.0.0.1:50010, bytes: 44, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-856876756_1, offset: 0, srvID: b59d0002-a15c-41fc-8cc2-e7259ea1fe64, blockid: BP-23928727-127.0.1.1-1621943893047:blk_1073741826_1002, duration: 25812100
2021-05-25 22:05:48,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-23928727-127.0.1.1-1621943893047:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-25 22:12:39,302 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-23928727-127.0.1.1-1621943893047/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2021-05-25 22:12:39,318 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-23928727-127.0.1.1-1621943893047 blk_1073741826_1002 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-23928727-127.0.1.1-1621943893047/current/finalized/subdir0/subdir0/blk_1073741826
2021-05-25 22:12:53,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-23928727-127.0.1.1-1621943893047:blk_1073741827_1003 src: /127.0.0.1:54333 dest: /127.0.0.1:50010
2021-05-25 22:12:53,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:54333, dest: /127.0.0.1:50010, bytes: 44, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878156629_1, offset: 0, srvID: b59d0002-a15c-41fc-8cc2-e7259ea1fe64, blockid: BP-23928727-127.0.1.1-1621943893047:blk_1073741827_1003, duration: 26033500
2021-05-25 22:12:53,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-23928727-127.0.1.1-1621943893047:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 15:12:27,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 15:12:27,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 15:12:29,058 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 15:12:29,128 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 15:12:29,128 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 15:12:29,179 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 15:12:29,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-27 15:12:29,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 15:12:29,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 15:12:29,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 15:12:29,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 15:12:29,722 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 15:12:29,729 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 15:12:29,734 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 15:12:29,739 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 15:12:29,740 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 15:12:29,740 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 15:12:29,740 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 15:12:29,752 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 54565
2021-05-27 15:12:29,752 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 15:12:29,925 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:54565
2021-05-27 15:12:30,220 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 15:12:30,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 15:12:30,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 15:12:30,854 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 15:12:30,869 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 15:12:30,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 15:12:30,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 15:12:30,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 15:12:31,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-27 15:12:31,509 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 15:12:31,509 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 15:12:32,645 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 2973@DESKTOP-TSQQRSN.localdomain
2021-05-27 15:12:32,661 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /opt/hadoop-2.7.2/data/tmp/dfs/data: namenode clusterID = CID-c7a05acd-19de-4072-8b60-2e8af295a6c2; datanode clusterID = CID-669bb093-4aad-46db-a358-5084b3d20f48
2021-05-27 15:12:32,662 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1358)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1323)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:802)
	at java.lang.Thread.run(Thread.java:748)
2021-05-27 15:12:32,692 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 15:12:32,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-05-27 15:12:34,796 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2021-05-27 15:12:34,799 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2021-05-27 15:12:34,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 15:12:58,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 15:12:58,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 15:12:58,825 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 15:12:58,891 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 15:12:58,891 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 15:12:58,896 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 15:12:58,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-27 15:12:58,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 15:12:58,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 15:12:58,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 15:12:58,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 15:12:59,031 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 15:12:59,040 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 15:12:59,045 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 15:12:59,049 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 15:12:59,051 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 15:12:59,051 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 15:12:59,051 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 15:12:59,065 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 54583
2021-05-27 15:12:59,065 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 15:12:59,188 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:54583
2021-05-27 15:12:59,321 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 15:12:59,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 15:12:59,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 15:12:59,519 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 15:12:59,550 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 15:12:59,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 15:12:59,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 15:12:59,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 15:12:59,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-27 15:12:59,616 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 15:12:59,617 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 15:12:59,838 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 3145@DESKTOP-TSQQRSN.localdomain
2021-05-27 15:12:59,840 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /opt/hadoop-2.7.2/data/tmp/dfs/data: namenode clusterID = CID-c7a05acd-19de-4072-8b60-2e8af295a6c2; datanode clusterID = CID-669bb093-4aad-46db-a358-5084b3d20f48
2021-05-27 15:12:59,840 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1358)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1323)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:802)
	at java.lang.Thread.run(Thread.java:748)
2021-05-27 15:12:59,842 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 15:12:59,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-05-27 15:13:01,965 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2021-05-27 15:13:01,967 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2021-05-27 15:13:01,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 15:15:30,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 15:15:30,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 15:15:30,635 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 15:15:30,695 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 15:15:30,695 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 15:15:30,700 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 15:15:30,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-27 15:15:30,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 15:15:30,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 15:15:30,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 15:15:30,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 15:15:30,816 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 15:15:30,823 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 15:15:30,828 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 15:15:30,833 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 15:15:30,835 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 15:15:30,835 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 15:15:30,835 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 15:15:30,847 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 54739
2021-05-27 15:15:30,847 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 15:15:30,957 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:54739
2021-05-27 15:15:31,065 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 15:15:31,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 15:15:31,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 15:15:31,628 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 15:15:31,640 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 15:15:31,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 15:15:31,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 15:15:31,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 15:15:31,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-27 15:15:31,705 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 15:15:31,705 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 15:15:31,913 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 3277@DESKTOP-TSQQRSN.localdomain
2021-05-27 15:15:31,916 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /opt/hadoop-2.7.2/data/tmp/dfs/data: namenode clusterID = CID-c7a05acd-19de-4072-8b60-2e8af295a6c2; datanode clusterID = CID-669bb093-4aad-46db-a358-5084b3d20f48
2021-05-27 15:15:31,916 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1358)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1323)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:802)
	at java.lang.Thread.run(Thread.java:748)
2021-05-27 15:15:31,917 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 15:15:32,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-05-27 15:15:34,042 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2021-05-27 15:15:34,045 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2021-05-27 15:15:34,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 15:16:52,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 15:16:52,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 15:16:52,766 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 15:16:52,824 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 15:16:52,824 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 15:16:52,829 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 15:16:52,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-27 15:16:52,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 15:16:52,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 15:16:52,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 15:16:52,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 15:16:52,945 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 15:16:52,952 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 15:16:52,958 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 15:16:52,963 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 15:16:52,964 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 15:16:52,964 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 15:16:52,965 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 15:16:52,976 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 54782
2021-05-27 15:16:52,977 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 15:16:53,083 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:54782
2021-05-27 15:16:53,194 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 15:16:53,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 15:16:53,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 15:16:53,407 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 15:16:53,422 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 15:16:53,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 15:16:53,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 15:16:53,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 15:16:53,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-27 15:16:53,486 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 15:16:53,486 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 15:16:54,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 15:16:55,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 15:16:56,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 15:16:57,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 15:16:58,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 15:16:59,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 15:17:00,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 15:17:01,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 15:17:02,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 15:17:03,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 15:17:03,662 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 15:17:09,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 15:17:10,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 15:17:10,889 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 3975@DESKTOP-TSQQRSN.localdomain
2021-05-27 15:17:10,891 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /opt/hadoop-2.7.2/data/tmp/dfs/data: namenode clusterID = CID-c7a05acd-19de-4072-8b60-2e8af295a6c2; datanode clusterID = CID-669bb093-4aad-46db-a358-5084b3d20f48
2021-05-27 15:17:10,892 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1358)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1323)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:802)
	at java.lang.Thread.run(Thread.java:748)
2021-05-27 15:17:10,893 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 15:17:10,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-05-27 15:17:13,005 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2021-05-27 15:17:13,008 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2021-05-27 15:17:13,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 15:17:36,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 15:17:36,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 15:17:36,564 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 15:17:36,623 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 15:17:36,623 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 15:17:36,627 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 15:17:36,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-27 15:17:36,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 15:17:36,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 15:17:36,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 15:17:36,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 15:17:36,744 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 15:17:36,750 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 15:17:36,755 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 15:17:36,760 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 15:17:36,761 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 15:17:36,761 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 15:17:36,762 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 15:17:36,773 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 54812
2021-05-27 15:17:36,773 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 15:17:36,879 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:54812
2021-05-27 15:17:36,984 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 15:17:37,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 15:17:37,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 15:17:37,196 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 15:17:37,208 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 15:17:37,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 15:17:37,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 15:17:37,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 15:17:37,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-27 15:17:37,271 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 15:17:37,271 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 15:17:37,476 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 4197@DESKTOP-TSQQRSN.localdomain
2021-05-27 15:17:37,478 WARN org.apache.hadoop.hdfs.server.common.Storage: java.io.IOException: Incompatible clusterIDs in /opt/hadoop-2.7.2/data/tmp/dfs/data: namenode clusterID = CID-c7a05acd-19de-4072-8b60-2e8af295a6c2; datanode clusterID = CID-669bb093-4aad-46db-a358-5084b3d20f48
2021-05-27 15:17:37,479 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:478)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1358)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1323)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:802)
	at java.lang.Thread.run(Thread.java:748)
2021-05-27 15:17:37,480 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 15:17:37,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2021-05-27 15:17:39,593 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2021-05-27 15:17:39,596 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2021-05-27 15:17:39,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 15:29:14,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 15:29:14,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 15:29:14,699 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 15:29:14,770 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 15:29:14,770 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 15:29:14,774 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 15:29:14,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-27 15:29:14,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 15:29:14,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 15:29:14,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 15:29:14,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 15:29:14,883 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 15:29:14,891 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 15:29:14,895 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 15:29:14,900 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 15:29:14,901 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 15:29:14,901 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 15:29:14,902 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 15:29:14,912 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 55310
2021-05-27 15:29:14,912 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 15:29:15,023 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:55310
2021-05-27 15:29:15,127 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 15:29:15,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 15:29:15,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 15:29:15,336 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 15:29:15,350 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 15:29:15,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 15:29:15,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 15:29:15,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 15:29:15,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-27 15:29:15,414 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 15:29:15,414 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 15:29:15,729 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 5416@DESKTOP-TSQQRSN.localdomain
2021-05-27 15:29:15,731 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /opt/hadoop-2.7.2/data/tmp/dfs/data is not formatted for BP-600518186-127.0.1.1-1622100536332
2021-05-27 15:29:15,731 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-05-27 15:29:15,760 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-600518186-127.0.1.1-1622100536332
2021-05-27 15:29:15,760 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332
2021-05-27 15:29:15,761 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332 is not formatted for BP-600518186-127.0.1.1-1622100536332
2021-05-27 15:29:15,761 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-05-27 15:29:15,761 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-600518186-127.0.1.1-1622100536332 directory /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current
2021-05-27 15:29:15,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=791526008;bpid=BP-600518186-127.0.1.1-1622100536332;lv=-56;nsInfo=lv=-63;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0;bpid=BP-600518186-127.0.1.1-1622100536332;dnuuid=null
2021-05-27 15:29:15,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 15:29:15,841 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12
2021-05-27 15:29:15,841 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-27 15:29:15,847 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-27 15:29:15,847 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 15:29:15,848 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 15:29:15,904 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-600518186-127.0.1.1-1622100536332 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 55ms
2021-05-27 15:29:15,904 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-600518186-127.0.1.1-1622100536332: 57ms
2021-05-27 15:29:15,905 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 15:29:15,906 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 1ms
2021-05-27 15:29:15,907 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2021-05-27 15:29:16,232 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data
2021-05-27 15:29:16,233 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12): finished scanning block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 15:29:16,234 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622120603233 with interval 21600000
2021-05-27 15:29:16,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 beginning handshake with NN
2021-05-27 15:29:16,291 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12): no suitable block pools found to scan.  Waiting 1814399940 ms.
2021-05-27 15:29:16,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 successfully registered with NN
2021-05-27 15:29:16,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-27 15:29:16,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000 trying to claim ACTIVE state with txid=1
2021-05-27 15:29:16,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 15:29:16,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1797745b6738,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 102 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-27 15:29:16,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 15:47:50,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741825_1001 src: /127.0.0.1:55918 dest: /127.0.0.1:50010
2021-05-27 15:47:50,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55918, dest: /127.0.0.1:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_708297571_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741825_1001, duration: 40123700
2021-05-27 15:47:50,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 15:52:35,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741826_1002 src: /127.0.0.1:56030 dest: /127.0.0.1:50010
2021-05-27 15:52:35,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56030, dest: /127.0.0.1:50010, bytes: 50, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-935993219_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741826_1002, duration: 25825500
2021-05-27 15:52:35,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 17:34:21,584 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2021-05-27 17:34:21,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741826_1002 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741826
2021-05-27 17:36:33,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741827_1003 src: /127.0.0.1:59284 dest: /127.0.0.1:50010
2021-05-27 17:36:33,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59284, dest: /127.0.0.1:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-181732907_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741827_1003, duration: 40647500
2021-05-27 17:36:33,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 17:36:34,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741828_1004 src: /127.0.0.1:59285 dest: /127.0.0.1:50010
2021-05-27 17:36:34,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59285, dest: /127.0.0.1:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-181732907_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741828_1004, duration: 2627100
2021-05-27 17:36:34,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 17:36:34,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741829_1005 src: /127.0.0.1:59286 dest: /127.0.0.1:50010
2021-05-27 17:36:34,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59286, dest: /127.0.0.1:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-181732907_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741829_1005, duration: 1695500
2021-05-27 17:36:34,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 17:36:34,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741830_1006 src: /127.0.0.1:59287 dest: /127.0.0.1:50010
2021-05-27 17:36:34,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59287, dest: /127.0.0.1:50010, bytes: 97447, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-181732907_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741830_1006, duration: 2975600
2021-05-27 17:36:34,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 17:41:12,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741831_1007 src: /127.0.0.1:59416 dest: /127.0.0.1:50010
2021-05-27 17:41:12,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59416, dest: /127.0.0.1:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_996484013_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741831_1007, duration: 44585900
2021-05-27 17:41:12,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 17:41:12,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741832_1008 src: /127.0.0.1:59417 dest: /127.0.0.1:50010
2021-05-27 17:41:12,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59417, dest: /127.0.0.1:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_996484013_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741832_1008, duration: 2198100
2021-05-27 17:41:12,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 17:41:12,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741833_1009 src: /127.0.0.1:59418 dest: /127.0.0.1:50010
2021-05-27 17:41:12,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59418, dest: /127.0.0.1:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_996484013_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741833_1009, duration: 3499600
2021-05-27 17:41:12,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 17:41:12,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741834_1010 src: /127.0.0.1:59419 dest: /127.0.0.1:50010
2021-05-27 17:41:12,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59419, dest: /127.0.0.1:50010, bytes: 97447, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_996484013_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741834_1010, duration: 2694700
2021-05-27 17:41:12,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 17:51:23,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1f58d2c65148,  containing 1 storage report(s), of which we sent 1. The reports had 9 total blocks and used 1 RPC(s). This took 86 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-27 17:51:23,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 17:56:40,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741835_1011 src: /127.0.0.1:60154 dest: /127.0.0.1:50010
2021-05-27 17:56:40,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60154, dest: /127.0.0.1:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1705296237_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741835_1011, duration: 44763300
2021-05-27 17:56:40,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 17:56:40,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741836_1012 src: /127.0.0.1:60155 dest: /127.0.0.1:50010
2021-05-27 17:56:40,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60155, dest: /127.0.0.1:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1705296237_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741836_1012, duration: 2860100
2021-05-27 17:56:40,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 17:56:40,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741837_1013 src: /127.0.0.1:60156 dest: /127.0.0.1:50010
2021-05-27 17:56:40,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60156, dest: /127.0.0.1:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1705296237_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741837_1013, duration: 2367800
2021-05-27 17:56:40,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 17:56:40,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741838_1014 src: /127.0.0.1:60157 dest: /127.0.0.1:50010
2021-05-27 17:56:40,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60157, dest: /127.0.0.1:50010, bytes: 97447, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1705296237_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741838_1014, duration: 3312200
2021-05-27 17:56:40,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:06:35,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741839_1015 src: /127.0.0.1:60810 dest: /127.0.0.1:50010
2021-05-27 18:06:35,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60810, dest: /127.0.0.1:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1893541551_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741839_1015, duration: 53679700
2021-05-27 18:06:35,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:06:35,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741840_1016 src: /127.0.0.1:60811 dest: /127.0.0.1:50010
2021-05-27 18:06:35,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60811, dest: /127.0.0.1:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1893541551_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741840_1016, duration: 3888100
2021-05-27 18:06:35,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:06:35,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741841_1017 src: /127.0.0.1:60812 dest: /127.0.0.1:50010
2021-05-27 18:06:35,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60812, dest: /127.0.0.1:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1893541551_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741841_1017, duration: 2088200
2021-05-27 18:06:35,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:06:35,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741842_1018 src: /127.0.0.1:60813 dest: /127.0.0.1:50010
2021-05-27 18:06:35,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60813, dest: /127.0.0.1:50010, bytes: 97442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1893541551_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741842_1018, duration: 3050500
2021-05-27 18:06:35,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:11:57,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741843_1019 src: /127.0.0.1:61062 dest: /127.0.0.1:50010
2021-05-27 18:11:57,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61062, dest: /127.0.0.1:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_310915260_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741843_1019, duration: 41316700
2021-05-27 18:11:57,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:11:57,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741844_1020 src: /127.0.0.1:61063 dest: /127.0.0.1:50010
2021-05-27 18:11:57,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61063, dest: /127.0.0.1:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_310915260_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741844_1020, duration: 2817400
2021-05-27 18:11:57,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:11:58,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741845_1021 src: /127.0.0.1:61064 dest: /127.0.0.1:50010
2021-05-27 18:11:58,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61064, dest: /127.0.0.1:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_310915260_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741845_1021, duration: 2325100
2021-05-27 18:11:58,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:11:58,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741846_1022 src: /127.0.0.1:61065 dest: /127.0.0.1:50010
2021-05-27 18:11:58,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61065, dest: /127.0.0.1:50010, bytes: 97442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_310915260_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741846_1022, duration: 2887200
2021-05-27 18:11:58,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:15:56,912 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN.localdomain/127.0.1.1"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-27 18:16:00,612 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 18:16:00,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 18:18:00,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 18:18:00,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 18:18:01,184 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 18:18:01,246 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 18:18:01,247 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 18:18:01,295 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 18:18:01,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-27 18:18:01,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 18:18:01,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 18:18:01,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 18:18:01,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 18:18:01,438 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 18:18:01,444 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 18:18:01,451 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 18:18:01,456 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 18:18:01,457 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 18:18:01,458 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 18:18:01,458 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 18:18:01,469 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 61355
2021-05-27 18:18:01,469 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 18:18:01,581 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:61355
2021-05-27 18:18:01,785 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 18:18:01,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 18:18:01,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 18:18:02,021 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 18:18:02,038 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 18:18:02,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 18:18:02,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 18:18:02,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 18:18:02,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-27 18:18:02,110 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 18:18:02,110 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 18:18:02,472 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 10247@DESKTOP-TSQQRSN.localdomain
2021-05-27 18:18:02,517 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-600518186-127.0.1.1-1622100536332
2021-05-27 18:18:02,518 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332
2021-05-27 18:18:02,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=791526008;bpid=BP-600518186-127.0.1.1-1622100536332;lv=-56;nsInfo=lv=-63;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0;bpid=BP-600518186-127.0.1.1-1622100536332;dnuuid=92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 18:18:02,558 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12
2021-05-27 18:18:02,558 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-27 18:18:02,587 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-27 18:18:02,587 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 18:18:02,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 18:18:02,618 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current: 2700511
2021-05-27 18:18:02,620 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-600518186-127.0.1.1-1622100536332 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 32ms
2021-05-27 18:18:02,620 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-600518186-127.0.1.1-1622100536332: 32ms
2021-05-27 18:18:02,621 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 18:18:02,627 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 6ms
2021-05-27 18:18:02,627 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 8ms
2021-05-27 18:18:02,805 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12): no suitable block pools found to scan.  Waiting 1804273426 ms.
2021-05-27 18:18:02,807 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622122583807 with interval 21600000
2021-05-27 18:18:02,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 beginning handshake with NN
2021-05-27 18:18:02,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 successfully registered with NN
2021-05-27 18:18:02,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-27 18:18:02,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000 trying to claim ACTIVE state with txid=177
2021-05-27 18:18:02,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 18:18:03,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x20cd36f5746c,  containing 1 storage report(s), of which we sent 1. The reports had 21 total blocks and used 1 RPC(s). This took 7 msec to generate and 68 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-27 18:18:03,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 18:19:14,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741847_1023 src: /127.0.0.1:61396 dest: /127.0.0.1:50010
2021-05-27 18:19:14,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61396, dest: /127.0.0.1:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-576194475_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741847_1023, duration: 58466000
2021-05-27 18:19:14,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741847_1023, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:19:14,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741848_1024 src: /127.0.0.1:61397 dest: /127.0.0.1:50010
2021-05-27 18:19:14,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61397, dest: /127.0.0.1:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-576194475_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741848_1024, duration: 5273600
2021-05-27 18:19:14,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741848_1024, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:19:14,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741849_1025 src: /127.0.0.1:61398 dest: /127.0.0.1:50010
2021-05-27 18:19:14,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61398, dest: /127.0.0.1:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-576194475_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741849_1025, duration: 2172200
2021-05-27 18:19:14,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741849_1025, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:19:14,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741850_1026 src: /127.0.0.1:61399 dest: /127.0.0.1:50010
2021-05-27 18:19:14,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61399, dest: /127.0.0.1:50010, bytes: 97442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-576194475_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741850_1026, duration: 10777100
2021-05-27 18:19:14,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741850_1026, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:31:19,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741851_1027 src: /127.0.0.1:62083 dest: /127.0.0.1:50010
2021-05-27 18:31:19,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62083, dest: /127.0.0.1:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2127679153_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741851_1027, duration: 39955400
2021-05-27 18:31:19,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741851_1027, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:31:19,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741852_1028 src: /127.0.0.1:62084 dest: /127.0.0.1:50010
2021-05-27 18:31:19,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62084, dest: /127.0.0.1:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2127679153_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741852_1028, duration: 2174400
2021-05-27 18:31:19,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741852_1028, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:31:19,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741853_1029 src: /127.0.0.1:62085 dest: /127.0.0.1:50010
2021-05-27 18:31:19,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62085, dest: /127.0.0.1:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2127679153_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741853_1029, duration: 1881400
2021-05-27 18:31:19,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741853_1029, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:31:19,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741854_1030 src: /127.0.0.1:62086 dest: /127.0.0.1:50010
2021-05-27 18:31:19,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62086, dest: /127.0.0.1:50010, bytes: 97440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2127679153_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741854_1030, duration: 2696200
2021-05-27 18:31:19,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741854_1030, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:33:11,217 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN.localdomain/127.0.1.1"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-27 18:33:15,079 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 18:33:15,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 18:33:57,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 18:33:57,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 18:33:57,616 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 18:33:57,677 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 18:33:57,677 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 18:33:57,681 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 18:33:57,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-27 18:33:57,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 18:33:57,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 18:33:57,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 18:33:57,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 18:33:57,795 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 18:33:57,801 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 18:33:57,807 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 18:33:57,812 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 18:33:57,813 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 18:33:57,813 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 18:33:57,813 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 18:33:57,825 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 62204
2021-05-27 18:33:57,825 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 18:33:57,930 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:62204
2021-05-27 18:33:58,042 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 18:33:58,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 18:33:58,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 18:33:58,255 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 18:33:58,270 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 18:33:58,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 18:33:58,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 18:33:58,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 18:33:58,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-27 18:33:58,332 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 18:33:58,333 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 18:33:58,613 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 11994@DESKTOP-TSQQRSN.localdomain
2021-05-27 18:33:58,655 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-600518186-127.0.1.1-1622100536332
2021-05-27 18:33:58,656 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332
2021-05-27 18:33:58,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=791526008;bpid=BP-600518186-127.0.1.1-1622100536332;lv=-56;nsInfo=lv=-63;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0;bpid=BP-600518186-127.0.1.1-1622100536332;dnuuid=92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 18:33:58,698 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12
2021-05-27 18:33:58,698 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-27 18:33:58,732 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-27 18:33:58,733 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 18:33:58,733 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 18:33:58,740 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current: 2860253
2021-05-27 18:33:58,742 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-600518186-127.0.1.1-1622100536332 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 8ms
2021-05-27 18:33:58,742 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-600518186-127.0.1.1-1622100536332: 10ms
2021-05-27 18:33:58,743 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 18:33:58,748 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 5ms
2021-05-27 18:33:58,748 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 5ms
2021-05-27 18:33:58,909 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12): no suitable block pools found to scan.  Waiting 1803317322 ms.
2021-05-27 18:33:58,911 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622126415911 with interval 21600000
2021-05-27 18:33:58,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 beginning handshake with NN
2021-05-27 18:33:58,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 successfully registered with NN
2021-05-27 18:33:58,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-27 18:33:59,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000 trying to claim ACTIVE state with txid=234
2021-05-27 18:33:59,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 18:33:59,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x21abd15cbd24,  containing 1 storage report(s), of which we sent 1. The reports had 29 total blocks and used 1 RPC(s). This took 7 msec to generate and 56 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-27 18:33:59,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 18:39:02,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741855_1031 src: /127.0.0.1:62426 dest: /127.0.0.1:50010
2021-05-27 18:39:02,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62426, dest: /127.0.0.1:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_706211513_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741855_1031, duration: 50704300
2021-05-27 18:39:02,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741855_1031, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:39:02,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741856_1032 src: /127.0.0.1:62427 dest: /127.0.0.1:50010
2021-05-27 18:39:02,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62427, dest: /127.0.0.1:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_706211513_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741856_1032, duration: 1974800
2021-05-27 18:39:02,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741856_1032, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:39:02,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741857_1033 src: /127.0.0.1:62428 dest: /127.0.0.1:50010
2021-05-27 18:39:02,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62428, dest: /127.0.0.1:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_706211513_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741857_1033, duration: 2353300
2021-05-27 18:39:02,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741857_1033, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:39:02,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741858_1034 src: /127.0.0.1:62429 dest: /127.0.0.1:50010
2021-05-27 18:39:02,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62429, dest: /127.0.0.1:50010, bytes: 97440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_706211513_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741858_1034, duration: 3029100
2021-05-27 18:39:02,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741858_1034, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:39:09,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741859_1035 src: /127.0.0.1:62443 dest: /127.0.0.1:50010
2021-05-27 18:39:09,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62443, dest: /127.0.0.1:50010, bytes: 115863, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1452325349_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741859_1035, duration: 40375400
2021-05-27 18:39:09,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741859_1035, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:39:15,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741860_1036 src: /127.0.0.1:62457 dest: /127.0.0.1:50010
2021-05-27 18:39:20,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741861_1037 src: /127.0.0.1:62464 dest: /127.0.0.1:50010
2021-05-27 18:39:20,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62464, dest: /127.0.0.1:50010, bytes: 50, op: HDFS_WRITE, cliID: DFSClient_attempt_1622111655401_0002_r_000000_0_1756284483_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741861_1037, duration: 34274300
2021-05-27 18:39:20,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741861_1037, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:39:20,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62457, dest: /127.0.0.1:50010, bytes: 33755, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1452325349_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741860_1036, duration: 5617269500
2021-05-27 18:39:20,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741860_1036, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:39:20,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741862_1038 src: /127.0.0.1:62466 dest: /127.0.0.1:50010
2021-05-27 18:39:20,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62466, dest: /127.0.0.1:50010, bytes: 347, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1452325349_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741862_1038, duration: 2380600
2021-05-27 18:39:20,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741862_1038, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:39:20,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741863_1039 src: /127.0.0.1:62468 dest: /127.0.0.1:50010
2021-05-27 18:39:20,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62468, dest: /127.0.0.1:50010, bytes: 33755, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1452325349_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741863_1039, duration: 2727400
2021-05-27 18:39:20,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741863_1039, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:39:20,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741864_1040 src: /127.0.0.1:62469 dest: /127.0.0.1:50010
2021-05-27 18:39:20,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:62469, dest: /127.0.0.1:50010, bytes: 115863, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1452325349_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741864_1040, duration: 3316300
2021-05-27 18:39:20,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741864_1040, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 18:39:26,593 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741856_1032 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741856 for deletion
2021-05-27 18:39:26,595 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741857_1033 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741857 for deletion
2021-05-27 18:39:26,595 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741858_1034 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741858 for deletion
2021-05-27 18:39:26,595 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2021-05-27 18:39:26,595 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741860_1036 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2021-05-27 18:39:26,595 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741855_1031 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741855 for deletion
2021-05-27 18:39:26,596 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741856_1032 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741856
2021-05-27 18:39:26,596 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741857_1033 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741857
2021-05-27 18:39:26,597 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741858_1034 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741858
2021-05-27 18:39:26,597 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741859_1035 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741859
2021-05-27 18:39:26,598 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741860_1036 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741860
2021-05-27 18:39:26,599 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741855_1031 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741855
2021-05-27 18:59:14,793 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2021-05-27 18:59:14,795 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741862_1038 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741862
2021-05-27 19:34:50,155 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741861_1037 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2021-05-27 19:34:50,158 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741861_1037 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741861
2021-05-27 19:35:53,270 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/127.0.1.1"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-27 19:35:56,397 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 19:35:56,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 19:36:34,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 19:36:34,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 19:36:35,109 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 19:36:35,165 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 19:36:35,166 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 19:36:35,173 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 19:36:35,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-27 19:36:35,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 19:36:35,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 19:36:35,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 19:36:35,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 19:36:35,302 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 19:36:35,313 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 19:36:35,320 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 19:36:35,327 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 19:36:35,328 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 19:36:35,328 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 19:36:35,328 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 19:36:35,341 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 65437
2021-05-27 19:36:35,341 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 19:36:35,474 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:65437
2021-05-27 19:36:35,642 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 19:36:35,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 19:36:35,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 19:36:35,862 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 19:36:35,892 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 19:36:35,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 19:36:35,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 19:36:35,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 19:36:35,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-27 19:36:36,003 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 19:36:36,003 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 19:36:36,371 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 14668@DESKTOP-TSQQRSN
2021-05-27 19:36:36,421 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-600518186-127.0.1.1-1622100536332
2021-05-27 19:36:36,421 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332
2021-05-27 19:36:36,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=791526008;bpid=BP-600518186-127.0.1.1-1622100536332;lv=-56;nsInfo=lv=-63;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0;bpid=BP-600518186-127.0.1.1-1622100536332;dnuuid=92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 19:36:36,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12
2021-05-27 19:36:36,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-27 19:36:36,489 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-27 19:36:36,490 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 19:36:36,490 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 19:36:36,515 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current: 2879427
2021-05-27 19:36:36,517 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-600518186-127.0.1.1-1622100536332 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 26ms
2021-05-27 19:36:36,517 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-600518186-127.0.1.1-1622100536332: 27ms
2021-05-27 19:36:36,518 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 19:36:36,525 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 6ms
2021-05-27 19:36:36,525 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 9ms
2021-05-27 19:36:36,691 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12): no suitable block pools found to scan.  Waiting 1799559540 ms.
2021-05-27 19:36:36,693 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622120568693 with interval 21600000
2021-05-27 19:36:36,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 beginning handshake with NN
2021-05-27 19:36:36,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 successfully registered with NN
2021-05-27 19:36:36,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-27 19:36:36,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000 trying to claim ACTIVE state with txid=325
2021-05-27 19:36:36,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 19:36:36,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2516c0a26e0c,  containing 1 storage report(s), of which we sent 1. The reports had 31 total blocks and used 1 RPC(s). This took 4 msec to generate and 66 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-27 19:36:36,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 19:37:26,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741865_1041 src: /127.0.0.1:65461 dest: /127.0.0.1:50010
2021-05-27 19:37:26,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:65461, dest: /127.0.0.1:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_673399775_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741865_1041, duration: 53080500
2021-05-27 19:37:26,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741865_1041, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 19:37:27,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741866_1042 src: /127.0.0.1:65462 dest: /127.0.0.1:50010
2021-05-27 19:37:27,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:65462, dest: /127.0.0.1:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_673399775_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741866_1042, duration: 2192000
2021-05-27 19:37:27,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741866_1042, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 19:37:27,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741867_1043 src: /127.0.0.1:65463 dest: /127.0.0.1:50010
2021-05-27 19:37:27,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:65463, dest: /127.0.0.1:50010, bytes: 29, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_673399775_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741867_1043, duration: 1907600
2021-05-27 19:37:27,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741867_1043, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 19:37:27,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741868_1044 src: /127.0.0.1:65464 dest: /127.0.0.1:50010
2021-05-27 19:37:27,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:65464, dest: /127.0.0.1:50010, bytes: 97432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_673399775_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741868_1044, duration: 2932200
2021-05-27 19:37:27,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741868_1044, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 19:37:34,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741869_1045 src: /127.0.0.1:65477 dest: /127.0.0.1:50010
2021-05-27 19:37:34,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:65477, dest: /127.0.0.1:50010, bytes: 115855, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459669539_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741869_1045, duration: 32649000
2021-05-27 19:37:34,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741869_1045, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 19:37:39,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741870_1046 src: /127.0.0.1:65486 dest: /127.0.0.1:50010
2021-05-27 19:37:44,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741871_1047 src: /127.0.0.1:65495 dest: /127.0.0.1:50010
2021-05-27 19:37:44,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:65495, dest: /127.0.0.1:50010, bytes: 50, op: HDFS_WRITE, cliID: DFSClient_attempt_1622115408185_0001_r_000000_0_803172870_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741871_1047, duration: 39867300
2021-05-27 19:37:44,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741871_1047, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 19:37:45,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:65486, dest: /127.0.0.1:50010, bytes: 33680, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459669539_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741870_1046, duration: 5478300800
2021-05-27 19:37:45,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741870_1046, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 19:37:45,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741872_1048 src: /127.0.0.1:65497 dest: /127.0.0.1:50010
2021-05-27 19:37:45,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:65497, dest: /127.0.0.1:50010, bytes: 347, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459669539_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741872_1048, duration: 2395600
2021-05-27 19:37:45,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741872_1048, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 19:37:45,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741873_1049 src: /127.0.0.1:65499 dest: /127.0.0.1:50010
2021-05-27 19:37:45,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:65499, dest: /127.0.0.1:50010, bytes: 33680, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459669539_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741873_1049, duration: 2842200
2021-05-27 19:37:45,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741873_1049, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 19:37:45,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741874_1050 src: /127.0.0.1:65500 dest: /127.0.0.1:50010
2021-05-27 19:37:45,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:65500, dest: /127.0.0.1:50010, bytes: 115855, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459669539_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741874_1050, duration: 3535000
2021-05-27 19:37:45,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741874_1050, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 19:37:48,908 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741865_1041 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741865 for deletion
2021-05-27 19:37:48,909 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741866_1042 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741866 for deletion
2021-05-27 19:37:48,909 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741867_1043 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741867 for deletion
2021-05-27 19:37:48,909 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741868_1044 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741868 for deletion
2021-05-27 19:37:48,909 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741869_1045 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741869 for deletion
2021-05-27 19:37:48,910 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741870_1046 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741870 for deletion
2021-05-27 19:37:48,910 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741865_1041 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741865
2021-05-27 19:37:48,910 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741866_1042 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741866
2021-05-27 19:37:48,911 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741867_1043 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741867
2021-05-27 19:37:48,912 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741868_1044 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741868
2021-05-27 19:37:48,912 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741869_1045 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741869
2021-05-27 19:37:48,913 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741870_1046 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741870
2021-05-27 19:38:12,911 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741872_1048 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741872 for deletion
2021-05-27 19:38:12,913 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741872_1048 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741872
2021-05-27 20:19:00,406 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/127.0.1.1"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-27 20:19:03,865 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 20:19:03,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/127.0.1.1
************************************************************/
2021-05-27 20:34:17,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 20:34:17,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 20:34:18,325 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 20:34:18,403 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 20:34:18,403 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 20:34:18,409 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 20:34:18,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-27 20:34:18,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 20:34:18,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 20:34:18,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 20:34:18,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 20:34:18,616 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 20:34:18,623 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 20:34:18,628 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 20:34:18,633 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 20:34:18,635 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 20:34:18,635 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 20:34:18,635 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 20:34:18,646 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 60219
2021-05-27 20:34:18,646 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 20:34:18,912 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:60219
2021-05-27 20:34:19,034 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 20:34:19,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 20:34:19,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 20:34:19,539 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 20:34:19,585 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 20:34:19,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 20:34:19,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 20:34:19,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 20:34:19,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-27 20:34:19,775 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 20:34:19,775 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 20:34:21,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 20:34:21,304 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 17571@DESKTOP-TSQQRSN
2021-05-27 20:34:21,357 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-600518186-127.0.1.1-1622100536332
2021-05-27 20:34:21,358 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332
2021-05-27 20:34:21,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=791526008;bpid=BP-600518186-127.0.1.1-1622100536332;lv=-56;nsInfo=lv=-63;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0;bpid=BP-600518186-127.0.1.1-1622100536332;dnuuid=92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 20:34:21,409 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12
2021-05-27 20:34:21,409 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-27 20:34:21,445 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-27 20:34:21,445 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 20:34:21,446 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 20:34:21,474 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-600518186-127.0.1.1-1622100536332 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 27ms
2021-05-27 20:34:21,474 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-600518186-127.0.1.1-1622100536332: 29ms
2021-05-27 20:34:21,475 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 20:34:21,483 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 8ms
2021-05-27 20:34:21,483 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 9ms
2021-05-27 20:34:21,701 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12): no suitable block pools found to scan.  Waiting 1796094530 ms.
2021-05-27 20:34:21,707 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622128641707 with interval 21600000
2021-05-27 20:34:21,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 beginning handshake with NN
2021-05-27 20:34:21,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 successfully registered with NN
2021-05-27 20:34:21,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-27 20:34:21,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000 trying to claim ACTIVE state with txid=411
2021-05-27 20:34:21,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 20:34:22,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x283d8938144c,  containing 1 storage report(s), of which we sent 1. The reports had 34 total blocks and used 1 RPC(s). This took 6 msec to generate and 115 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-27 20:34:22,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 20:34:55,177 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/127.0.1.1"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-27 20:34:58,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 20:34:59,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-27 20:35:00,493 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 20:35:00,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/127.0.1.1
************************************************************/
2021-05-27 20:36:18,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 20:36:18,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 20:36:18,908 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 20:36:18,989 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 20:36:18,989 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 20:36:18,995 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 20:36:18,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-27 20:36:19,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 20:36:19,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 20:36:19,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 20:36:19,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 20:36:19,118 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 20:36:19,125 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 20:36:19,130 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 20:36:19,135 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 20:36:19,136 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 20:36:19,136 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 20:36:19,136 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 20:36:19,147 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 60330
2021-05-27 20:36:19,147 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 20:36:19,255 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:60330
2021-05-27 20:36:19,377 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 20:36:19,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 20:36:19,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 20:36:19,664 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 20:36:19,679 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 20:36:19,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 20:36:19,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 20:36:19,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 20:36:19,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-27 20:36:19,754 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 20:36:19,754 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 20:36:20,584 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 19417@DESKTOP-TSQQRSN
2021-05-27 20:36:20,632 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-600518186-127.0.1.1-1622100536332
2021-05-27 20:36:20,632 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332
2021-05-27 20:36:20,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=791526008;bpid=BP-600518186-127.0.1.1-1622100536332;lv=-56;nsInfo=lv=-63;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0;bpid=BP-600518186-127.0.1.1-1622100536332;dnuuid=92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 20:36:20,667 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12
2021-05-27 20:36:20,668 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-27 20:36:20,698 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-27 20:36:20,698 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 20:36:20,699 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 20:36:20,706 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current: 3092480
2021-05-27 20:36:20,707 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-600518186-127.0.1.1-1622100536332 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 9ms
2021-05-27 20:36:20,708 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-600518186-127.0.1.1-1622100536332: 9ms
2021-05-27 20:36:20,708 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 20:36:20,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 5ms
2021-05-27 20:36:20,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 6ms
2021-05-27 20:36:20,874 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12): no suitable block pools found to scan.  Waiting 1795975357 ms.
2021-05-27 20:36:20,876 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622133454876 with interval 21600000
2021-05-27 20:36:20,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-05-27 20:36:20,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-05-27 20:36:20,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-27 20:36:21,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=412
2021-05-27 20:36:21,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-27 20:36:21,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2859416abc20,  containing 1 storage report(s), of which we sent 1. The reports had 34 total blocks and used 1 RPC(s). This took 3 msec to generate and 56 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-27 20:36:21,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 20:38:12,291 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741871_1047 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741871 for deletion
2021-05-27 20:38:12,293 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741871_1047 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741871
2021-05-27 20:38:33,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741875_1051 src: /10.191.53.85:60426 dest: /10.191.53.85:50010
2021-05-27 20:38:33,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60426, dest: /10.191.53.85:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-276237265_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741875_1051, duration: 46505100
2021-05-27 20:38:33,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741875_1051, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:38:34,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741876_1052 src: /10.191.53.85:60427 dest: /10.191.53.85:50010
2021-05-27 20:38:34,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60427, dest: /10.191.53.85:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-276237265_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741876_1052, duration: 3084300
2021-05-27 20:38:34,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741876_1052, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:38:34,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741877_1053 src: /10.191.53.85:60428 dest: /10.191.53.85:50010
2021-05-27 20:38:34,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60428, dest: /10.191.53.85:50010, bytes: 29, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-276237265_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741877_1053, duration: 1728800
2021-05-27 20:38:34,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741877_1053, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:38:34,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741878_1054 src: /10.191.53.85:60429 dest: /10.191.53.85:50010
2021-05-27 20:38:34,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60429, dest: /10.191.53.85:50010, bytes: 97435, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-276237265_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741878_1054, duration: 2846400
2021-05-27 20:38:34,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741878_1054, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:38:42,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741879_1055 src: /10.191.53.85:60445 dest: /10.191.53.85:50010
2021-05-27 20:38:42,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60445, dest: /10.191.53.85:50010, bytes: 115858, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_715595971_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741879_1055, duration: 35549900
2021-05-27 20:38:42,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741879_1055, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:38:47,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741880_1056 src: /10.191.53.85:60454 dest: /10.191.53.85:50010
2021-05-27 20:38:52,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741881_1057 src: /10.191.53.85:60460 dest: /10.191.53.85:50010
2021-05-27 20:38:52,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60460, dest: /10.191.53.85:50010, bytes: 50, op: HDFS_WRITE, cliID: DFSClient_attempt_1622119001821_0001_r_000000_0_-445556908_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741881_1057, duration: 37513900
2021-05-27 20:38:52,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741881_1057, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:38:52,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60454, dest: /10.191.53.85:50010, bytes: 33672, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_715595971_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741880_1056, duration: 5850353300
2021-05-27 20:38:52,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741880_1056, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:38:52,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741882_1058 src: /10.191.53.85:60462 dest: /10.191.53.85:50010
2021-05-27 20:38:52,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60462, dest: /10.191.53.85:50010, bytes: 347, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_715595971_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741882_1058, duration: 1806700
2021-05-27 20:38:52,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741882_1058, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:38:52,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741883_1059 src: /10.191.53.85:60464 dest: /10.191.53.85:50010
2021-05-27 20:38:52,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60464, dest: /10.191.53.85:50010, bytes: 33672, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_715595971_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741883_1059, duration: 1905200
2021-05-27 20:38:52,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741883_1059, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:38:52,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741884_1060 src: /10.191.53.85:60465 dest: /10.191.53.85:50010
2021-05-27 20:38:52,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60465, dest: /10.191.53.85:50010, bytes: 115858, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_715595971_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741884_1060, duration: 3373800
2021-05-27 20:38:52,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741884_1060, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:38:57,375 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741875_1051 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741875 for deletion
2021-05-27 20:38:57,376 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741876_1052 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741876 for deletion
2021-05-27 20:38:57,376 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741877_1053 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741877 for deletion
2021-05-27 20:38:57,376 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741878_1054 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741878 for deletion
2021-05-27 20:38:57,376 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741879_1055 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741879 for deletion
2021-05-27 20:38:57,376 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741880_1056 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741880 for deletion
2021-05-27 20:38:57,376 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741875_1051 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741875
2021-05-27 20:38:57,377 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741876_1052 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741876
2021-05-27 20:38:57,377 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741877_1053 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741877
2021-05-27 20:38:57,378 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741878_1054 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741878
2021-05-27 20:38:57,379 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741879_1055 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741879
2021-05-27 20:38:57,383 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741880_1056 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741880
2021-05-27 20:43:31,057 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741881_1057 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741881 for deletion
2021-05-27 20:43:31,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741881_1057 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741881
2021-05-27 20:43:35,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741885_1061 src: /10.191.53.85:60768 dest: /10.191.53.85:50010
2021-05-27 20:43:35,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60768, dest: /10.191.53.85:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-508293523_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741885_1061, duration: 42913800
2021-05-27 20:43:35,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741885_1061, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:43:35,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741886_1062 src: /10.191.53.85:60769 dest: /10.191.53.85:50010
2021-05-27 20:43:35,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60769, dest: /10.191.53.85:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-508293523_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741886_1062, duration: 2928900
2021-05-27 20:43:35,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741886_1062, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:43:35,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741887_1063 src: /10.191.53.85:60770 dest: /10.191.53.85:50010
2021-05-27 20:43:35,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60770, dest: /10.191.53.85:50010, bytes: 29, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-508293523_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741887_1063, duration: 2572800
2021-05-27 20:43:35,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741887_1063, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:43:36,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741888_1064 src: /10.191.53.85:60771 dest: /10.191.53.85:50010
2021-05-27 20:43:36,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60771, dest: /10.191.53.85:50010, bytes: 97438, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-508293523_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741888_1064, duration: 2898000
2021-05-27 20:43:36,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741888_1064, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:43:43,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741889_1065 src: /10.191.53.85:60785 dest: /10.191.53.85:50010
2021-05-27 20:43:43,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60785, dest: /10.191.53.85:50010, bytes: 115861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-641705300_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741889_1065, duration: 30688900
2021-05-27 20:43:43,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741889_1065, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:43:47,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741890_1066 src: /10.191.53.85:60792 dest: /10.191.53.85:50010
2021-05-27 20:43:52,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741891_1067 src: /10.191.53.85:60799 dest: /10.191.53.85:50010
2021-05-27 20:43:52,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60799, dest: /10.191.53.85:50010, bytes: 50, op: HDFS_WRITE, cliID: DFSClient_attempt_1622119389401_0001_r_000000_0_-703067675_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741891_1067, duration: 34150600
2021-05-27 20:43:52,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741891_1067, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:43:52,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60792, dest: /10.191.53.85:50010, bytes: 33672, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-641705300_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741890_1066, duration: 5199654300
2021-05-27 20:43:52,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741890_1066, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:43:52,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741892_1068 src: /10.191.53.85:60802 dest: /10.191.53.85:50010
2021-05-27 20:43:52,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60802, dest: /10.191.53.85:50010, bytes: 347, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-641705300_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741892_1068, duration: 2265600
2021-05-27 20:43:52,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741892_1068, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:43:52,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741893_1069 src: /10.191.53.85:60804 dest: /10.191.53.85:50010
2021-05-27 20:43:52,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60804, dest: /10.191.53.85:50010, bytes: 33672, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-641705300_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741893_1069, duration: 2160500
2021-05-27 20:43:52,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741893_1069, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:43:53,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-600518186-127.0.1.1-1622100536332:blk_1073741894_1070 src: /10.191.53.85:60805 dest: /10.191.53.85:50010
2021-05-27 20:43:53,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60805, dest: /10.191.53.85:50010, bytes: 115861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-641705300_1, offset: 0, srvID: 92478c8c-8e85-4c7e-8076-628dcc214550, blockid: BP-600518186-127.0.1.1-1622100536332:blk_1073741894_1070, duration: 3285400
2021-05-27 20:43:53,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-600518186-127.0.1.1-1622100536332:blk_1073741894_1070, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-27 20:43:55,124 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741888_1064 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741888 for deletion
2021-05-27 20:43:55,124 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741889_1065 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741889 for deletion
2021-05-27 20:43:55,124 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741890_1066 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741890 for deletion
2021-05-27 20:43:55,124 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741885_1061 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741885 for deletion
2021-05-27 20:43:55,125 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741886_1062 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741886 for deletion
2021-05-27 20:43:55,125 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741887_1063 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741887 for deletion
2021-05-27 20:43:55,156 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741888_1064 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741888
2021-05-27 20:43:55,159 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741889_1065 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741889
2021-05-27 20:43:55,160 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741890_1066 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741890
2021-05-27 20:43:55,161 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741885_1061 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741885
2021-05-27 20:43:55,162 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741886_1062 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741886
2021-05-27 20:43:55,163 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741887_1063 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741887
2021-05-27 20:48:22,823 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-27 20:48:26,068 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 20:48:26,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-27 20:52:29,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/169.254.148.169
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 20:52:29,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 20:52:29,879 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 20:52:29,941 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 20:52:29,942 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 20:52:29,947 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 20:52:29,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-27 20:52:29,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 20:52:30,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 20:52:30,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 20:52:30,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 20:52:30,110 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 20:52:30,117 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 20:52:30,122 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 20:52:30,127 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 20:52:30,129 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 20:52:30,129 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 20:52:30,129 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 20:52:30,176 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 61312
2021-05-27 20:52:30,176 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 20:52:30,315 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:61312
2021-05-27 20:52:30,456 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 20:52:30,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 20:52:30,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 20:52:34,685 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 20:52:34,698 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 20:52:34,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 20:52:34,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 20:52:34,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 20:52:34,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/169.254.148.169:9000 starting to offer service
2021-05-27 20:52:34,795 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 20:52:34,795 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 20:52:54,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 0 time(s); maxRetries=45
2021-05-27 20:53:14,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 1 time(s); maxRetries=45
2021-05-27 20:53:34,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 2 time(s); maxRetries=45
2021-05-27 20:53:54,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 3 time(s); maxRetries=45
2021-05-27 20:54:14,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 4 time(s); maxRetries=45
2021-05-27 20:54:34,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 5 time(s); maxRetries=45
2021-05-27 20:54:54,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 6 time(s); maxRetries=45
2021-05-27 20:55:14,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 7 time(s); maxRetries=45
2021-05-27 20:55:34,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 8 time(s); maxRetries=45
2021-05-27 20:55:54,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 9 time(s); maxRetries=45
2021-05-27 20:56:14,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 10 time(s); maxRetries=45
2021-05-27 20:56:34,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 11 time(s); maxRetries=45
2021-05-27 20:56:54,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 12 time(s); maxRetries=45
2021-05-27 20:57:14,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 13 time(s); maxRetries=45
2021-05-27 20:57:34,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 14 time(s); maxRetries=45
2021-05-27 20:57:55,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 15 time(s); maxRetries=45
2021-05-27 20:58:15,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 16 time(s); maxRetries=45
2021-05-27 20:58:35,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 17 time(s); maxRetries=45
2021-05-27 20:58:55,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/169.254.148.169:9000. Already tried 18 time(s); maxRetries=45
2021-05-27 20:59:03,251 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 20:59:03,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/169.254.148.169
************************************************************/
2021-05-27 21:00:39,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 21:00:39,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 21:00:40,157 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 21:00:40,217 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 21:00:40,218 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-27 21:00:40,223 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-27 21:00:40,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-27 21:00:40,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-27 21:00:40,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-27 21:00:40,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-27 21:00:40,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-27 21:00:40,351 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 21:00:40,362 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 21:00:40,367 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-27 21:00:40,372 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 21:00:40,373 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-27 21:00:40,373 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 21:00:40,374 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 21:00:40,385 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 61813
2021-05-27 21:00:40,385 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 21:00:40,517 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:61813
2021-05-27 21:00:40,628 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-27 21:00:40,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-27 21:00:40,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-27 21:00:45,849 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 21:00:45,864 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-27 21:00:45,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-27 21:00:45,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-27 21:00:45,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-27 21:00:45,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-27 21:00:45,945 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 21:00:45,946 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-27 21:00:46,414 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 24669@DESKTOP-TSQQRSN
2021-05-27 21:00:46,459 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-600518186-127.0.1.1-1622100536332
2021-05-27 21:00:46,459 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332
2021-05-27 21:00:46,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=791526008;bpid=BP-600518186-127.0.1.1-1622100536332;lv=-56;nsInfo=lv=-63;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0;bpid=BP-600518186-127.0.1.1-1622100536332;dnuuid=92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 21:00:46,508 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12
2021-05-27 21:00:46,508 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-27 21:00:46,535 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-27 21:00:46,536 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-600518186-127.0.1.1-1622100536332
2021-05-27 21:00:46,536 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 21:00:46,598 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-600518186-127.0.1.1-1622100536332 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 61ms
2021-05-27 21:00:46,598 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-600518186-127.0.1.1-1622100536332: 62ms
2021-05-27 21:00:46,598 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-27 21:00:46,605 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 6ms
2021-05-27 21:00:46,605 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 7ms
2021-05-27 21:00:46,791 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12): no suitable block pools found to scan.  Waiting 1794509440 ms.
2021-05-27 21:00:46,793 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622125996793 with interval 21600000
2021-05-27 21:00:46,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-05-27 21:00:46,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-05-27 21:00:46,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-27 21:00:47,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=578
2021-05-27 21:00:47,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-27 21:00:47,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x29ae9681b244,  containing 1 storage report(s), of which we sent 1. The reports had 40 total blocks and used 1 RPC(s). This took 4 msec to generate and 87 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-27 21:00:47,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:28:11,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 11:28:11,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 11:28:12,003 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 11:28:12,087 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 11:28:12,087 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 11:28:12,135 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 11:28:12,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-29 11:28:12,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 11:28:12,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 11:28:12,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 11:28:12,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 11:28:12,541 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 11:28:12,549 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 11:28:12,555 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 11:28:12,560 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 11:28:12,561 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 11:28:12,562 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 11:28:12,562 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 11:28:12,573 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 61994
2021-05-29 11:28:12,573 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 11:28:12,717 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:61994
2021-05-29 11:28:13,008 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 11:28:13,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 11:28:13,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 11:28:13,377 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 11:28:13,393 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 11:28:13,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 11:28:13,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 11:28:13,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 11:28:13,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-29 11:28:13,507 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 11:28:13,507 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 11:28:14,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:28:15,084 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 6919@DESKTOP-TSQQRSN.localdomain
2021-05-29 11:28:15,160 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:28:15,160 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:28:15,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=791526008;bpid=BP-600518186-127.0.1.1-1622100536332;lv=-56;nsInfo=lv=-63;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0;bpid=BP-600518186-127.0.1.1-1622100536332;dnuuid=92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-29 11:28:15,233 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12
2021-05-29 11:28:15,233 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-29 11:28:15,268 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-29 11:28:15,269 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:28:15,269 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 11:28:15,476 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-600518186-127.0.1.1-1622100536332 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 207ms
2021-05-29 11:28:15,476 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-600518186-127.0.1.1-1622100536332: 207ms
2021-05-29 11:28:15,477 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 11:28:15,485 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 8ms
2021-05-29 11:28:15,485 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 9ms
2021-05-29 11:28:15,840 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12): no suitable block pools found to scan.  Waiting 1656060391 ms.
2021-05-29 11:28:15,842 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622262610842 with interval 21600000
2021-05-29 11:28:15,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 beginning handshake with NN
2021-05-29 11:28:15,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 successfully registered with NN
2021-05-29 11:28:15,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-29 11:28:16,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000 trying to claim ACTIVE state with txid=581
2021-05-29 11:28:16,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-29 11:28:16,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x12e093c313c,  containing 1 storage report(s), of which we sent 1. The reports had 40 total blocks and used 1 RPC(s). This took 6 msec to generate and 110 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-29 11:28:16,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:32:25,289 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN.localdomain/127.0.1.1"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-29 11:32:28,482 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 11:32:28,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-29 11:33:24,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 11:33:24,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 11:33:25,304 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 11:33:25,370 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 11:33:25,370 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 11:33:25,374 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 11:33:25,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-29 11:33:25,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 11:33:25,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 11:33:25,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 11:33:25,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 11:33:25,491 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 11:33:25,498 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 11:33:25,503 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 11:33:25,507 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 11:33:25,509 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 11:33:25,509 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 11:33:25,509 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 11:33:25,521 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 52272
2021-05-29 11:33:25,521 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 11:33:25,629 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:52272
2021-05-29 11:33:25,736 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 11:33:25,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 11:33:25,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 11:33:25,942 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 11:33:25,958 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 11:33:25,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 11:33:25,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 11:33:26,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 11:33:26,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-29 11:33:26,024 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 11:33:26,024 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 11:33:26,307 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 8801@DESKTOP-TSQQRSN.localdomain
2021-05-29 11:33:26,350 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:33:26,350 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:33:26,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=791526008;bpid=BP-600518186-127.0.1.1-1622100536332;lv=-56;nsInfo=lv=-63;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0;bpid=BP-600518186-127.0.1.1-1622100536332;dnuuid=92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-29 11:33:26,382 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12
2021-05-29 11:33:26,382 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-29 11:33:26,420 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-29 11:33:26,420 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:33:26,421 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 11:33:26,427 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current: 3305472
2021-05-29 11:33:26,429 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-600518186-127.0.1.1-1622100536332 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 9ms
2021-05-29 11:33:26,429 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-600518186-127.0.1.1-1622100536332: 9ms
2021-05-29 11:33:26,430 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 11:33:26,435 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 5ms
2021-05-29 11:33:26,436 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 6ms
2021-05-29 11:33:26,600 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12): no suitable block pools found to scan.  Waiting 1655749631 ms.
2021-05-29 11:33:26,602 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622274340602 with interval 21600000
2021-05-29 11:33:26,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 beginning handshake with NN
2021-05-29 11:33:26,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 successfully registered with NN
2021-05-29 11:33:26,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-29 11:33:26,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000 trying to claim ACTIVE state with txid=582
2021-05-29 11:33:26,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-29 11:33:26,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1765b0d90d0,  containing 1 storage report(s), of which we sent 1. The reports had 40 total blocks and used 1 RPC(s). This took 4 msec to generate and 62 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-29 11:33:26,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:34:05,691 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN.localdomain/127.0.1.1"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-29 11:34:09,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:34:10,290 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 11:34:10,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-29 11:38:09,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 11:38:09,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 11:38:10,007 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 11:38:10,066 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 11:38:10,067 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 11:38:10,071 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 11:38:10,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN.localdomain
2021-05-29 11:38:10,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 11:38:10,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 11:38:10,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 11:38:10,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 11:38:10,188 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 11:38:10,194 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 11:38:10,200 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 11:38:10,205 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 11:38:10,207 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 11:38:10,207 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 11:38:10,207 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 11:38:10,220 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 54616
2021-05-29 11:38:10,220 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 11:38:10,327 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:54616
2021-05-29 11:38:10,427 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 11:38:10,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 11:38:10,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 11:38:11,754 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 11:38:11,767 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 11:38:11,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 11:38:11,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 11:38:11,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 11:38:11,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/127.0.1.1:9000 starting to offer service
2021-05-29 11:38:11,835 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 11:38:11,835 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 11:38:12,119 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 10594@DESKTOP-TSQQRSN.localdomain
2021-05-29 11:38:12,161 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:38:12,161 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:38:12,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=791526008;bpid=BP-600518186-127.0.1.1-1622100536332;lv=-56;nsInfo=lv=-63;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0;bpid=BP-600518186-127.0.1.1-1622100536332;dnuuid=92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-29 11:38:12,193 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12
2021-05-29 11:38:12,193 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-29 11:38:12,219 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-29 11:38:12,219 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:38:12,220 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 11:38:12,228 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current: 3305472
2021-05-29 11:38:12,230 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-600518186-127.0.1.1-1622100536332 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 9ms
2021-05-29 11:38:12,230 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-600518186-127.0.1.1-1622100536332: 11ms
2021-05-29 11:38:12,230 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 11:38:12,237 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 6ms
2021-05-29 11:38:12,237 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 7ms
2021-05-29 11:38:12,404 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12): no suitable block pools found to scan.  Waiting 1655463827 ms.
2021-05-29 11:38:12,406 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622275285406 with interval 21600000
2021-05-29 11:38:12,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 beginning handshake with NN
2021-05-29 11:38:12,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/127.0.1.1:9000 successfully registered with NN
2021-05-29 11:38:12,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-29 11:38:12,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000 trying to claim ACTIVE state with txid=583
2021-05-29 11:38:12,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-29 11:38:12,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1b8e705282c,  containing 1 storage report(s), of which we sent 1. The reports had 40 total blocks and used 1 RPC(s). This took 4 msec to generate and 55 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-29 11:38:12,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:38:45,498 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN.localdomain/127.0.1.1"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-29 11:38:49,046 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 11:38:49,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-29 11:45:10,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 11:45:10,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 11:45:11,058 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 11:45:11,119 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 11:45:11,119 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 11:45:11,124 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 11:45:11,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-29 11:45:11,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 11:45:11,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 11:45:11,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 11:45:11,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 11:45:11,246 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 11:45:11,253 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 11:45:11,258 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 11:45:11,263 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 11:45:11,264 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 11:45:11,264 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 11:45:11,264 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 11:45:11,276 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 49534
2021-05-29 11:45:11,276 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 11:45:11,384 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:49534
2021-05-29 11:45:11,492 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 11:45:11,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 11:45:11,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 11:45:11,869 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 11:45:11,885 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 11:45:11,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 11:45:11,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 11:45:11,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 11:45:11,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-29 11:45:11,970 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 11:45:11,970 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 11:45:12,341 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 12526@DESKTOP-TSQQRSN
2021-05-29 11:45:12,387 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:45:12,388 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:45:12,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=791526008;bpid=BP-600518186-127.0.1.1-1622100536332;lv=-56;nsInfo=lv=-63;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0;bpid=BP-600518186-127.0.1.1-1622100536332;dnuuid=92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-29 11:45:12,423 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12
2021-05-29 11:45:12,423 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-29 11:45:12,456 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-29 11:45:12,457 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:45:12,457 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 11:45:12,464 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current: 3305472
2021-05-29 11:45:12,466 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-600518186-127.0.1.1-1622100536332 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 9ms
2021-05-29 11:45:12,467 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-600518186-127.0.1.1-1622100536332: 10ms
2021-05-29 11:45:12,467 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 11:45:12,473 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-600518186-127.0.1.1-1622100536332 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 6ms
2021-05-29 11:45:12,473 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 7ms
2021-05-29 11:45:12,639 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12): no suitable block pools found to scan.  Waiting 1655043592 ms.
2021-05-29 11:45:12,641 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622279242641 with interval 21600000
2021-05-29 11:45:12,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-05-29 11:45:12,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-05-29 11:45:12,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-29 11:45:12,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=584
2021-05-29 11:45:12,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-600518186-127.0.1.1-1622100536332 (Datanode Uuid 92478c8c-8e85-4c7e-8076-628dcc214550) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 11:45:12,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x21abf921414,  containing 1 storage report(s), of which we sent 1. The reports had 40 total blocks and used 1 RPC(s). This took 4 msec to generate and 81 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-29 11:45:12,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-600518186-127.0.1.1-1622100536332
2021-05-29 11:49:01,257 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741892_1068 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741892 for deletion
2021-05-29 11:49:01,258 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741882_1058 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741882 for deletion
2021-05-29 11:49:01,259 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741892_1068 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741892
2021-05-29 11:49:01,259 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-600518186-127.0.1.1-1622100536332 blk_1073741882_1058 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-600518186-127.0.1.1-1622100536332/current/finalized/subdir0/subdir0/blk_1073741882
2021-05-29 11:56:35,307 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-29 11:56:39,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:40,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:41,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:42,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:43,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:44,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:45,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:46,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:47,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:48,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:48,414 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From DESKTOP-TSQQRSN/10.191.53.85 to DESKTOP-TSQQRSN:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 8 more
2021-05-29 11:56:49,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:50,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:51,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:52,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:53,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:54,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:55,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:56,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:57,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:58,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:56:58,515 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From DESKTOP-TSQQRSN/10.191.53.85 to DESKTOP-TSQQRSN:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 8 more
2021-05-29 11:56:59,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:00,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:01,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:02,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:03,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:04,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:05,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:06,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:07,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:08,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:08,642 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From DESKTOP-TSQQRSN/10.191.53.85 to DESKTOP-TSQQRSN:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 8 more
2021-05-29 11:57:09,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:10,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:11,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:12,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:13,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:14,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:15,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:16,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:17,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:18,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:18,730 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From DESKTOP-TSQQRSN/10.191.53.85 to DESKTOP-TSQQRSN:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 8 more
2021-05-29 11:57:19,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:20,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:21,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:22,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:23,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:24,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:25,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:26,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:27,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:28,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:28,854 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From DESKTOP-TSQQRSN/10.191.53.85 to DESKTOP-TSQQRSN:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 8 more
2021-05-29 11:57:29,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:30,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:31,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:32,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:33,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:34,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:35,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:36,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:37,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:38,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:38,943 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From DESKTOP-TSQQRSN/10.191.53.85 to DESKTOP-TSQQRSN:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 8 more
2021-05-29 11:57:39,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:40,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:41,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:42,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:43,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:44,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:45,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:47,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:48,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:49,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:49,028 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From DESKTOP-TSQQRSN/10.191.53.85 to DESKTOP-TSQQRSN:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 8 more
2021-05-29 11:57:50,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:51,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:52,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:53,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:54,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:55,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:56,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:57,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:58,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:59,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:57:59,119 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From DESKTOP-TSQQRSN/10.191.53.85 to DESKTOP-TSQQRSN:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 8 more
2021-05-29 11:58:00,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:01,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:02,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:03,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:04,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:05,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:06,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:07,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:08,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:09,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:09,196 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From DESKTOP-TSQQRSN/10.191.53.85 to DESKTOP-TSQQRSN:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 8 more
2021-05-29 11:58:10,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:11,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:12,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:13,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:14,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:15,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:16,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:17,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:18,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:19,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:19,284 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From DESKTOP-TSQQRSN/10.191.53.85 to DESKTOP-TSQQRSN:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 8 more
2021-05-29 11:58:20,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:21,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:22,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:23,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:24,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:25,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:26,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:27,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:28,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:29,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:29,382 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From DESKTOP-TSQQRSN/10.191.53.85 to DESKTOP-TSQQRSN:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 8 more
2021-05-29 11:58:30,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:31,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:32,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:33,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:34,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:35,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:36,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:37,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:38,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:39,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:39,513 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From DESKTOP-TSQQRSN/10.191.53.85 to DESKTOP-TSQQRSN:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 8 more
2021-05-29 11:58:40,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:41,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:42,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:43,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:44,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:45,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:46,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:47,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:48,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 11:58:49,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:05:56,511 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-29 12:06:00,337 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 12:06:00,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 12:14:39,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 12:14:39,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 12:14:39,975 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 12:14:40,051 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 12:14:40,052 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 12:14:40,057 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 12:14:40,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-29 12:14:40,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 12:14:40,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 12:14:40,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 12:14:40,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 12:14:40,277 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 12:14:40,289 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 12:14:40,298 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 12:14:40,309 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 12:14:40,312 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 12:14:40,312 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 12:14:40,312 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 12:14:40,327 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 52798
2021-05-29 12:14:40,327 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 12:14:40,509 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:52798
2021-05-29 12:14:40,774 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 12:14:40,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 12:14:40,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 12:14:41,093 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 12:14:41,107 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 12:14:41,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 12:14:41,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 12:14:41,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 12:14:41,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-29 12:14:41,202 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 12:14:41,202 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 12:14:44,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:14:47,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:14:50,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:14:53,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:14:56,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:14:59,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:15:02,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:15:05,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:15:08,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:15:11,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:15:13,858 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:15:21,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:15:24,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:15:28,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:15:31,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:15:34,061 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 12:15:34,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 12:31:12,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 12:31:12,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 12:31:12,976 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 12:31:13,036 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 12:31:13,036 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 12:31:13,041 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 12:31:13,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-29 12:31:13,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 12:31:13,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 12:31:13,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 12:31:13,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 12:31:13,164 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 12:31:13,171 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 12:31:13,176 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 12:31:13,181 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 12:31:13,183 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 12:31:13,183 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 12:31:13,183 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 12:31:13,195 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 64268
2021-05-29 12:31:13,195 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 12:31:13,306 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:64268
2021-05-29 12:31:13,414 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 12:31:13,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 12:31:13,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 12:31:13,645 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 12:31:13,664 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 12:31:13,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 12:31:13,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 12:31:13,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 12:31:13,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-29 12:31:13,733 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 12:31:13,733 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 12:31:16,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:31:19,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:31:22,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:31:25,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:31:29,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:31:32,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:31:35,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:31:38,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:31:41,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:31:44,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:31:46,233 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:31:54,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:31:57,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:00,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:03,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:06,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:09,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:12,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:15,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:18,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:21,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:23,689 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:32:31,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:34,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:37,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:40,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:43,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:46,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:49,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:52,921 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:55,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:32:58,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:00,986 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:33:09,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:12,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:15,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:18,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:21,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:24,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:27,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:30,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:33,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:36,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:38,508 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:33:46,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:49,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:52,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:55,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:33:58,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:01,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:04,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:07,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:10,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:13,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:15,913 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:34:23,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:26,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:30,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:33,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:36,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:39,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:42,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:45,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:48,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:51,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:34:53,329 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:35:01,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:04,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:07,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:10,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:13,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:16,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:19,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:22,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:25,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:28,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:30,903 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:35:38,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:42,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:45,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:48,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:51,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:54,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:35:57,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:36:00,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:36:03,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:36:03,981 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 12:36:03,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 12:37:02,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 12:37:02,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 12:37:03,014 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 12:37:03,100 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 12:37:03,100 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 12:37:03,107 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 12:37:03,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-29 12:37:03,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 12:37:03,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 12:37:03,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 12:37:03,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 12:37:03,271 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 12:37:03,286 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 12:37:03,295 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 12:37:03,304 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 12:37:03,307 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 12:37:03,307 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 12:37:03,307 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 12:37:03,324 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 52522
2021-05-29 12:37:03,324 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 12:37:03,482 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:52522
2021-05-29 12:37:03,600 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 12:37:03,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 12:37:03,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 12:37:03,878 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 12:37:03,905 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 12:37:03,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 12:37:03,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 12:37:03,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 12:37:04,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-29 12:37:04,011 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 12:37:04,011 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 12:37:07,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:10,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:13,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:16,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:19,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:22,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:25,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:28,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:31,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:34,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:36,746 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:37:44,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:47,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:50,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:53,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:56,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:37:59,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:03,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:06,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:09,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:12,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:14,228 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:38:22,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:25,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:28,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:31,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:34,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:37,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:40,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:43,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:46,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:49,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:38:51,725 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:38:59,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:02,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:05,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:08,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:11,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:15,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:18,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:21,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:24,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:27,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:29,220 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:39:37,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:40,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:43,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:46,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:49,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:52,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:55,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:39:58,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:01,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:04,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:06,608 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:40:14,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:17,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:20,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:23,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:26,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:29,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:32,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:35,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:38,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:41,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:44,043 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:40:52,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:55,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:40:58,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:01,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:04,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:07,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:10,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:13,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:16,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:19,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:21,447 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:41:29,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:32,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:35,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:38,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:41,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:44,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:47,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:50,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:53,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:56,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:41:58,938 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:42:07,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:10,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:13,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:16,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:19,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:22,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:25,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:28,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:31,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:34,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:36,419 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:42:44,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:47,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:50,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:53,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:56,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:42:59,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:02,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:05,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:08,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:11,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:13,812 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 12:43:21,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:24,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:27,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:30,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:34,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:37,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:40,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:43,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:46,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:49,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:43:49,569 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 12:43:49,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 12:48:24,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 12:48:24,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 12:48:25,320 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 12:48:25,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 12:48:25,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 12:48:25,417 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 12:48:25,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-29 12:48:25,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 12:48:25,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 12:48:25,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 12:48:25,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 12:48:25,578 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 12:48:25,588 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 12:48:25,597 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 12:48:25,602 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 12:48:25,603 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 12:48:25,603 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 12:48:25,604 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 12:48:25,620 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 54088
2021-05-29 12:48:25,620 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 12:48:25,794 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:54088
2021-05-29 12:48:25,991 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 12:48:26,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 12:48:26,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 12:48:26,670 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 12:48:26,690 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 12:48:26,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 12:48:26,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 12:48:26,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 12:48:26,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-29 12:48:26,784 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 12:48:26,784 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 12:48:30,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:48:33,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:48:36,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:48:39,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 12:48:41,182 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 12:48:41,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 13:07:39,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 13:07:39,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 13:07:40,343 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 13:07:40,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 13:07:40,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 13:07:40,463 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 13:07:40,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-29 13:07:40,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 13:07:40,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 13:07:40,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 13:07:40,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 13:07:40,642 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 13:07:40,649 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 13:07:40,654 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 13:07:40,658 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 13:07:40,660 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 13:07:40,660 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 13:07:40,660 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 13:07:40,670 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 49822
2021-05-29 13:07:40,670 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 13:07:40,810 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:49822
2021-05-29 13:07:41,047 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 13:07:41,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 13:07:41,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 13:07:41,330 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 13:07:41,347 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 13:07:41,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 13:07:41,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 13:07:41,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 13:07:41,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-29 13:07:41,492 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 13:07:41,492 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 13:07:41,987 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 1012@DESKTOP-TSQQRSN
2021-05-29 13:07:41,988 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /opt/hadoop-2.7.2/data/tmp/dfs/data is not formatted for BP-1542253369-10.191.53.85-1622264819009
2021-05-29 13:07:41,988 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-05-29 13:07:42,020 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1542253369-10.191.53.85-1622264819009
2021-05-29 13:07:42,020 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009
2021-05-29 13:07:42,021 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009 is not formatted for BP-1542253369-10.191.53.85-1622264819009
2021-05-29 13:07:42,021 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-05-29 13:07:42,021 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1542253369-10.191.53.85-1622264819009 directory /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current
2021-05-29 13:07:42,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2005162102;bpid=BP-1542253369-10.191.53.85-1622264819009;lv=-56;nsInfo=lv=-63;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0;bpid=BP-1542253369-10.191.53.85-1622264819009;dnuuid=null
2021-05-29 13:07:42,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-05-29 13:07:42,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-77177884-7e39-4105-ae4c-bdc787c546af
2021-05-29 13:07:42,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-29 13:07:42,080 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-29 13:07:42,081 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-29 13:07:42,081 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 13:07:42,139 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1542253369-10.191.53.85-1622264819009 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 58ms
2021-05-29 13:07:42,140 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1542253369-10.191.53.85-1622264819009: 59ms
2021-05-29 13:07:42,140 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 13:07:42,141 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 1ms
2021-05-29 13:07:42,141 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-05-29 13:07:42,433 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data
2021-05-29 13:07:42,434 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): finished scanning block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-29 13:07:42,435 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622277974435 with interval 21600000
2021-05-29 13:07:42,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-05-29 13:07:42,477 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): no suitable block pools found to scan.  Waiting 1814399956 ms.
2021-05-29 13:07:42,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-05-29 13:07:42,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-29 13:07:42,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=1
2021-05-29 13:07:42,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 13:07:42,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x7e10854308,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 80 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-29 13:07:42,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-29 13:08:50,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741825_1001 src: /10.191.53.85:65276 dest: /10.191.53.85:50010
2021-05-29 13:08:50,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:65276, dest: /10.191.53.85:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_867993242_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741825_1001, duration: 50273000
2021-05-29 13:08:50,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 13:09:15,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741826_1002 src: /10.191.53.85:52679 dest: /10.191.53.85:50010
2021-05-29 13:09:15,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:52679, dest: /10.191.53.85:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1939157955_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741826_1002, duration: 68335700
2021-05-29 13:09:15,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 13:09:15,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741827_1003 src: /10.191.53.85:52680 dest: /10.191.53.85:50010
2021-05-29 13:09:15,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:52680, dest: /10.191.53.85:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1939157955_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741827_1003, duration: 5556400
2021-05-29 13:09:15,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 13:09:15,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741828_1004 src: /10.191.53.85:52681 dest: /10.191.53.85:50010
2021-05-29 13:09:15,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:52681, dest: /10.191.53.85:50010, bytes: 29, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1939157955_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741828_1004, duration: 1326000
2021-05-29 13:09:15,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 13:09:16,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741829_1005 src: /10.191.53.85:52682 dest: /10.191.53.85:50010
2021-05-29 13:09:16,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:52682, dest: /10.191.53.85:50010, bytes: 97435, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1939157955_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741829_1005, duration: 8244700
2021-05-29 13:09:16,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 13:09:25,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741830_1006 src: /10.191.53.85:49426 dest: /10.191.53.85:50010
2021-05-29 13:09:25,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:49426, dest: /10.191.53.85:50010, bytes: 115858, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-594974019_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741830_1006, duration: 33189800
2021-05-29 13:09:25,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 13:09:30,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741831_1007 src: /10.191.53.85:51718 dest: /10.191.53.85:50010
2021-05-29 13:09:37,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741832_1008 src: /10.191.53.85:50938 dest: /10.191.53.85:50010
2021-05-29 13:09:37,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:50938, dest: /10.191.53.85:50010, bytes: 50, op: HDFS_WRITE, cliID: DFSClient_attempt_1622264873807_0001_r_000000_0_-233333853_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741832_1008, duration: 84975600
2021-05-29 13:09:37,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 13:09:37,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:51718, dest: /10.191.53.85:50010, bytes: 33696, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-594974019_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741831_1007, duration: 7021644900
2021-05-29 13:09:37,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 13:09:37,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741833_1009 src: /10.191.53.85:49198 dest: /10.191.53.85:50010
2021-05-29 13:09:37,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:49198, dest: /10.191.53.85:50010, bytes: 347, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-594974019_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741833_1009, duration: 4630600
2021-05-29 13:09:37,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 13:09:37,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741834_1010 src: /10.191.53.85:49200 dest: /10.191.53.85:50010
2021-05-29 13:09:37,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:49200, dest: /10.191.53.85:50010, bytes: 33696, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-594974019_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741834_1010, duration: 4003100
2021-05-29 13:09:37,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 13:09:37,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741835_1011 src: /10.191.53.85:49201 dest: /10.191.53.85:50010
2021-05-29 13:09:37,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:49201, dest: /10.191.53.85:50010, bytes: 115858, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-594974019_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741835_1011, duration: 4242600
2021-05-29 13:09:37,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 13:09:42,825 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2021-05-29 13:09:42,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741827_1003 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2021-05-29 13:09:42,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741828_1004 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741828 for deletion
2021-05-29 13:09:42,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
2021-05-29 13:09:42,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2021-05-29 13:09:42,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741831_1007 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741831 for deletion
2021-05-29 13:09:42,827 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741826_1002 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741826
2021-05-29 13:09:42,828 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741827_1003 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741827
2021-05-29 13:09:42,828 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741828_1004 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741828
2021-05-29 13:09:42,829 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741829_1005 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741829
2021-05-29 13:09:42,829 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741830_1006 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741830
2021-05-29 13:09:42,829 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741831_1007 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741831
2021-05-29 13:09:44,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741836_1012 src: /10.191.53.85:51372 dest: /10.191.53.85:50010
2021-05-29 13:09:44,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:51372, dest: /10.191.53.85:50010, bytes: 46928, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1797568578_93, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741836_1012, duration: 31501200
2021-05-29 13:09:44,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 13:09:57,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2021-05-29 13:09:57,842 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741833_1009 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741833
2021-05-29 14:06:10,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 14:06:10,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 14:06:11,330 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 14:06:11,387 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 14:06:11,387 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 14:06:11,393 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 14:06:11,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-29 14:06:11,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 14:06:11,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 14:06:11,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 14:06:11,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 14:06:11,559 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 14:06:11,566 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 14:06:11,571 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 14:06:11,575 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 14:06:11,576 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 14:06:11,577 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 14:06:11,577 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 14:06:11,587 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 60571
2021-05-29 14:06:11,587 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 14:06:11,752 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:60571
2021-05-29 14:06:11,971 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 14:06:12,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 14:06:12,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 14:06:12,219 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 14:06:12,234 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 14:06:12,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 14:06:12,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 14:06:12,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 14:06:12,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-29 14:06:12,337 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 14:06:12,337 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 14:06:12,911 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 1078@DESKTOP-TSQQRSN
2021-05-29 14:06:12,954 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1542253369-10.191.53.85-1622264819009
2021-05-29 14:06:12,955 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009
2021-05-29 14:06:12,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2005162102;bpid=BP-1542253369-10.191.53.85-1622264819009;lv=-56;nsInfo=lv=-63;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0;bpid=BP-1542253369-10.191.53.85-1622264819009;dnuuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-05-29 14:06:13,004 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-77177884-7e39-4105-ae4c-bdc787c546af
2021-05-29 14:06:13,004 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-29 14:06:13,030 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-29 14:06:13,031 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-29 14:06:13,031 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 14:06:13,149 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1542253369-10.191.53.85-1622264819009 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 118ms
2021-05-29 14:06:13,149 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1542253369-10.191.53.85-1622264819009: 119ms
2021-05-29 14:06:13,150 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 14:06:13,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 7ms
2021-05-29 14:06:13,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 8ms
2021-05-29 14:06:13,547 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): no suitable block pools found to scan.  Waiting 1810888886 ms.
2021-05-29 14:06:13,549 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622289059549 with interval 21600000
2021-05-29 14:06:13,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-05-29 14:06:13,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-05-29 14:06:13,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-29 14:06:13,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=123
2021-05-29 14:06:13,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 14:06:13,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1b5586d13fc,  containing 1 storage report(s), of which we sent 1. The reports had 5 total blocks and used 1 RPC(s). This took 4 msec to generate and 156 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-29 14:06:13,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-29 14:10:44,115 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-29 14:10:49,132 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 14:10:49,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 14:29:51,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 14:29:51,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 14:29:52,106 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 14:29:52,167 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 14:29:52,167 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 14:29:52,172 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 14:29:52,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-29 14:29:52,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 14:29:52,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 14:29:52,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 14:29:52,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 14:29:52,282 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 14:29:52,291 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 14:29:52,299 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 14:29:52,306 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 14:29:52,307 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 14:29:52,307 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 14:29:52,307 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 14:29:52,319 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 51860
2021-05-29 14:29:52,319 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 14:29:52,433 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:51860
2021-05-29 14:29:52,544 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 14:29:52,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 14:29:52,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 14:29:52,736 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 14:29:52,749 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 14:29:52,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 14:29:52,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 14:29:52,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 14:29:52,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-29 14:29:52,809 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 14:29:52,809 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 14:29:53,106 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 3517@DESKTOP-TSQQRSN
2021-05-29 14:29:53,148 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1542253369-10.191.53.85-1622264819009
2021-05-29 14:29:53,148 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009
2021-05-29 14:29:53,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2005162102;bpid=BP-1542253369-10.191.53.85-1622264819009;lv=-56;nsInfo=lv=-63;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0;bpid=BP-1542253369-10.191.53.85-1622264819009;dnuuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-05-29 14:29:53,182 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-77177884-7e39-4105-ae4c-bdc787c546af
2021-05-29 14:29:53,183 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-29 14:29:53,215 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-29 14:29:53,215 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-29 14:29:53,216 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 14:29:53,248 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1542253369-10.191.53.85-1622264819009 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 33ms
2021-05-29 14:29:53,249 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1542253369-10.191.53.85-1622264819009: 33ms
2021-05-29 14:29:53,249 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 14:29:53,252 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 3ms
2021-05-29 14:29:53,252 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 4ms
2021-05-29 14:29:53,420 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): no suitable block pools found to scan.  Waiting 1809469013 ms.
2021-05-29 14:29:53,422 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622276363422 with interval 21600000
2021-05-29 14:29:53,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-05-29 14:29:53,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-05-29 14:29:53,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-29 14:29:53,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=124
2021-05-29 14:29:53,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 14:29:53,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2ffecab0fc4,  containing 1 storage report(s), of which we sent 1. The reports had 5 total blocks and used 1 RPC(s). This took 4 msec to generate and 50 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-29 14:29:53,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-29 14:30:14,488 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-29 14:30:19,168 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 14:30:19,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 14:32:08,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 14:32:08,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 14:32:09,349 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 14:32:09,407 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 14:32:09,407 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 14:32:09,412 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 14:32:09,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-29 14:32:09,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 14:32:09,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 14:32:09,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 14:32:09,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 14:32:09,798 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 14:32:09,806 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 14:32:09,811 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 14:32:09,816 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 14:32:09,817 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 14:32:09,817 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 14:32:09,817 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 14:32:09,830 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 51888
2021-05-29 14:32:09,830 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 14:32:09,943 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:51888
2021-05-29 14:32:10,036 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 14:32:10,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 14:32:10,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 14:32:10,333 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 14:32:10,356 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 14:32:10,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 14:32:10,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 14:32:10,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 14:32:10,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-29 14:32:10,428 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 14:32:10,428 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 14:32:10,716 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 4418@DESKTOP-TSQQRSN
2021-05-29 14:32:10,754 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1542253369-10.191.53.85-1622264819009
2021-05-29 14:32:10,755 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009
2021-05-29 14:32:10,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2005162102;bpid=BP-1542253369-10.191.53.85-1622264819009;lv=-56;nsInfo=lv=-63;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0;bpid=BP-1542253369-10.191.53.85-1622264819009;dnuuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-05-29 14:32:10,785 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-77177884-7e39-4105-ae4c-bdc787c546af
2021-05-29 14:32:10,786 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-29 14:32:10,812 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-29 14:32:10,813 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-29 14:32:10,813 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 14:32:10,820 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current: 262144
2021-05-29 14:32:10,822 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1542253369-10.191.53.85-1622264819009 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 8ms
2021-05-29 14:32:10,822 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1542253369-10.191.53.85-1622264819009: 10ms
2021-05-29 14:32:10,823 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 14:32:10,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 4ms
2021-05-29 14:32:10,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 4ms
2021-05-29 14:32:10,993 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): no suitable block pools found to scan.  Waiting 1809331440 ms.
2021-05-29 14:32:10,995 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622279091995 with interval 21600000
2021-05-29 14:32:10,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-05-29 14:32:11,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-05-29 14:32:11,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-29 14:32:11,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=125
2021-05-29 14:32:11,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 14:32:11,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x31ff474eb38,  containing 1 storage report(s), of which we sent 1. The reports had 5 total blocks and used 1 RPC(s). This took 4 msec to generate and 54 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-29 14:32:11,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-29 14:41:57,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741837_1013 src: /10.191.53.85:59965 dest: /10.191.53.85:50010
2021-05-29 14:41:58,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59965, dest: /10.191.53.85:50010, bytes: 4436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741837_1013, duration: 39167200
2021-05-29 14:41:58,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741838_1014 src: /10.191.53.85:59968 dest: /10.191.53.85:50010
2021-05-29 14:41:58,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59968, dest: /10.191.53.85:50010, bytes: 1335, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741838_1014, duration: 4153300
2021-05-29 14:41:58,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741839_1015 src: /10.191.53.85:59969 dest: /10.191.53.85:50010
2021-05-29 14:41:58,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59969, dest: /10.191.53.85:50010, bytes: 318, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741839_1015, duration: 2603200
2021-05-29 14:41:58,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741840_1016 src: /10.191.53.85:59970 dest: /10.191.53.85:50010
2021-05-29 14:41:58,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59970, dest: /10.191.53.85:50010, bytes: 989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741840_1016, duration: 2488700
2021-05-29 14:41:58,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741841_1017 src: /10.191.53.85:59971 dest: /10.191.53.85:50010
2021-05-29 14:41:58,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59971, dest: /10.191.53.85:50010, bytes: 3670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741841_1017, duration: 2575000
2021-05-29 14:41:58,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741842_1018 src: /10.191.53.85:59972 dest: /10.191.53.85:50010
2021-05-29 14:41:58,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59972, dest: /10.191.53.85:50010, bytes: 4264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741842_1018, duration: 2752800
2021-05-29 14:41:58,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741843_1019 src: /10.191.53.85:59973 dest: /10.191.53.85:50010
2021-05-29 14:41:58,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59973, dest: /10.191.53.85:50010, bytes: 2490, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741843_1019, duration: 2605300
2021-05-29 14:41:58,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741844_1020 src: /10.191.53.85:59974 dest: /10.191.53.85:50010
2021-05-29 14:41:58,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59974, dest: /10.191.53.85:50010, bytes: 2598, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741844_1020, duration: 2751300
2021-05-29 14:41:58,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741845_1021 src: /10.191.53.85:59975 dest: /10.191.53.85:50010
2021-05-29 14:41:58,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59975, dest: /10.191.53.85:50010, bytes: 9683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741845_1021, duration: 2579200
2021-05-29 14:41:58,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741846_1022 src: /10.191.53.85:59976 dest: /10.191.53.85:50010
2021-05-29 14:41:58,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59976, dest: /10.191.53.85:50010, bytes: 977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741846_1022, duration: 3038800
2021-05-29 14:41:58,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741847_1023 src: /10.191.53.85:59977 dest: /10.191.53.85:50010
2021-05-29 14:41:58,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59977, dest: /10.191.53.85:50010, bytes: 1449, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741847_1023, duration: 2954500
2021-05-29 14:41:58,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741847_1023, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741848_1024 src: /10.191.53.85:59978 dest: /10.191.53.85:50010
2021-05-29 14:41:58,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59978, dest: /10.191.53.85:50010, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741848_1024, duration: 3240100
2021-05-29 14:41:58,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741848_1024, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741849_1025 src: /10.191.53.85:59979 dest: /10.191.53.85:50010
2021-05-29 14:41:58,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59979, dest: /10.191.53.85:50010, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741849_1025, duration: 2642200
2021-05-29 14:41:58,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741849_1025, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741850_1026 src: /10.191.53.85:59980 dest: /10.191.53.85:50010
2021-05-29 14:41:58,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59980, dest: /10.191.53.85:50010, bytes: 620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741850_1026, duration: 2485000
2021-05-29 14:41:58,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741850_1026, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741851_1027 src: /10.191.53.85:59981 dest: /10.191.53.85:50010
2021-05-29 14:41:58,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59981, dest: /10.191.53.85:50010, bytes: 3518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741851_1027, duration: 3154300
2021-05-29 14:41:58,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741851_1027, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:58,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741852_1028 src: /10.191.53.85:59982 dest: /10.191.53.85:50010
2021-05-29 14:41:58,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59982, dest: /10.191.53.85:50010, bytes: 1527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741852_1028, duration: 2965800
2021-05-29 14:41:58,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741852_1028, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741853_1029 src: /10.191.53.85:59983 dest: /10.191.53.85:50010
2021-05-29 14:41:59,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59983, dest: /10.191.53.85:50010, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741853_1029, duration: 3135800
2021-05-29 14:41:59,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741853_1029, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741854_1030 src: /10.191.53.85:59984 dest: /10.191.53.85:50010
2021-05-29 14:41:59,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59984, dest: /10.191.53.85:50010, bytes: 5511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741854_1030, duration: 2797800
2021-05-29 14:41:59,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741854_1030, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741855_1031 src: /10.191.53.85:59985 dest: /10.191.53.85:50010
2021-05-29 14:41:59,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59985, dest: /10.191.53.85:50010, bytes: 11237, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741855_1031, duration: 3098900
2021-05-29 14:41:59,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741855_1031, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741856_1032 src: /10.191.53.85:59986 dest: /10.191.53.85:50010
2021-05-29 14:41:59,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59986, dest: /10.191.53.85:50010, bytes: 951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741856_1032, duration: 3582900
2021-05-29 14:41:59,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741856_1032, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741857_1033 src: /10.191.53.85:59987 dest: /10.191.53.85:50010
2021-05-29 14:41:59,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59987, dest: /10.191.53.85:50010, bytes: 1373, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741857_1033, duration: 1904000
2021-05-29 14:41:59,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741857_1033, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741858_1034 src: /10.191.53.85:59988 dest: /10.191.53.85:50010
2021-05-29 14:41:59,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59988, dest: /10.191.53.85:50010, bytes: 4113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741858_1034, duration: 1931200
2021-05-29 14:41:59,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741858_1034, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741859_1035 src: /10.191.53.85:59989 dest: /10.191.53.85:50010
2021-05-29 14:41:59,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59989, dest: /10.191.53.85:50010, bytes: 1122, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741859_1035, duration: 1907300
2021-05-29 14:41:59,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741859_1035, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741860_1036 src: /10.191.53.85:59990 dest: /10.191.53.85:50010
2021-05-29 14:41:59,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59990, dest: /10.191.53.85:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741860_1036, duration: 1722100
2021-05-29 14:41:59,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741860_1036, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741861_1037 src: /10.191.53.85:59991 dest: /10.191.53.85:50010
2021-05-29 14:41:59,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59991, dest: /10.191.53.85:50010, bytes: 2316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741861_1037, duration: 1862100
2021-05-29 14:41:59,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741861_1037, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741862_1038 src: /10.191.53.85:59993 dest: /10.191.53.85:50010
2021-05-29 14:41:59,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59993, dest: /10.191.53.85:50010, bytes: 2268, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741862_1038, duration: 3351000
2021-05-29 14:41:59,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741862_1038, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741863_1039 src: /10.191.53.85:59994 dest: /10.191.53.85:50010
2021-05-29 14:41:59,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59994, dest: /10.191.53.85:50010, bytes: 2250, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741863_1039, duration: 2503000
2021-05-29 14:41:59,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741863_1039, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741864_1040 src: /10.191.53.85:59995 dest: /10.191.53.85:50010
2021-05-29 14:41:59,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59995, dest: /10.191.53.85:50010, bytes: 4558, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741864_1040, duration: 2561600
2021-05-29 14:41:59,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741864_1040, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:41:59,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741865_1041 src: /10.191.53.85:59996 dest: /10.191.53.85:50010
2021-05-29 14:41:59,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59996, dest: /10.191.53.85:50010, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854206194_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741865_1041, duration: 2513100
2021-05-29 14:41:59,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741865_1041, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:43:03,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741866_1042 src: /10.191.53.85:60065 dest: /10.191.53.85:50010
2021-05-29 14:43:03,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60065, dest: /10.191.53.85:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-626930045_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741866_1042, duration: 38569300
2021-05-29 14:43:03,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741866_1042, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:43:03,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741867_1043 src: /10.191.53.85:60066 dest: /10.191.53.85:50010
2021-05-29 14:43:03,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60066, dest: /10.191.53.85:50010, bytes: 3764, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-626930045_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741867_1043, duration: 1920100
2021-05-29 14:43:03,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741867_1043, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:43:03,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741868_1044 src: /10.191.53.85:60067 dest: /10.191.53.85:50010
2021-05-29 14:43:03,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60067, dest: /10.191.53.85:50010, bytes: 670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-626930045_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741868_1044, duration: 1780900
2021-05-29 14:43:03,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741868_1044, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:43:03,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741869_1045 src: /10.191.53.85:60068 dest: /10.191.53.85:50010
2021-05-29 14:43:03,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60068, dest: /10.191.53.85:50010, bytes: 97412, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-626930045_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741869_1045, duration: 1587700
2021-05-29 14:43:03,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741869_1045, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:43:11,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741870_1046 src: /10.191.53.85:60088 dest: /10.191.53.85:50010
2021-05-29 14:43:11,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60088, dest: /10.191.53.85:50010, bytes: 115835, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1024477442_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741870_1046, duration: 30815300
2021-05-29 14:43:11,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741870_1046, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:43:21,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741871_1047 src: /10.191.53.85:60128 dest: /10.191.53.85:50010
2021-05-29 14:44:07,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741872_1048 src: /10.191.53.85:60299 dest: /10.191.53.85:50010
2021-05-29 14:44:07,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60299, dest: /10.191.53.85:50010, bytes: 37412, op: HDFS_WRITE, cliID: DFSClient_attempt_1622270333365_0001_r_000000_0_905241161_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741872_1048, duration: 61076600
2021-05-29 14:44:07,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741872_1048, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:44:07,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60128, dest: /10.191.53.85:50010, bytes: 221493, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1024477442_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741871_1047, duration: 45804646000
2021-05-29 14:44:07,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741871_1047, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:44:08,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741873_1049 src: /10.191.53.85:60303 dest: /10.191.53.85:50010
2021-05-29 14:44:08,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60303, dest: /10.191.53.85:50010, bytes: 351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1024477442_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741873_1049, duration: 2696700
2021-05-29 14:44:08,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741873_1049, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:44:08,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741874_1050 src: /10.191.53.85:60305 dest: /10.191.53.85:50010
2021-05-29 14:44:08,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60305, dest: /10.191.53.85:50010, bytes: 221493, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1024477442_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741874_1050, duration: 5370900
2021-05-29 14:44:08,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741874_1050, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:44:08,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741875_1051 src: /10.191.53.85:60306 dest: /10.191.53.85:50010
2021-05-29 14:44:08,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60306, dest: /10.191.53.85:50010, bytes: 115835, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1024477442_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741875_1051, duration: 2414000
2021-05-29 14:44:08,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741875_1051, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:44:13,191 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741866_1042 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741866 for deletion
2021-05-29 14:44:13,195 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741867_1043 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741867 for deletion
2021-05-29 14:44:13,195 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741868_1044 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741868 for deletion
2021-05-29 14:44:13,195 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741869_1045 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741869 for deletion
2021-05-29 14:44:13,195 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741870_1046 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741870 for deletion
2021-05-29 14:44:13,195 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741871_1047 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741871 for deletion
2021-05-29 14:44:13,196 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741866_1042 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741866
2021-05-29 14:44:13,197 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741867_1043 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741867
2021-05-29 14:44:13,198 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741868_1044 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741868
2021-05-29 14:44:13,200 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741869_1045 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741869
2021-05-29 14:44:13,201 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741870_1046 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741870
2021-05-29 14:44:13,202 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741871_1047 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741871
2021-05-29 14:44:15,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741876_1052 src: /10.191.53.85:60312 dest: /10.191.53.85:50010
2021-05-29 14:44:15,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60312, dest: /10.191.53.85:50010, bytes: 357169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1532685249_105, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741876_1052, duration: 21771100
2021-05-29 14:44:15,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741876_1052, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-29 14:46:28,304 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741873_1049 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741873 for deletion
2021-05-29 14:46:28,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741873_1049 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741873
2021-05-29 15:00:48,501 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2221ms
No GCs detected
2021-05-29 15:06:52,277 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-29 15:06:56,915 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 15:06:56,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 15:59:26,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 15:59:26,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 15:59:27,411 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 15:59:27,486 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 15:59:27,486 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-29 15:59:27,522 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-29 15:59:27,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-29 15:59:27,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-29 15:59:27,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-29 15:59:27,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-29 15:59:27,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-29 15:59:27,707 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 15:59:27,715 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 15:59:27,723 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-29 15:59:27,728 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 15:59:27,731 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-29 15:59:27,732 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 15:59:27,732 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 15:59:27,752 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 62876
2021-05-29 15:59:27,752 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 15:59:27,912 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:62876
2021-05-29 15:59:28,242 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-29 15:59:28,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-29 15:59:28,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-29 15:59:28,578 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 15:59:28,607 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-29 15:59:28,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-29 15:59:28,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-29 15:59:28,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-29 15:59:28,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-29 15:59:28,753 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 15:59:28,754 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-29 15:59:29,345 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 9201@DESKTOP-TSQQRSN
2021-05-29 15:59:29,405 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1542253369-10.191.53.85-1622264819009
2021-05-29 15:59:29,405 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009
2021-05-29 15:59:29,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2005162102;bpid=BP-1542253369-10.191.53.85-1622264819009;lv=-56;nsInfo=lv=-63;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0;bpid=BP-1542253369-10.191.53.85-1622264819009;dnuuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-05-29 15:59:29,470 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-77177884-7e39-4105-ae4c-bdc787c546af
2021-05-29 15:59:29,470 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-29 15:59:29,504 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-29 15:59:29,504 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-29 15:59:29,505 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 15:59:29,551 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1542253369-10.191.53.85-1622264819009 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 47ms
2021-05-29 15:59:29,551 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1542253369-10.191.53.85-1622264819009: 47ms
2021-05-29 15:59:29,552 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-29 15:59:29,557 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 5ms
2021-05-29 15:59:29,557 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 6ms
2021-05-29 15:59:30,014 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): no suitable block pools found to scan.  Waiting 1804092419 ms.
2021-05-29 15:59:30,019 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622280590019 with interval 21600000
2021-05-29 15:59:30,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-05-29 15:59:30,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-05-29 15:59:30,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-29 15:59:30,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=394
2021-05-29 15:59:30,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 15:59:30,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x7e3cbb435b4,  containing 1 storage report(s), of which we sent 1. The reports had 38 total blocks and used 1 RPC(s). This took 8 msec to generate and 125 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-29 15:59:30,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-29 16:05:55,193 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-29 16:06:00,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-05-29 16:06:00,940 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 16:06:00,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-31 19:00:17,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-31 19:00:17,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-31 19:00:18,541 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-31 19:00:18,602 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-31 19:00:18,603 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-05-31 19:00:18,610 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-05-31 19:00:18,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-05-31 19:00:18,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-05-31 19:00:18,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-05-31 19:00:18,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-05-31 19:00:18,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-05-31 19:00:18,755 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-31 19:00:18,762 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-31 19:00:18,767 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-05-31 19:00:18,772 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-31 19:00:18,774 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-05-31 19:00:18,775 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-31 19:00:18,775 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-31 19:00:18,785 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 57665
2021-05-31 19:00:18,785 INFO org.mortbay.log: jetty-6.1.26
2021-05-31 19:00:18,926 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:57665
2021-05-31 19:00:19,127 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-05-31 19:00:19,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-05-31 19:00:19,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-05-31 19:00:29,355 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-31 19:00:29,372 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-05-31 19:00:29,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-05-31 19:00:29,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-05-31 19:00:29,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-05-31 19:00:29,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-05-31 19:00:29,447 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-31 19:00:29,447 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-05-31 19:00:29,908 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 566@DESKTOP-TSQQRSN
2021-05-31 19:00:30,010 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1542253369-10.191.53.85-1622264819009
2021-05-31 19:00:30,010 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009
2021-05-31 19:00:30,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2005162102;bpid=BP-1542253369-10.191.53.85-1622264819009;lv=-56;nsInfo=lv=-63;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0;bpid=BP-1542253369-10.191.53.85-1622264819009;dnuuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-05-31 19:00:30,091 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-77177884-7e39-4105-ae4c-bdc787c546af
2021-05-31 19:00:30,091 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-05-31 19:00:30,137 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-05-31 19:00:30,138 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-31 19:00:30,139 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-31 19:00:30,294 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1542253369-10.191.53.85-1622264819009 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 154ms
2021-05-31 19:00:30,294 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1542253369-10.191.53.85-1622264819009: 156ms
2021-05-31 19:00:30,304 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-05-31 19:00:30,312 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 8ms
2021-05-31 19:00:30,312 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 18ms
2021-05-31 19:00:30,701 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): no suitable block pools found to scan.  Waiting 1620431732 ms.
2021-05-31 19:00:30,707 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1622477104706 with interval 21600000
2021-05-31 19:00:30,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-05-31 19:00:30,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-05-31 19:00:30,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-05-31 19:00:30,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=397
2021-05-31 19:00:30,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-31 19:00:31,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1085d36c6ec,  containing 1 storage report(s), of which we sent 1. The reports had 38 total blocks and used 1 RPC(s). This took 6 msec to generate and 114 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-05-31 19:00:31,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-05-31 19:02:29,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741877_1053 src: /10.191.53.85:60991 dest: /10.191.53.85:50010
2021-05-31 19:02:29,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60991, dest: /10.191.53.85:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_404430562_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741877_1053, duration: 42981800
2021-05-31 19:02:29,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741877_1053, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:02:29,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741878_1054 src: /10.191.53.85:60992 dest: /10.191.53.85:50010
2021-05-31 19:02:29,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60992, dest: /10.191.53.85:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_404430562_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741878_1054, duration: 2596600
2021-05-31 19:02:29,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741878_1054, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:02:29,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741879_1055 src: /10.191.53.85:60993 dest: /10.191.53.85:50010
2021-05-31 19:02:29,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60993, dest: /10.191.53.85:50010, bytes: 29, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_404430562_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741879_1055, duration: 1801100
2021-05-31 19:02:29,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741879_1055, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:02:29,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741880_1056 src: /10.191.53.85:60994 dest: /10.191.53.85:50010
2021-05-31 19:02:29,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60994, dest: /10.191.53.85:50010, bytes: 97706, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_404430562_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741880_1056, duration: 2630800
2021-05-31 19:02:29,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741880_1056, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:02:37,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741881_1057 src: /10.191.53.85:57793 dest: /10.191.53.85:50010
2021-05-31 19:02:37,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:57793, dest: /10.191.53.85:50010, bytes: 116177, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_375595400_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741881_1057, duration: 31382600
2021-05-31 19:02:37,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741881_1057, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:02:41,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741882_1058 src: /10.191.53.85:63254 dest: /10.191.53.85:50010
2021-05-31 19:02:46,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741883_1059 src: /10.191.53.85:63259 dest: /10.191.53.85:50010
2021-05-31 19:02:46,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:63259, dest: /10.191.53.85:50010, bytes: 86, op: HDFS_WRITE, cliID: DFSClient_attempt_1622458832718_0001_r_000000_0_1906262704_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741883_1059, duration: 32555000
2021-05-31 19:02:46,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741883_1059, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:02:46,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:63254, dest: /10.191.53.85:50010, bytes: 33658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_375595400_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741882_1058, duration: 5142305800
2021-05-31 19:02:46,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741882_1058, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:02:46,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741884_1060 src: /10.191.53.85:63261 dest: /10.191.53.85:50010
2021-05-31 19:02:46,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:63261, dest: /10.191.53.85:50010, bytes: 348, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_375595400_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741884_1060, duration: 14864000
2021-05-31 19:02:46,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741884_1060, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:02:46,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741885_1061 src: /10.191.53.85:63263 dest: /10.191.53.85:50010
2021-05-31 19:02:46,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:63263, dest: /10.191.53.85:50010, bytes: 33658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_375595400_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741885_1061, duration: 3225600
2021-05-31 19:02:46,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741885_1061, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:02:46,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741886_1062 src: /10.191.53.85:63264 dest: /10.191.53.85:50010
2021-05-31 19:02:46,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:63264, dest: /10.191.53.85:50010, bytes: 116177, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_375595400_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741886_1062, duration: 2903100
2021-05-31 19:02:46,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741886_1062, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:02:52,234 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741877_1053 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741877 for deletion
2021-05-31 19:02:52,235 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741878_1054 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741878 for deletion
2021-05-31 19:02:52,235 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741879_1055 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741879 for deletion
2021-05-31 19:02:52,235 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741880_1056 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741880 for deletion
2021-05-31 19:02:52,235 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741881_1057 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741881 for deletion
2021-05-31 19:02:52,235 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741882_1058 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741882 for deletion
2021-05-31 19:02:52,235 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741883_1059 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741883 for deletion
2021-05-31 19:02:52,236 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741877_1053 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741877
2021-05-31 19:02:52,237 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741878_1054 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741878
2021-05-31 19:02:52,237 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741879_1055 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741879
2021-05-31 19:02:52,238 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741880_1056 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741880
2021-05-31 19:02:52,239 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741881_1057 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741881
2021-05-31 19:02:52,239 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741882_1058 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741882
2021-05-31 19:02:52,240 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741883_1059 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741883
2021-05-31 19:02:54,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741887_1063 src: /10.191.53.85:64349 dest: /10.191.53.85:50010
2021-05-31 19:02:54,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:64349, dest: /10.191.53.85:50010, bytes: 48073, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-787079911_105, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741887_1063, duration: 31258900
2021-05-31 19:02:54,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741887_1063, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:03:52,397 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741884_1060 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741884 for deletion
2021-05-31 19:03:52,399 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741884_1060 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741884
2021-05-31 19:05:25,746 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741825_1001 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
2021-05-31 19:05:25,747 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741832_1008 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741832 for deletion
2021-05-31 19:05:25,749 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741825_1001 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741825
2021-05-31 19:05:25,750 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741832_1008 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741832
2021-05-31 19:05:35,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741888_1064 src: /10.191.53.85:65022 dest: /10.191.53.85:50010
2021-05-31 19:05:35,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:65022, dest: /10.191.53.85:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_225455994_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741888_1064, duration: 42345300
2021-05-31 19:05:35,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741888_1064, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:05:37,781 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741888_1064 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741888 for deletion
2021-05-31 19:05:37,782 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741888_1064 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741888
2021-05-31 19:07:07,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741889_1065 src: /10.191.53.85:55805 dest: /10.191.53.85:50010
2021-05-31 19:07:07,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55805, dest: /10.191.53.85:50010, bytes: 4436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926628778_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741889_1065, duration: 49639500
2021-05-31 19:07:07,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741889_1065, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:07,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741890_1066 src: /10.191.53.85:55806 dest: /10.191.53.85:50010
2021-05-31 19:07:07,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55806, dest: /10.191.53.85:50010, bytes: 989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926628778_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741890_1066, duration: 2221700
2021-05-31 19:07:07,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741890_1066, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:07,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741891_1067 src: /10.191.53.85:55807 dest: /10.191.53.85:50010
2021-05-31 19:07:07,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55807, dest: /10.191.53.85:50010, bytes: 9683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926628778_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741891_1067, duration: 1896700
2021-05-31 19:07:07,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741891_1067, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:07,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741892_1068 src: /10.191.53.85:55808 dest: /10.191.53.85:50010
2021-05-31 19:07:07,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55808, dest: /10.191.53.85:50010, bytes: 977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926628778_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741892_1068, duration: 2019700
2021-05-31 19:07:07,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741892_1068, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:07,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741893_1069 src: /10.191.53.85:55809 dest: /10.191.53.85:50010
2021-05-31 19:07:07,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55809, dest: /10.191.53.85:50010, bytes: 620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926628778_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741893_1069, duration: 5818000
2021-05-31 19:07:07,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741893_1069, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:07,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741894_1070 src: /10.191.53.85:55810 dest: /10.191.53.85:50010
2021-05-31 19:07:07,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55810, dest: /10.191.53.85:50010, bytes: 3518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926628778_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741894_1070, duration: 1994100
2021-05-31 19:07:07,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741894_1070, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:07,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741895_1071 src: /10.191.53.85:55811 dest: /10.191.53.85:50010
2021-05-31 19:07:07,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55811, dest: /10.191.53.85:50010, bytes: 5511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926628778_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741895_1071, duration: 6372000
2021-05-31 19:07:07,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741895_1071, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:07,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741896_1072 src: /10.191.53.85:55812 dest: /10.191.53.85:50010
2021-05-31 19:07:07,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55812, dest: /10.191.53.85:50010, bytes: 1158, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926628778_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741896_1072, duration: 3821400
2021-05-31 19:07:07,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741896_1072, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:07,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741897_1073 src: /10.191.53.85:55813 dest: /10.191.53.85:50010
2021-05-31 19:07:07,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55813, dest: /10.191.53.85:50010, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926628778_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741897_1073, duration: 2385300
2021-05-31 19:07:07,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741897_1073, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:24,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741898_1074 src: /10.191.53.85:50616 dest: /10.191.53.85:50010
2021-05-31 19:07:24,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:50616, dest: /10.191.53.85:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-157872653_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741898_1074, duration: 55073400
2021-05-31 19:07:24,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741898_1074, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:24,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741899_1075 src: /10.191.53.85:50617 dest: /10.191.53.85:50010
2021-05-31 19:07:24,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:50617, dest: /10.191.53.85:50010, bytes: 1120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-157872653_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741899_1075, duration: 3054300
2021-05-31 19:07:24,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741899_1075, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:24,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741900_1076 src: /10.191.53.85:50618 dest: /10.191.53.85:50010
2021-05-31 19:07:24,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:50618, dest: /10.191.53.85:50010, bytes: 213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-157872653_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741900_1076, duration: 4489100
2021-05-31 19:07:24,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741900_1076, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:24,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741901_1077 src: /10.191.53.85:50619 dest: /10.191.53.85:50010
2021-05-31 19:07:24,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:50619, dest: /10.191.53.85:50010, bytes: 97706, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-157872653_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741901_1077, duration: 5636600
2021-05-31 19:07:24,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741901_1077, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:32,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741902_1078 src: /10.191.53.85:61841 dest: /10.191.53.85:50010
2021-05-31 19:07:32,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:61841, dest: /10.191.53.85:50010, bytes: 116177, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1664413794_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741902_1078, duration: 41405900
2021-05-31 19:07:32,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741902_1078, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:45,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741903_1079 src: /10.191.53.85:59574 dest: /10.191.53.85:50010
2021-05-31 19:07:56,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741904_1080 src: /10.191.53.85:57402 dest: /10.191.53.85:50010
2021-05-31 19:07:57,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:57402, dest: /10.191.53.85:50010, bytes: 176, op: HDFS_WRITE, cliID: DFSClient_attempt_1622458832718_0003_r_000000_0_123207895_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741904_1080, duration: 232472300
2021-05-31 19:07:57,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741904_1080, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:57,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59574, dest: /10.191.53.85:50010, bytes: 87170, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1664413794_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741903_1079, duration: 11887304800
2021-05-31 19:07:57,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741903_1079, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:57,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741905_1081 src: /10.191.53.85:57405 dest: /10.191.53.85:50010
2021-05-31 19:07:57,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:57405, dest: /10.191.53.85:50010, bytes: 349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1664413794_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741905_1081, duration: 2473900
2021-05-31 19:07:57,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741905_1081, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:57,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741906_1082 src: /10.191.53.85:57407 dest: /10.191.53.85:50010
2021-05-31 19:07:57,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:57407, dest: /10.191.53.85:50010, bytes: 87170, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1664413794_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741906_1082, duration: 2623100
2021-05-31 19:07:57,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741906_1082, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:57,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741907_1083 src: /10.191.53.85:57408 dest: /10.191.53.85:50010
2021-05-31 19:07:57,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:57408, dest: /10.191.53.85:50010, bytes: 116177, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1664413794_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741907_1083, duration: 4515100
2021-05-31 19:07:57,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741907_1083, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:58,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741908_1084 src: /10.191.53.85:55670 dest: /10.191.53.85:50010
2021-05-31 19:07:58,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55670, dest: /10.191.53.85:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-157872653_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741908_1084, duration: 3625100
2021-05-31 19:07:58,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741908_1084, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:58,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741909_1085 src: /10.191.53.85:55671 dest: /10.191.53.85:50010
2021-05-31 19:07:58,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55671, dest: /10.191.53.85:50010, bytes: 142, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-157872653_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741909_1085, duration: 2179400
2021-05-31 19:07:58,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741909_1085, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:58,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741910_1086 src: /10.191.53.85:55672 dest: /10.191.53.85:50010
2021-05-31 19:07:58,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55672, dest: /10.191.53.85:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-157872653_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741910_1086, duration: 2836600
2021-05-31 19:07:58,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741910_1086, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:07:58,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741911_1087 src: /10.191.53.85:55673 dest: /10.191.53.85:50010
2021-05-31 19:07:58,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55673, dest: /10.191.53.85:50010, bytes: 97271, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-157872653_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741911_1087, duration: 2433600
2021-05-31 19:07:58,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741911_1087, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:08:02,276 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741898_1074 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741898 for deletion
2021-05-31 19:08:02,277 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741899_1075 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741899 for deletion
2021-05-31 19:08:02,277 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741900_1076 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741900 for deletion
2021-05-31 19:08:02,277 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741901_1077 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741901 for deletion
2021-05-31 19:08:02,277 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741902_1078 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741902 for deletion
2021-05-31 19:08:02,278 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741903_1079 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741903 for deletion
2021-05-31 19:08:02,278 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741898_1074 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741898
2021-05-31 19:08:02,279 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741899_1075 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741899
2021-05-31 19:08:02,281 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741900_1076 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741900
2021-05-31 19:08:02,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741901_1077 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741901
2021-05-31 19:08:02,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741902_1078 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741902
2021-05-31 19:08:02,285 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741903_1079 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741903
2021-05-31 19:08:04,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741912_1088 src: /10.191.53.85:60267 dest: /10.191.53.85:50010
2021-05-31 19:08:04,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60267, dest: /10.191.53.85:50010, bytes: 130786, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-944223701_161, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741912_1088, duration: 5031900
2021-05-31 19:08:04,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741912_1088, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:08:11,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741913_1089 src: /10.191.53.85:57737 dest: /10.191.53.85:50010
2021-05-31 19:08:11,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:57737, dest: /10.191.53.85:50010, bytes: 115670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_898503872_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741913_1089, duration: 36793300
2021-05-31 19:08:11,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741913_1089, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:08:15,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741914_1090 src: /10.191.53.85:58600 dest: /10.191.53.85:50010
2021-05-31 19:08:20,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741915_1091 src: /10.191.53.85:59969 dest: /10.191.53.85:50010
2021-05-31 19:08:20,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59969, dest: /10.191.53.85:50010, bytes: 48, op: HDFS_WRITE, cliID: DFSClient_attempt_1622458832718_0004_r_000000_0_-1368497864_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741915_1091, duration: 33646400
2021-05-31 19:08:20,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741915_1091, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:08:20,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:58600, dest: /10.191.53.85:50010, bytes: 33428, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_898503872_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741914_1090, duration: 5113939000
2021-05-31 19:08:20,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741914_1090, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:08:20,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741916_1092 src: /10.191.53.85:58202 dest: /10.191.53.85:50010
2021-05-31 19:08:20,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:58202, dest: /10.191.53.85:50010, bytes: 346, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_898503872_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741916_1092, duration: 2318400
2021-05-31 19:08:20,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741916_1092, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:08:20,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741917_1093 src: /10.191.53.85:58204 dest: /10.191.53.85:50010
2021-05-31 19:08:20,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:58204, dest: /10.191.53.85:50010, bytes: 33428, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_898503872_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741917_1093, duration: 2582300
2021-05-31 19:08:20,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741917_1093, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:08:21,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741918_1094 src: /10.191.53.85:58205 dest: /10.191.53.85:50010
2021-05-31 19:08:21,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:58205, dest: /10.191.53.85:50010, bytes: 115670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_898503872_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741918_1094, duration: 3304300
2021-05-31 19:08:21,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741918_1094, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:08:26,318 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741904_1080 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741904 for deletion
2021-05-31 19:08:26,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741908_1084 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741908 for deletion
2021-05-31 19:08:26,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741909_1085 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741909 for deletion
2021-05-31 19:08:26,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741910_1086 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741910 for deletion
2021-05-31 19:08:26,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741911_1087 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741911 for deletion
2021-05-31 19:08:26,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741913_1089 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741913 for deletion
2021-05-31 19:08:26,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741914_1090 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741914 for deletion
2021-05-31 19:08:26,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741904_1080 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741904
2021-05-31 19:08:26,321 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741908_1084 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741908
2021-05-31 19:08:26,322 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741909_1085 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741909
2021-05-31 19:08:26,323 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741910_1086 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741910
2021-05-31 19:08:26,325 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741911_1087 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741911
2021-05-31 19:08:26,327 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741913_1089 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741913
2021-05-31 19:08:26,328 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741914_1090 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741914
2021-05-31 19:08:27,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741919_1095 src: /10.191.53.85:54453 dest: /10.191.53.85:50010
2021-05-31 19:08:27,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:54453, dest: /10.191.53.85:50010, bytes: 46666, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_44581544_264, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741919_1095, duration: 4503400
2021-05-31 19:08:27,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741919_1095, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:09:50,516 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741905_1081 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741905 for deletion
2021-05-31 19:09:50,516 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741916_1092 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741916 for deletion
2021-05-31 19:09:50,517 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741905_1081 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741905
2021-05-31 19:09:50,518 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741916_1092 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741916
2021-05-31 19:13:26,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741920_1096 src: /10.191.53.85:63643 dest: /10.191.53.85:50010
2021-05-31 19:13:26,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:63643, dest: /10.191.53.85:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2030016880_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741920_1096, duration: 36579000
2021-05-31 19:13:26,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741920_1096, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:15:20,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741921_1097 src: /10.191.53.85:55339 dest: /10.191.53.85:50010
2021-05-31 19:15:20,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55339, dest: /10.191.53.85:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_643965434_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741921_1097, duration: 44065600
2021-05-31 19:15:20,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741921_1097, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:15:20,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741922_1098 src: /10.191.53.85:55341 dest: /10.191.53.85:50010
2021-05-31 19:15:20,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55341, dest: /10.191.53.85:50010, bytes: 126, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_643965434_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741922_1098, duration: 2710600
2021-05-31 19:15:20,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741922_1098, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:15:20,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741923_1099 src: /10.191.53.85:55342 dest: /10.191.53.85:50010
2021-05-31 19:15:20,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55342, dest: /10.191.53.85:50010, bytes: 29, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_643965434_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741923_1099, duration: 2116700
2021-05-31 19:15:20,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741923_1099, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:15:20,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741924_1100 src: /10.191.53.85:55343 dest: /10.191.53.85:50010
2021-05-31 19:15:20,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55343, dest: /10.191.53.85:50010, bytes: 97403, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_643965434_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741924_1100, duration: 2679400
2021-05-31 19:15:20,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741924_1100, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:15:27,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741925_1101 src: /10.191.53.85:55111 dest: /10.191.53.85:50010
2021-05-31 19:15:27,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55111, dest: /10.191.53.85:50010, bytes: 115826, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1628696393_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741925_1101, duration: 51752500
2021-05-31 19:15:27,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741925_1101, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:15:31,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741926_1102 src: /10.191.53.85:50120 dest: /10.191.53.85:50010
2021-05-31 19:15:36,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741927_1103 src: /10.191.53.85:54127 dest: /10.191.53.85:50010
2021-05-31 19:15:36,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:54127, dest: /10.191.53.85:50010, bytes: 50, op: HDFS_WRITE, cliID: DFSClient_attempt_1622458832718_0005_r_000000_0_1785779676_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741927_1103, duration: 33103300
2021-05-31 19:15:36,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741927_1103, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:15:37,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:50120, dest: /10.191.53.85:50010, bytes: 33674, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1628696393_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741926_1102, duration: 5456614500
2021-05-31 19:15:37,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741926_1102, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:15:37,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741928_1104 src: /10.191.53.85:54129 dest: /10.191.53.85:50010
2021-05-31 19:15:37,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:54129, dest: /10.191.53.85:50010, bytes: 347, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1628696393_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741928_1104, duration: 2402200
2021-05-31 19:15:37,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741928_1104, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:15:37,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741929_1105 src: /10.191.53.85:54131 dest: /10.191.53.85:50010
2021-05-31 19:15:37,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:54131, dest: /10.191.53.85:50010, bytes: 33674, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1628696393_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741929_1105, duration: 2038800
2021-05-31 19:15:37,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741929_1105, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:15:37,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741930_1106 src: /10.191.53.85:54132 dest: /10.191.53.85:50010
2021-05-31 19:15:37,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:54132, dest: /10.191.53.85:50010, bytes: 115826, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1628696393_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741930_1106, duration: 3191700
2021-05-31 19:15:37,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741930_1106, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:15:42,488 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741921_1097 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741921 for deletion
2021-05-31 19:15:42,489 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741922_1098 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741922 for deletion
2021-05-31 19:15:42,489 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741923_1099 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741923 for deletion
2021-05-31 19:15:42,489 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741924_1100 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741924 for deletion
2021-05-31 19:15:42,489 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741925_1101 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741925 for deletion
2021-05-31 19:15:42,489 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741926_1102 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741926 for deletion
2021-05-31 19:15:42,490 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741921_1097 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741921
2021-05-31 19:15:42,491 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741922_1098 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741922
2021-05-31 19:15:42,492 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741923_1099 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741923
2021-05-31 19:15:42,493 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741924_1100 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741924
2021-05-31 19:15:42,493 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741925_1101 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741925
2021-05-31 19:15:42,494 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741926_1102 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741926
2021-05-31 19:15:44,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741931_1107 src: /10.191.53.85:50785 dest: /10.191.53.85:50010
2021-05-31 19:15:44,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:50785, dest: /10.191.53.85:50010, bytes: 46807, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1999028167_312, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741931_1107, duration: 2715600
2021-05-31 19:15:44,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741931_1107, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:15:51,500 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741928_1104 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741928 for deletion
2021-05-31 19:15:51,501 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741928_1104 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741928
2021-05-31 19:27:58,688 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741889_1065 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741889 for deletion
2021-05-31 19:27:58,689 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741890_1066 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741890 for deletion
2021-05-31 19:27:58,689 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741891_1067 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741891 for deletion
2021-05-31 19:27:58,689 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741892_1068 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741892 for deletion
2021-05-31 19:27:58,690 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741893_1069 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741893 for deletion
2021-05-31 19:27:58,690 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741894_1070 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741894 for deletion
2021-05-31 19:27:58,690 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741895_1071 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741895 for deletion
2021-05-31 19:27:58,690 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741896_1072 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741896 for deletion
2021-05-31 19:27:58,690 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741897_1073 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741897 for deletion
2021-05-31 19:27:58,690 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741915_1091 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741915 for deletion
2021-05-31 19:27:58,691 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741889_1065 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741889
2021-05-31 19:27:58,692 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741890_1066 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741890
2021-05-31 19:27:58,693 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741891_1067 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741891
2021-05-31 19:27:58,694 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741892_1068 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741892
2021-05-31 19:27:58,695 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741893_1069 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741893
2021-05-31 19:27:58,695 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741894_1070 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741894
2021-05-31 19:27:58,695 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741895_1071 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741895
2021-05-31 19:27:58,696 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741896_1072 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741896
2021-05-31 19:27:58,696 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741897_1073 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741897
2021-05-31 19:27:58,697 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741915_1091 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741915
2021-05-31 19:28:44,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741932_1108 src: /10.191.53.85:49824 dest: /10.191.53.85:50010
2021-05-31 19:28:44,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:49824, dest: /10.191.53.85:50010, bytes: 4436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-249603971_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741932_1108, duration: 32418500
2021-05-31 19:28:44,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741932_1108, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:28:44,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741933_1109 src: /10.191.53.85:49825 dest: /10.191.53.85:50010
2021-05-31 19:28:44,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:49825, dest: /10.191.53.85:50010, bytes: 989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-249603971_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741933_1109, duration: 2272400
2021-05-31 19:28:44,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741933_1109, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:28:44,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741934_1110 src: /10.191.53.85:49826 dest: /10.191.53.85:50010
2021-05-31 19:28:44,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:49826, dest: /10.191.53.85:50010, bytes: 9683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-249603971_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741934_1110, duration: 13041000
2021-05-31 19:28:44,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741934_1110, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:28:44,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741935_1111 src: /10.191.53.85:49827 dest: /10.191.53.85:50010
2021-05-31 19:28:44,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:49827, dest: /10.191.53.85:50010, bytes: 977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-249603971_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741935_1111, duration: 1845400
2021-05-31 19:28:44,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741935_1111, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:28:44,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741936_1112 src: /10.191.53.85:49828 dest: /10.191.53.85:50010
2021-05-31 19:28:44,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:49828, dest: /10.191.53.85:50010, bytes: 620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-249603971_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741936_1112, duration: 1726300
2021-05-31 19:28:44,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741936_1112, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:28:44,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741937_1113 src: /10.191.53.85:62962 dest: /10.191.53.85:50010
2021-05-31 19:28:44,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:62962, dest: /10.191.53.85:50010, bytes: 3518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-249603971_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741937_1113, duration: 2035200
2021-05-31 19:28:44,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741937_1113, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:28:44,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741938_1114 src: /10.191.53.85:62963 dest: /10.191.53.85:50010
2021-05-31 19:28:44,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:62963, dest: /10.191.53.85:50010, bytes: 5511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-249603971_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741938_1114, duration: 1917800
2021-05-31 19:28:44,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741938_1114, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:28:44,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741939_1115 src: /10.191.53.85:62964 dest: /10.191.53.85:50010
2021-05-31 19:28:44,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:62964, dest: /10.191.53.85:50010, bytes: 1158, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-249603971_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741939_1115, duration: 2442700
2021-05-31 19:28:44,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741939_1115, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:28:44,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741940_1116 src: /10.191.53.85:62965 dest: /10.191.53.85:50010
2021-05-31 19:28:44,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:62965, dest: /10.191.53.85:50010, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-249603971_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741940_1116, duration: 2054900
2021-05-31 19:28:44,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741940_1116, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:29:51,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741941_1117 src: /10.191.53.85:63347 dest: /10.191.53.85:50010
2021-05-31 19:29:51,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:63347, dest: /10.191.53.85:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1446240431_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741941_1117, duration: 38009600
2021-05-31 19:29:51,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741941_1117, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:29:51,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741942_1118 src: /10.191.53.85:63348 dest: /10.191.53.85:50010
2021-05-31 19:29:51,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:63348, dest: /10.191.53.85:50010, bytes: 1120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1446240431_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741942_1118, duration: 4384800
2021-05-31 19:29:51,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741942_1118, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:29:51,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741943_1119 src: /10.191.53.85:63349 dest: /10.191.53.85:50010
2021-05-31 19:29:51,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:63349, dest: /10.191.53.85:50010, bytes: 213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1446240431_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741943_1119, duration: 2203600
2021-05-31 19:29:51,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741943_1119, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:29:51,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741944_1120 src: /10.191.53.85:63350 dest: /10.191.53.85:50010
2021-05-31 19:29:51,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:63350, dest: /10.191.53.85:50010, bytes: 97707, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1446240431_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741944_1120, duration: 2630100
2021-05-31 19:29:51,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741944_1120, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:29:57,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741945_1121 src: /10.191.53.85:64439 dest: /10.191.53.85:50010
2021-05-31 19:29:57,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:64439, dest: /10.191.53.85:50010, bytes: 116178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1481771991_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741945_1121, duration: 31610000
2021-05-31 19:29:57,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741945_1121, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:07,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741946_1122 src: /10.191.53.85:56004 dest: /10.191.53.85:50010
2021-05-31 19:30:16,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741947_1123 src: /10.191.53.85:65279 dest: /10.191.53.85:50010
2021-05-31 19:30:16,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:65279, dest: /10.191.53.85:50010, bytes: 176, op: HDFS_WRITE, cliID: DFSClient_attempt_1622458832718_0006_r_000000_0_1194131175_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741947_1123, duration: 36465400
2021-05-31 19:30:16,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741947_1123, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:17,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:56004, dest: /10.191.53.85:50010, bytes: 87106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1481771991_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741946_1122, duration: 9705909400
2021-05-31 19:30:17,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741946_1122, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:17,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741948_1124 src: /10.191.53.85:65281 dest: /10.191.53.85:50010
2021-05-31 19:30:17,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:65281, dest: /10.191.53.85:50010, bytes: 349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1481771991_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741948_1124, duration: 2685900
2021-05-31 19:30:17,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741948_1124, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:17,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741949_1125 src: /10.191.53.85:65283 dest: /10.191.53.85:50010
2021-05-31 19:30:17,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:65283, dest: /10.191.53.85:50010, bytes: 87106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1481771991_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741949_1125, duration: 3008100
2021-05-31 19:30:17,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741949_1125, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:17,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741950_1126 src: /10.191.53.85:65284 dest: /10.191.53.85:50010
2021-05-31 19:30:17,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:65284, dest: /10.191.53.85:50010, bytes: 116178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1481771991_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741950_1126, duration: 5659200
2021-05-31 19:30:17,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741950_1126, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:19,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741951_1127 src: /10.191.53.85:65287 dest: /10.191.53.85:50010
2021-05-31 19:30:19,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:65287, dest: /10.191.53.85:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1446240431_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741951_1127, duration: 9491000
2021-05-31 19:30:19,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741951_1127, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:19,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741952_1128 src: /10.191.53.85:65288 dest: /10.191.53.85:50010
2021-05-31 19:30:19,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:65288, dest: /10.191.53.85:50010, bytes: 143, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1446240431_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741952_1128, duration: 3443600
2021-05-31 19:30:19,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741952_1128, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:19,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741953_1129 src: /10.191.53.85:65289 dest: /10.191.53.85:50010
2021-05-31 19:30:19,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:65289, dest: /10.191.53.85:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1446240431_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741953_1129, duration: 3115100
2021-05-31 19:30:19,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741953_1129, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:19,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741954_1130 src: /10.191.53.85:65290 dest: /10.191.53.85:50010
2021-05-31 19:30:19,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:65290, dest: /10.191.53.85:50010, bytes: 97272, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1446240431_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741954_1130, duration: 18219800
2021-05-31 19:30:19,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741954_1130, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:23,010 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741941_1117 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741941 for deletion
2021-05-31 19:30:23,011 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741942_1118 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741942 for deletion
2021-05-31 19:30:23,011 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741943_1119 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741943 for deletion
2021-05-31 19:30:23,011 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741944_1120 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741944 for deletion
2021-05-31 19:30:23,011 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741945_1121 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741945 for deletion
2021-05-31 19:30:23,012 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741946_1122 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741946 for deletion
2021-05-31 19:30:23,013 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741941_1117 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741941
2021-05-31 19:30:23,014 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741942_1118 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741942
2021-05-31 19:30:23,015 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741943_1119 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741943
2021-05-31 19:30:23,016 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741944_1120 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741944
2021-05-31 19:30:23,016 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741945_1121 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741945
2021-05-31 19:30:23,017 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741946_1122 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741946
2021-05-31 19:30:23,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741955_1131 src: /10.191.53.85:56595 dest: /10.191.53.85:50010
2021-05-31 19:30:23,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:56595, dest: /10.191.53.85:50010, bytes: 130276, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1088867715_364, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741955_1131, duration: 3300100
2021-05-31 19:30:23,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741955_1131, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:29,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741956_1132 src: /10.191.53.85:56605 dest: /10.191.53.85:50010
2021-05-31 19:30:29,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:56605, dest: /10.191.53.85:50010, bytes: 115671, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2049630402_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741956_1132, duration: 31833400
2021-05-31 19:30:29,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741956_1132, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:33,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741957_1133 src: /10.191.53.85:62243 dest: /10.191.53.85:50010
2021-05-31 19:30:38,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741958_1134 src: /10.191.53.85:57319 dest: /10.191.53.85:50010
2021-05-31 19:30:38,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:57319, dest: /10.191.53.85:50010, bytes: 48, op: HDFS_WRITE, cliID: DFSClient_attempt_1622458832718_0007_r_000000_0_1858213551_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741958_1134, duration: 32915800
2021-05-31 19:30:38,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741958_1134, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:39,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:62243, dest: /10.191.53.85:50010, bytes: 33421, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2049630402_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741957_1133, duration: 5442449200
2021-05-31 19:30:39,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741957_1133, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:39,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741959_1135 src: /10.191.53.85:57321 dest: /10.191.53.85:50010
2021-05-31 19:30:39,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:57321, dest: /10.191.53.85:50010, bytes: 346, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2049630402_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741959_1135, duration: 2427500
2021-05-31 19:30:39,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741959_1135, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:39,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741960_1136 src: /10.191.53.85:57323 dest: /10.191.53.85:50010
2021-05-31 19:30:39,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:57323, dest: /10.191.53.85:50010, bytes: 33421, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2049630402_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741960_1136, duration: 2592400
2021-05-31 19:30:39,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741960_1136, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:39,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741961_1137 src: /10.191.53.85:57324 dest: /10.191.53.85:50010
2021-05-31 19:30:39,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:57324, dest: /10.191.53.85:50010, bytes: 115671, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2049630402_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741961_1137, duration: 2981200
2021-05-31 19:30:39,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741961_1137, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:44,061 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741952_1128 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741952 for deletion
2021-05-31 19:30:44,061 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741953_1129 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741953 for deletion
2021-05-31 19:30:44,061 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741954_1130 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741954 for deletion
2021-05-31 19:30:44,061 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741956_1132 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741956 for deletion
2021-05-31 19:30:44,061 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741957_1133 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741957 for deletion
2021-05-31 19:30:44,061 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741947_1123 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741947 for deletion
2021-05-31 19:30:44,061 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741951_1127 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741951 for deletion
2021-05-31 19:30:44,062 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741952_1128 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741952
2021-05-31 19:30:44,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741953_1129 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741953
2021-05-31 19:30:44,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741954_1130 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741954
2021-05-31 19:30:44,065 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741956_1132 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741956
2021-05-31 19:30:44,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741957_1133 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741957
2021-05-31 19:30:44,067 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741947_1123 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741947
2021-05-31 19:30:44,067 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741951_1127 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741951
2021-05-31 19:30:46,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741962_1138 src: /10.191.53.85:60419 dest: /10.191.53.85:50010
2021-05-31 19:30:46,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:60419, dest: /10.191.53.85:50010, bytes: 46532, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1572411227_468, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741962_1138, duration: 3358200
2021-05-31 19:30:46,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741962_1138, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:30:53,068 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741959_1135 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741959 for deletion
2021-05-31 19:30:53,068 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741948_1124 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741948 for deletion
2021-05-31 19:30:53,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741959_1135 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741959
2021-05-31 19:30:53,070 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741948_1124 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741948
2021-05-31 19:32:44,210 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741927_1103 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741927 for deletion
2021-05-31 19:32:44,213 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741927_1103 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741927
2021-05-31 19:33:08,244 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741920_1096 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741920 for deletion
2021-05-31 19:33:08,245 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741920_1096 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741920
2021-05-31 19:33:41,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741963_1139 src: /10.191.53.85:55691 dest: /10.191.53.85:50010
2021-05-31 19:33:41,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55691, dest: /10.191.53.85:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_917289971_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741963_1139, duration: 31849800
2021-05-31 19:33:41,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741963_1139, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:34:02,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741964_1140 src: /10.191.53.85:53986 dest: /10.191.53.85:50010
2021-05-31 19:34:02,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:53986, dest: /10.191.53.85:50010, bytes: 273436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1949910088_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741964_1140, duration: 41174400
2021-05-31 19:34:02,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741964_1140, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:34:02,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741965_1141 src: /10.191.53.85:53987 dest: /10.191.53.85:50010
2021-05-31 19:34:02,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:53987, dest: /10.191.53.85:50010, bytes: 126, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1949910088_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741965_1141, duration: 2038500
2021-05-31 19:34:02,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741965_1141, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:34:02,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741966_1142 src: /10.191.53.85:53988 dest: /10.191.53.85:50010
2021-05-31 19:34:02,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:53988, dest: /10.191.53.85:50010, bytes: 29, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1949910088_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741966_1142, duration: 2226200
2021-05-31 19:34:02,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741966_1142, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:34:03,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741967_1143 src: /10.191.53.85:53989 dest: /10.191.53.85:50010
2021-05-31 19:34:03,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:53989, dest: /10.191.53.85:50010, bytes: 97403, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1949910088_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741967_1143, duration: 2498100
2021-05-31 19:34:03,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741967_1143, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:34:08,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741968_1144 src: /10.191.53.85:50149 dest: /10.191.53.85:50010
2021-05-31 19:34:08,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:50149, dest: /10.191.53.85:50010, bytes: 115826, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_735513374_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741968_1144, duration: 29782900
2021-05-31 19:34:08,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741968_1144, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:34:13,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741969_1145 src: /10.191.53.85:54335 dest: /10.191.53.85:50010
2021-05-31 19:34:17,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741970_1146 src: /10.191.53.85:61701 dest: /10.191.53.85:50010
2021-05-31 19:34:18,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:61701, dest: /10.191.53.85:50010, bytes: 50, op: HDFS_WRITE, cliID: DFSClient_attempt_1622458832718_0008_r_000000_0_-1262499070_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741970_1146, duration: 33178800
2021-05-31 19:34:18,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741970_1146, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:34:18,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:54335, dest: /10.191.53.85:50010, bytes: 33669, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_735513374_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741969_1145, duration: 5319015900
2021-05-31 19:34:18,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741969_1145, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:34:18,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741971_1147 src: /10.191.53.85:61703 dest: /10.191.53.85:50010
2021-05-31 19:34:18,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:61703, dest: /10.191.53.85:50010, bytes: 347, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_735513374_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741971_1147, duration: 2358000
2021-05-31 19:34:18,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741971_1147, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:34:18,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741972_1148 src: /10.191.53.85:61705 dest: /10.191.53.85:50010
2021-05-31 19:34:18,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:61705, dest: /10.191.53.85:50010, bytes: 33669, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_735513374_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741972_1148, duration: 2617000
2021-05-31 19:34:18,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741972_1148, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:34:18,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741973_1149 src: /10.191.53.85:61706 dest: /10.191.53.85:50010
2021-05-31 19:34:18,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:61706, dest: /10.191.53.85:50010, bytes: 115826, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_735513374_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741973_1149, duration: 3194700
2021-05-31 19:34:18,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741973_1149, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:34:23,356 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741968_1144 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741968 for deletion
2021-05-31 19:34:23,357 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741969_1145 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741969 for deletion
2021-05-31 19:34:23,357 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741964_1140 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741964 for deletion
2021-05-31 19:34:23,357 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741965_1141 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741965 for deletion
2021-05-31 19:34:23,357 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741966_1142 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741966 for deletion
2021-05-31 19:34:23,357 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741967_1143 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741967 for deletion
2021-05-31 19:34:23,358 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741968_1144 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741968
2021-05-31 19:34:23,360 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741969_1145 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741969
2021-05-31 19:34:23,361 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741964_1140 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741964
2021-05-31 19:34:23,362 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741965_1141 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741965
2021-05-31 19:34:23,363 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741966_1142 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741966
2021-05-31 19:34:23,364 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741967_1143 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741967
2021-05-31 19:34:25,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741974_1150 src: /10.191.53.85:62733 dest: /10.191.53.85:50010
2021-05-31 19:34:25,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:62733, dest: /10.191.53.85:50010, bytes: 46519, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1232899637_517, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741974_1150, duration: 3100700
2021-05-31 19:34:25,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741974_1150, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-05-31 19:34:35,384 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741971_1147 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741971 for deletion
2021-05-31 19:34:35,386 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741971_1147 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741971
2021-05-31 19:43:09,570 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-05-31 19:43:15,122 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-31 19:43:15,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-05 09:40:13,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-05 09:40:13,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-05 09:40:14,814 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-05 09:40:15,073 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-05 09:40:15,073 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-05 09:40:15,079 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-06-05 09:40:15,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-06-05 09:40:15,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-05 09:40:15,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-05 09:40:15,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-05 09:40:15,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-05 09:40:15,385 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-05 09:40:15,392 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-05 09:40:15,409 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-05 09:40:15,431 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-05 09:40:15,434 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-05 09:40:15,434 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-05 09:40:15,434 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-05 09:40:15,462 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 56241
2021-06-05 09:40:15,462 INFO org.mortbay.log: jetty-6.1.26
2021-06-05 09:40:16,073 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:56241
2021-06-05 09:40:16,262 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-06-05 09:40:16,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-05 09:40:16,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-05 09:40:23,419 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-05 09:40:23,440 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-05 09:40:23,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-05 09:40:23,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-05 09:40:23,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-06-05 09:40:23,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-06-05 09:40:23,669 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-05 09:40:23,669 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-05 09:40:43,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); maxRetries=45
2021-06-05 09:41:03,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); maxRetries=45
2021-06-05 09:41:23,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); maxRetries=45
2021-06-05 09:41:43,404 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-05 09:41:43,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-13 23:51:09,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-13 23:51:09,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-13 23:51:10,528 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-13 23:51:10,663 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-13 23:51:10,663 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-13 23:51:10,676 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-06-13 23:51:10,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-06-13 23:51:10,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-13 23:51:10,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-13 23:51:10,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-13 23:51:10,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-13 23:51:10,952 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-13 23:51:10,962 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-13 23:51:10,969 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-13 23:51:10,978 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-13 23:51:10,980 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-13 23:51:10,980 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-13 23:51:10,981 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-13 23:51:11,001 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 55315
2021-06-13 23:51:11,001 INFO org.mortbay.log: jetty-6.1.26
2021-06-13 23:51:11,227 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:55315
2021-06-13 23:51:11,533 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-06-13 23:51:11,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-13 23:51:11,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-13 23:51:11,924 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-13 23:51:11,951 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-13 23:51:11,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-13 23:51:12,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-13 23:51:12,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-06-13 23:51:12,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-06-13 23:51:12,143 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-13 23:51:12,143 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-13 23:51:13,007 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 657@DESKTOP-TSQQRSN
2021-06-13 23:51:13,134 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1542253369-10.191.53.85-1622264819009
2021-06-13 23:51:13,134 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009
2021-06-13 23:51:13,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2005162102;bpid=BP-1542253369-10.191.53.85-1622264819009;lv=-56;nsInfo=lv=-63;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0;bpid=BP-1542253369-10.191.53.85-1622264819009;dnuuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-13 23:51:13,229 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-77177884-7e39-4105-ae4c-bdc787c546af
2021-06-13 23:51:13,230 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-06-13 23:51:13,337 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-06-13 23:51:13,339 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-13 23:51:13,341 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-06-13 23:51:13,535 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1542253369-10.191.53.85-1622264819009 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 193ms
2021-06-13 23:51:13,535 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1542253369-10.191.53.85-1622264819009: 196ms
2021-06-13 23:51:13,537 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-06-13 23:51:13,553 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 16ms
2021-06-13 23:51:13,553 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 17ms
2021-06-13 23:51:14,724 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): no suitable block pools found to scan.  Waiting 479787709 ms.
2021-06-13 23:51:14,728 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1623602255727 with interval 21600000
2021-06-13 23:51:14,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-06-13 23:51:14,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-06-13 23:51:14,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-06-13 23:51:15,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=1184
2021-06-13 23:51:15,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-13 23:51:15,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1502507a280,  containing 1 storage report(s), of which we sent 1. The reports had 69 total blocks and used 1 RPC(s). This took 8 msec to generate and 142 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-06-13 23:51:15,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-13 23:51:53,946 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-06-13 23:51:57,944 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-13 23:51:57,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-14 18:57:58,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-14 18:57:58,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-14 18:57:59,092 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-14 18:57:59,160 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-14 18:57:59,160 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-14 18:57:59,195 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-06-14 18:57:59,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-06-14 18:57:59,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-14 18:57:59,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-14 18:57:59,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-14 18:57:59,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-14 18:57:59,431 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-14 18:57:59,439 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-14 18:57:59,446 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-14 18:57:59,451 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-14 18:57:59,453 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-14 18:57:59,453 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-14 18:57:59,453 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-14 18:57:59,468 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 51139
2021-06-14 18:57:59,468 INFO org.mortbay.log: jetty-6.1.26
2021-06-14 18:57:59,641 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:51139
2021-06-14 18:57:59,981 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-06-14 18:58:00,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-14 18:58:00,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-14 18:58:00,244 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-14 18:58:00,262 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-14 18:58:00,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-14 18:58:00,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-14 18:58:00,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-06-14 18:58:00,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-06-14 18:58:00,411 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-14 18:58:00,411 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-14 18:58:00,992 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 515@DESKTOP-TSQQRSN
2021-06-14 18:58:01,051 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1542253369-10.191.53.85-1622264819009
2021-06-14 18:58:01,051 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009
2021-06-14 18:58:01,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2005162102;bpid=BP-1542253369-10.191.53.85-1622264819009;lv=-56;nsInfo=lv=-63;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0;bpid=BP-1542253369-10.191.53.85-1622264819009;dnuuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-14 18:58:01,115 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-77177884-7e39-4105-ae4c-bdc787c546af
2021-06-14 18:58:01,115 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-06-14 18:58:01,150 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-06-14 18:58:01,150 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-14 18:58:01,151 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-06-14 18:58:01,420 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1542253369-10.191.53.85-1622264819009 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 268ms
2021-06-14 18:58:01,420 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1542253369-10.191.53.85-1622264819009: 269ms
2021-06-14 18:58:01,420 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-06-14 18:58:01,430 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 10ms
2021-06-14 18:58:01,430 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 11ms
2021-06-14 18:58:01,713 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): no suitable block pools found to scan.  Waiting 410980720 ms.
2021-06-14 18:58:01,717 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1623684791717 with interval 21600000
2021-06-14 18:58:01,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-06-14 18:58:01,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-06-14 18:58:01,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-06-14 18:58:01,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=1194
2021-06-14 18:58:01,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-14 18:58:02,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x162438369f8,  containing 1 storage report(s), of which we sent 1. The reports had 69 total blocks and used 1 RPC(s). This took 7 msec to generate and 93 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-06-14 18:58:02,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-14 18:59:04,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741960_1136 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741960 for deletion
2021-06-14 18:59:04,834 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741961_1137 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741961 for deletion
2021-06-14 18:59:04,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741929_1105 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741929 for deletion
2021-06-14 18:59:04,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741834_1010 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741834 for deletion
2021-06-14 18:59:04,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741930_1106 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741930 for deletion
2021-06-14 18:59:04,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741835_1011 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
2021-06-14 18:59:04,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741874_1050 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741874 for deletion
2021-06-14 18:59:04,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741906_1082 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741906 for deletion
2021-06-14 18:59:04,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741875_1051 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741875 for deletion
2021-06-14 18:59:04,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741907_1083 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741907 for deletion
2021-06-14 18:59:04,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741972_1148 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741972 for deletion
2021-06-14 18:59:04,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741973_1149 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741973 for deletion
2021-06-14 18:59:04,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741949_1125 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741949 for deletion
2021-06-14 18:59:04,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741917_1093 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741917 for deletion
2021-06-14 18:59:04,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741885_1061 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741885 for deletion
2021-06-14 18:59:04,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741918_1094 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741918 for deletion
2021-06-14 18:59:04,837 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741886_1062 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741886 for deletion
2021-06-14 18:59:04,837 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741950_1126 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741950 for deletion
2021-06-14 18:59:04,850 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741960_1136 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741960
2021-06-14 18:59:04,863 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741961_1137 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741961
2021-06-14 18:59:04,865 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741929_1105 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741929
2021-06-14 18:59:04,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741834_1010 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741834
2021-06-14 18:59:04,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741930_1106 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741930
2021-06-14 18:59:04,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741835_1011 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741835
2021-06-14 18:59:04,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741874_1050 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741874
2021-06-14 18:59:04,870 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741906_1082 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741906
2021-06-14 18:59:04,872 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741875_1051 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741875
2021-06-14 18:59:04,873 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741907_1083 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741907
2021-06-14 18:59:04,876 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741972_1148 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741972
2021-06-14 18:59:04,877 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741973_1149 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741973
2021-06-14 18:59:04,877 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741949_1125 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741949
2021-06-14 18:59:04,878 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741917_1093 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741917
2021-06-14 18:59:04,880 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741885_1061 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741885
2021-06-14 18:59:04,881 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741918_1094 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741918
2021-06-14 18:59:04,883 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741886_1062 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741886
2021-06-14 18:59:04,884 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741950_1126 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741950
2021-06-14 19:11:29,116 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-06-14 19:11:33,243 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-14 19:11:33,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-14 19:16:38,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-14 19:16:38,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-14 19:16:39,426 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-14 19:16:39,499 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-14 19:16:39,499 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-14 19:16:39,505 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-06-14 19:16:39,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-06-14 19:16:39,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-14 19:16:39,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-14 19:16:39,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-14 19:16:39,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-14 19:16:39,737 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-14 19:16:39,758 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-14 19:16:39,769 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-14 19:16:39,777 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-14 19:16:39,780 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-14 19:16:39,780 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-14 19:16:39,780 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-14 19:16:39,811 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 62866
2021-06-14 19:16:39,811 INFO org.mortbay.log: jetty-6.1.26
2021-06-14 19:16:39,980 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:62866
2021-06-14 19:16:40,156 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-06-14 19:16:40,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-14 19:16:40,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-14 19:16:40,432 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-14 19:16:40,449 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-14 19:16:40,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-14 19:16:40,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-14 19:16:40,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-06-14 19:16:40,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-06-14 19:16:40,555 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-14 19:16:40,555 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-14 19:16:41,491 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 3072@DESKTOP-TSQQRSN
2021-06-14 19:16:41,551 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1542253369-10.191.53.85-1622264819009
2021-06-14 19:16:41,552 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009
2021-06-14 19:16:41,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2005162102;bpid=BP-1542253369-10.191.53.85-1622264819009;lv=-56;nsInfo=lv=-63;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0;bpid=BP-1542253369-10.191.53.85-1622264819009;dnuuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-14 19:16:41,598 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-77177884-7e39-4105-ae4c-bdc787c546af
2021-06-14 19:16:41,598 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-06-14 19:16:41,635 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-06-14 19:16:41,635 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-14 19:16:41,636 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-06-14 19:16:41,644 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current: 1167360
2021-06-14 19:16:41,646 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1542253369-10.191.53.85-1622264819009 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 10ms
2021-06-14 19:16:41,646 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1542253369-10.191.53.85-1622264819009: 10ms
2021-06-14 19:16:41,647 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-06-14 19:16:41,655 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 9ms
2021-06-14 19:16:41,655 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 9ms
2021-06-14 19:16:41,865 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): no suitable block pools found to scan.  Waiting 409860568 ms.
2021-06-14 19:16:41,868 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1623685921868 with interval 21600000
2021-06-14 19:16:41,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-06-14 19:16:41,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-06-14 19:16:41,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-06-14 19:16:42,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=1215
2021-06-14 19:16:42,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-14 19:16:42,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2670d84eeac,  containing 1 storage report(s), of which we sent 1. The reports had 51 total blocks and used 1 RPC(s). This took 5 msec to generate and 75 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-06-14 19:16:42,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-14 19:31:37,623 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-06-14 19:31:40,859 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-14 19:31:40,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-20 21:01:11,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-20 21:01:11,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-20 21:01:12,731 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-20 21:01:12,806 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-20 21:01:12,806 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-20 21:01:12,884 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-06-20 21:01:12,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-06-20 21:01:12,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-20 21:01:13,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-20 21:01:13,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-20 21:01:13,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-20 21:01:13,278 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-20 21:01:13,289 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-20 21:01:13,311 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-20 21:01:13,316 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-20 21:01:13,318 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-20 21:01:13,318 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-20 21:01:13,319 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-20 21:01:13,337 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 61928
2021-06-20 21:01:13,337 INFO org.mortbay.log: jetty-6.1.26
2021-06-20 21:01:13,761 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:61928
2021-06-20 21:01:14,078 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-06-20 21:01:14,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-20 21:01:14,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-20 21:01:19,688 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-20 21:01:19,717 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-20 21:01:19,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-20 21:01:19,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-20 21:01:19,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-06-20 21:01:19,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-06-20 21:01:19,925 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-20 21:01:19,928 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-20 21:01:20,460 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 1040@DESKTOP-TSQQRSN
2021-06-20 21:01:20,540 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1542253369-10.191.53.85-1622264819009
2021-06-20 21:01:20,540 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009
2021-06-20 21:01:20,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2005162102;bpid=BP-1542253369-10.191.53.85-1622264819009;lv=-56;nsInfo=lv=-63;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0;bpid=BP-1542253369-10.191.53.85-1622264819009;dnuuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-20 21:01:20,593 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-77177884-7e39-4105-ae4c-bdc787c546af
2021-06-20 21:01:20,593 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-06-20 21:01:20,634 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-06-20 21:01:20,635 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-20 21:01:20,635 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-06-20 21:01:20,672 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1542253369-10.191.53.85-1622264819009 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 36ms
2021-06-20 21:01:20,672 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1542253369-10.191.53.85-1622264819009: 37ms
2021-06-20 21:01:20,672 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-06-20 21:01:20,680 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 8ms
2021-06-20 21:01:20,680 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 8ms
2021-06-20 21:01:21,082 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now rescanning bpid BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data, after more than 504 hour(s)
2021-06-20 21:01:21,097 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1624208323097 with interval 21600000
2021-06-20 21:01:21,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-06-20 21:01:21,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-06-20 21:01:21,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-06-20 21:01:21,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=1216
2021-06-20 21:01:21,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-20 21:01:21,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xede956b62c8,  containing 1 storage report(s), of which we sent 1. The reports had 51 total blocks and used 1 RPC(s). This took 6 msec to generate and 74 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-06-20 21:01:21,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-20 21:02:22,113 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): finished scanning block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-20 21:02:22,120 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): no suitable block pools found to scan.  Waiting 1814338962 ms.
2021-06-20 21:24:10,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741975_1151 src: /10.191.53.85:54135 dest: /10.191.53.85:50010
2021-06-20 21:24:10,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:54135, dest: /10.191.53.85:50010, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-727550756_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741975_1151, duration: 46532000
2021-06-20 21:24:10,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741975_1151, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-20 21:28:17,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741976_1152 src: /10.191.53.85:59298 dest: /10.191.53.85:50010
2021-06-20 21:28:17,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:59298, dest: /10.191.53.85:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-477728251_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741976_1152, duration: 39072800
2021-06-20 21:28:17,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741976_1152, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-20 21:29:53,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741976_1152 src: /10.191.53.85:57696 dest: /10.191.53.85:50010
2021-06-20 21:29:53,918 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Appending to FinalizedReplica, blk_1073741976_1152, FINALIZED
  getNumBytes()     = 16
  getBytesOnDisk()  = 16
  getVisibleLength()= 16
  getVolume()       = /opt/hadoop-2.7.2/data/tmp/dfs/data/current
  getBlockFile()    = /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741976
  unlinked          =false
2021-06-20 21:29:54,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:57696, dest: /10.191.53.85:50010, bytes: 34, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-981909271_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741976_1153, duration: 53595400
2021-06-20 21:29:54,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741976_1153, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-20 21:39:18,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741977_1154 src: /10.191.53.85:55529 dest: /10.191.53.85:50010
2021-06-20 21:39:18,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55529, dest: /10.191.53.85:50010, bytes: 404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1177663384_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741977_1154, duration: 44467100
2021-06-20 21:39:18,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741977_1154, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-20 21:40:47,518 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741976_1153 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741976 for deletion
2021-06-20 21:40:47,521 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741976_1153 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741976
2021-06-20 21:42:32,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x111dfc1b10e0,  containing 1 storage report(s), of which we sent 1. The reports had 53 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-06-20 21:42:32,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-20 21:42:35,695 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741955_1131 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741955 for deletion
2021-06-20 21:42:35,695 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741876_1052 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741876 for deletion
2021-06-20 21:42:35,696 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741974_1150 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741974 for deletion
2021-06-20 21:42:35,696 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741912_1088 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741912 for deletion
2021-06-20 21:42:35,696 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741962_1138 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741962 for deletion
2021-06-20 21:42:35,696 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741931_1107 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741931 for deletion
2021-06-20 21:42:35,696 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741836_1012 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
2021-06-20 21:42:35,696 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741887_1063 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741887 for deletion
2021-06-20 21:42:35,697 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741919_1095 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741919 for deletion
2021-06-20 21:42:35,711 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741955_1131 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741955
2021-06-20 21:42:35,715 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741876_1052 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741876
2021-06-20 21:42:35,722 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741974_1150 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741974
2021-06-20 21:42:35,725 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741912_1088 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741912
2021-06-20 21:42:35,727 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741962_1138 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741962
2021-06-20 21:42:35,728 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741931_1107 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741931
2021-06-20 21:42:35,729 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741836_1012 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741836
2021-06-20 21:42:35,730 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741887_1063 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741887
2021-06-20 21:42:35,731 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741919_1095 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741919
2021-06-20 21:43:41,813 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741975_1151 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741975 for deletion
2021-06-20 21:43:41,815 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741975_1151 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741975
2021-06-20 21:44:11,876 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-06-20 21:44:17,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-20 21:44:19,264 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-20 21:44:19,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-21 18:40:35,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-21 18:40:35,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-21 18:40:36,100 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-21 18:40:36,168 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-21 18:40:36,168 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-21 18:40:36,175 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-06-21 18:40:36,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-06-21 18:40:36,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-21 18:40:36,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-21 18:40:36,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-21 18:40:36,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-21 18:40:36,369 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-21 18:40:36,377 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-21 18:40:36,384 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-21 18:40:36,389 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-21 18:40:36,390 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-21 18:40:36,390 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-21 18:40:36,391 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-21 18:40:36,406 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 62784
2021-06-21 18:40:36,406 INFO org.mortbay.log: jetty-6.1.26
2021-06-21 18:40:36,575 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:62784
2021-06-21 18:40:36,785 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-06-21 18:40:36,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-21 18:40:36,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-21 18:40:37,015 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-21 18:40:37,029 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-21 18:40:37,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-21 18:40:37,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-21 18:40:37,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-06-21 18:40:37,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-06-21 18:40:37,172 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-21 18:40:37,172 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-21 18:40:37,685 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 369@DESKTOP-TSQQRSN
2021-06-21 18:40:37,742 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1542253369-10.191.53.85-1622264819009
2021-06-21 18:40:37,742 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009
2021-06-21 18:40:37,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2005162102;bpid=BP-1542253369-10.191.53.85-1622264819009;lv=-56;nsInfo=lv=-63;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0;bpid=BP-1542253369-10.191.53.85-1622264819009;dnuuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-21 18:40:37,844 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-77177884-7e39-4105-ae4c-bdc787c546af
2021-06-21 18:40:37,845 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-06-21 18:40:37,878 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-06-21 18:40:37,878 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-21 18:40:37,879 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-06-21 18:40:38,051 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1542253369-10.191.53.85-1622264819009 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 171ms
2021-06-21 18:40:38,051 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1542253369-10.191.53.85-1622264819009: 173ms
2021-06-21 18:40:38,052 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-06-21 18:40:38,059 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 8ms
2021-06-21 18:40:38,059 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 8ms
2021-06-21 18:40:38,341 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): no suitable block pools found to scan.  Waiting 1736442741 ms.
2021-06-21 18:40:38,344 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1624272372344 with interval 21600000
2021-06-21 18:40:38,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-06-21 18:40:38,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-06-21 18:40:38,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-06-21 18:40:38,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=1246
2021-06-21 18:40:38,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-21 18:40:38,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x16eb15168c,  containing 1 storage report(s), of which we sent 1. The reports had 43 total blocks and used 1 RPC(s). This took 5 msec to generate and 99 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-06-21 18:40:38,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-21 18:46:12,373 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1542253369-10.191.53.85-1622264819009 Total blocks: 43, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2021-06-21 18:59:55,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741978_1155 src: /10.191.53.85:55406 dest: /10.191.53.85:50010
2021-06-21 18:59:55,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55406, dest: /10.191.53.85:50010, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_330630287_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741978_1155, duration: 47471200
2021-06-21 18:59:55,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741978_1155, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-21 19:00:50,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741978_1155 src: /10.191.53.85:56167 dest: /10.191.53.85:50010
2021-06-21 19:00:50,735 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Appending to FinalizedReplica, blk_1073741978_1155, FINALIZED
  getNumBytes()     = 4
  getBytesOnDisk()  = 4
  getVisibleLength()= 4
  getVolume()       = /opt/hadoop-2.7.2/data/tmp/dfs/data/current
  getBlockFile()    = /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741978
  unlinked          =false
2021-06-21 19:00:50,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:56167, dest: /10.191.53.85:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1201173458_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741978_1156, duration: 52591400
2021-06-21 19:00:50,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741978_1156, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-21 19:04:30,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741979_1157 src: /10.191.53.85:50065 dest: /10.191.53.85:50010
2021-06-21 19:04:30,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:50065, dest: /10.191.53.85:50010, bytes: 34, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-616012894_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741979_1157, duration: 41517500
2021-06-21 19:04:30,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741979_1157, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-21 19:07:47,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741980_1158 src: /10.191.53.85:57544 dest: /10.191.53.85:50010
2021-06-21 19:07:47,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:57544, dest: /10.191.53.85:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_446297674_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741980_1158, duration: 38156900
2021-06-21 19:07:47,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741980_1158, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-21 19:08:24,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741981_1159 src: /10.191.53.85:64741 dest: /10.191.53.85:50010
2021-06-21 19:08:24,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:64741, dest: /10.191.53.85:50010, bytes: 34, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-747635998_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741981_1159, duration: 38864600
2021-06-21 19:08:24,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741981_1159, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-21 19:09:08,281 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741980_1158 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741980 for deletion
2021-06-21 19:09:08,286 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741980_1158 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741980
2021-06-21 19:21:36,397 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741978_1156 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741978 for deletion
2021-06-21 19:21:36,398 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741981_1159 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741981 for deletion
2021-06-21 19:21:36,400 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741978_1156 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741978
2021-06-21 19:21:36,402 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741981_1159 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741981
2021-06-21 19:44:51,279 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741958_1134 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741958 for deletion
2021-06-21 19:44:51,280 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741963_1139 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741963 for deletion
2021-06-21 19:44:51,280 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741837_1013 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2021-06-21 19:44:51,280 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741838_1014 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
2021-06-21 19:44:51,280 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741839_1015 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2021-06-21 19:44:51,280 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741840_1016 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2021-06-21 19:44:51,280 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741841_1017 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2021-06-21 19:44:51,280 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741842_1018 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2021-06-21 19:44:51,281 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741970_1146 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741970 for deletion
2021-06-21 19:44:51,281 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741843_1019 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2021-06-21 19:44:51,281 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741844_1020 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2021-06-21 19:44:51,281 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741845_1021 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741845 for deletion
2021-06-21 19:44:51,281 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741846_1022 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741846 for deletion
2021-06-21 19:44:51,281 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741847_1023 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741847 for deletion
2021-06-21 19:44:51,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741848_1024 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741848 for deletion
2021-06-21 19:44:51,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741958_1134 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741958
2021-06-21 19:44:51,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741849_1025 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741849 for deletion
2021-06-21 19:44:51,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741850_1026 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741850 for deletion
2021-06-21 19:44:51,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741851_1027 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741851 for deletion
2021-06-21 19:44:51,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741852_1028 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741852 for deletion
2021-06-21 19:44:51,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741853_1029 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741853 for deletion
2021-06-21 19:44:51,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741854_1030 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741854 for deletion
2021-06-21 19:44:51,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741855_1031 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741855 for deletion
2021-06-21 19:44:51,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741856_1032 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741856 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741857_1033 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741857 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741858_1034 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741858 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741963_1139 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741963
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741860_1036 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741861_1037 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741863_1039 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741863 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741864_1040 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741864 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741865_1041 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741865 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741932_1108 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741932 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741933_1109 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741933 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741934_1110 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741934 for deletion
2021-06-21 19:44:51,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741935_1111 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741935 for deletion
2021-06-21 19:44:51,284 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741936_1112 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741936 for deletion
2021-06-21 19:44:51,284 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741872_1048 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741872 for deletion
2021-06-21 19:44:51,284 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741837_1013 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741837
2021-06-21 19:44:51,284 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741937_1113 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741937 for deletion
2021-06-21 19:44:51,284 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741938_1114 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741938 for deletion
2021-06-21 19:44:51,284 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741939_1115 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741939 for deletion
2021-06-21 19:44:51,284 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741940_1116 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741940 for deletion
2021-06-21 19:44:51,450 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741838_1014 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741838
2021-06-21 19:44:51,452 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741839_1015 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741839
2021-06-21 19:44:51,454 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741840_1016 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741840
2021-06-21 19:44:51,455 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741841_1017 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741841
2021-06-21 19:44:51,455 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741842_1018 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741842
2021-06-21 19:44:51,456 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741970_1146 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741970
2021-06-21 19:44:51,459 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741843_1019 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741843
2021-06-21 19:44:51,464 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741844_1020 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741844
2021-06-21 19:44:51,466 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741845_1021 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741845
2021-06-21 19:44:51,467 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741846_1022 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741846
2021-06-21 19:44:51,468 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741847_1023 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741847
2021-06-21 19:44:51,469 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741848_1024 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741848
2021-06-21 19:44:51,470 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741849_1025 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741849
2021-06-21 19:44:51,470 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741850_1026 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741850
2021-06-21 19:44:51,471 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741851_1027 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741851
2021-06-21 19:44:51,472 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741852_1028 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741852
2021-06-21 19:44:51,472 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741853_1029 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741853
2021-06-21 19:44:51,473 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741854_1030 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741854
2021-06-21 19:44:51,474 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741855_1031 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741855
2021-06-21 19:44:51,474 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741856_1032 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741856
2021-06-21 19:44:51,475 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741857_1033 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741857
2021-06-21 19:44:51,476 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741858_1034 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741858
2021-06-21 19:44:51,476 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741859_1035 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741859
2021-06-21 19:44:51,477 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741860_1036 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741860
2021-06-21 19:44:51,478 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741861_1037 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741861
2021-06-21 19:44:51,479 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741862_1038 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741862
2021-06-21 19:44:51,479 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741863_1039 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741863
2021-06-21 19:44:51,480 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741864_1040 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741864
2021-06-21 19:44:51,481 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741865_1041 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741865
2021-06-21 19:44:51,481 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741932_1108 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741932
2021-06-21 19:44:51,482 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741933_1109 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741933
2021-06-21 19:44:51,483 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741934_1110 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741934
2021-06-21 19:44:51,483 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741935_1111 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741935
2021-06-21 19:44:51,484 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741936_1112 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741936
2021-06-21 19:44:51,485 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741872_1048 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741872
2021-06-21 19:44:51,485 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741937_1113 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741937
2021-06-21 19:44:51,487 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741938_1114 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741938
2021-06-21 19:44:51,488 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741939_1115 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741939
2021-06-21 19:44:51,490 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741940_1116 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741940
2021-06-21 20:12:39,654 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741977_1154 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741977 for deletion
2021-06-21 20:12:39,657 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741977_1154 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741977
2021-06-21 20:15:11,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741982_1160 src: /10.191.53.85:49526 dest: /10.191.53.85:50010
2021-06-21 20:15:11,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:49526, dest: /10.191.53.85:50010, bytes: 404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1906973481_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741982_1160, duration: 55931300
2021-06-21 20:15:11,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741982_1160, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-21 20:28:14,829 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741982_1160 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741982 for deletion
2021-06-21 20:28:14,831 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741982_1160 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741982
2021-06-21 20:30:34,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741979_1157 src: /10.191.53.85:55027 dest: /10.191.53.85:50010
2021-06-21 20:30:34,715 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Appending to FinalizedReplica, blk_1073741979_1157, FINALIZED
  getNumBytes()     = 34
  getBytesOnDisk()  = 34
  getVisibleLength()= 34
  getVolume()       = /opt/hadoop-2.7.2/data/tmp/dfs/data/current
  getBlockFile()    = /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741979
  unlinked          =false
2021-06-21 20:30:34,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55027, dest: /10.191.53.85:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-512586312_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741979_1161, duration: 53282900
2021-06-21 20:30:34,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741979_1161, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-21 20:31:36,346 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741979_1161 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741979 for deletion
2021-06-21 20:31:36,348 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741979_1161 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741979
2021-06-21 20:35:06,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741983_1162 src: /10.191.53.85:50699 dest: /10.191.53.85:50010
2021-06-21 20:35:06,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:50699, dest: /10.191.53.85:50010, bytes: 34, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_25175107_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741983_1162, duration: 41511000
2021-06-21 20:35:06,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741983_1162, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-21 21:38:20,059 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-06-21 21:38:25,888 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-21 21:38:25,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-22 10:59:44,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-22 10:59:44,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-22 10:59:45,392 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-22 10:59:45,724 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-22 10:59:45,724 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-22 10:59:45,755 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-06-22 10:59:45,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-06-22 10:59:45,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-22 10:59:45,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-22 10:59:45,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-22 10:59:45,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-22 10:59:46,242 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-22 10:59:46,251 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-22 10:59:46,262 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-22 10:59:46,325 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-22 10:59:46,327 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-22 10:59:46,327 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-22 10:59:46,327 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-22 10:59:46,393 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 51322
2021-06-22 10:59:46,393 INFO org.mortbay.log: jetty-6.1.26
2021-06-22 10:59:46,942 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:51322
2021-06-22 10:59:47,189 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-06-22 10:59:47,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-22 10:59:47,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-22 10:59:48,098 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-22 10:59:48,134 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-22 10:59:48,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-22 10:59:48,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-22 10:59:48,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-06-22 10:59:48,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-06-22 10:59:48,300 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-22 10:59:48,300 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-22 11:00:08,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); maxRetries=45
2021-06-22 11:00:28,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 1 time(s); maxRetries=45
2021-06-22 11:00:48,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 2 time(s); maxRetries=45
2021-06-22 11:01:08,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 3 time(s); maxRetries=45
2021-06-22 11:01:28,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 4 time(s); maxRetries=45
2021-06-22 11:01:48,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 5 time(s); maxRetries=45
2021-06-22 11:02:03,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: DESKTOP-TSQQRSN/10.191.53.85:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-06-22 11:02:03,738 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-22 11:02:03,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-22 11:02:42,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-22 11:02:42,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-22 11:02:42,842 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-22 11:02:42,908 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-22 11:02:42,908 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-06-22 11:02:42,914 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-06-22 11:02:42,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is DESKTOP-TSQQRSN
2021-06-22 11:02:42,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-06-22 11:02:42,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-06-22 11:02:42,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-06-22 11:02:42,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-06-22 11:02:43,057 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-22 11:02:43,065 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-22 11:02:43,071 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-06-22 11:02:43,077 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-22 11:02:43,078 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-06-22 11:02:43,078 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-22 11:02:43,079 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-22 11:02:43,092 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 49202
2021-06-22 11:02:43,092 INFO org.mortbay.log: jetty-6.1.26
2021-06-22 11:02:43,214 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:49202
2021-06-22 11:02:43,343 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-06-22 11:02:43,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-06-22 11:02:43,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-06-22 11:02:43,820 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-22 11:02:43,836 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-06-22 11:02:43,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-06-22 11:02:43,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-06-22 11:02:43,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-06-22 11:02:43,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to DESKTOP-TSQQRSN/10.191.53.85:9000 starting to offer service
2021-06-22 11:02:43,913 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-22 11:02:43,913 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-06-22 11:02:44,311 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/data/in_use.lock acquired by nodename 1842@DESKTOP-TSQQRSN
2021-06-22 11:02:44,367 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1542253369-10.191.53.85-1622264819009
2021-06-22 11:02:44,367 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009
2021-06-22 11:02:44,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2005162102;bpid=BP-1542253369-10.191.53.85-1622264819009;lv=-56;nsInfo=lv=-63;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0;bpid=BP-1542253369-10.191.53.85-1622264819009;dnuuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-22 11:02:44,426 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-77177884-7e39-4105-ae4c-bdc787c546af
2021-06-22 11:02:44,426 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /opt/hadoop-2.7.2/data/tmp/dfs/data/current, StorageType: DISK
2021-06-22 11:02:44,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-06-22 11:02:44,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-22 11:02:44,459 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-06-22 11:02:44,576 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1542253369-10.191.53.85-1622264819009 on /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 118ms
2021-06-22 11:02:44,576 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1542253369-10.191.53.85-1622264819009: 118ms
2021-06-22 11:02:44,577 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current...
2021-06-22 11:02:44,582 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1542253369-10.191.53.85-1622264819009 on volume /opt/hadoop-2.7.2/data/tmp/dfs/data/current: 5ms
2021-06-22 11:02:44,582 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 6ms
2021-06-22 11:02:45,232 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/opt/hadoop-2.7.2/data/tmp/dfs/data, DS-77177884-7e39-4105-ae4c-bdc787c546af): no suitable block pools found to scan.  Waiting 1677515850 ms.
2021-06-22 11:02:45,235 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1624350204235 with interval 21600000
2021-06-22 11:02:45,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 beginning handshake with NN
2021-06-22 11:02:45,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid null) service to DESKTOP-TSQQRSN/10.191.53.85:9000 successfully registered with NN
2021-06-22 11:02:45,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode DESKTOP-TSQQRSN/10.191.53.85:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-06-22 11:02:45,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000 trying to claim ACTIVE state with txid=1369
2021-06-22 11:02:45,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1542253369-10.191.53.85-1622264819009 (Datanode Uuid 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52) service to DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-22 11:02:45,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x37ceb85848,  containing 1 storage report(s), of which we sent 1. The reports had 1 total blocks and used 1 RPC(s). This took 5 msec to generate and 72 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-06-22 11:02:45,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-22 13:44:11,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x906d2e0cd88,  containing 1 storage report(s), of which we sent 1. The reports had 1 total blocks and used 1 RPC(s). This took 1 msec to generate and 377 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-06-22 13:44:11,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-22 13:46:41,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741984_1163 src: /10.191.53.85:49743 dest: /10.191.53.85:50010
2021-06-22 13:46:41,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:49743, dest: /10.191.53.85:50010, bytes: 404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_648353265_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741984_1163, duration: 144882500
2021-06-22 13:46:41,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741984_1163, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-22 13:57:39,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741985_1164 src: /10.191.53.85:52762 dest: /10.191.53.85:50010
2021-06-22 13:57:39,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:52762, dest: /10.191.53.85:50010, bytes: 404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1298327709_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741985_1164, duration: 41913600
2021-06-22 13:57:39,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741985_1164, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-22 13:58:21,448 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741984_1163 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741984 for deletion
2021-06-22 13:58:21,455 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741984_1163 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741984
2021-06-22 13:58:33,428 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741985_1164 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741985 for deletion
2021-06-22 13:58:33,432 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741985_1164 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741985
2021-06-22 15:19:30,504 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 129229ms
No GCs detected
2021-06-22 16:23:24,282 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1542253369-10.191.53.85-1622264819009 Total blocks: 1, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2021-06-22 18:08:23,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741986_1165 src: /10.191.53.85:58517 dest: /10.191.53.85:50010
2021-06-22 18:08:23,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:58517, dest: /10.191.53.85:50010, bytes: 2239, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_367191016_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741986_1165, duration: 57743200
2021-06-22 18:08:23,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741986_1165, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-22 19:44:12,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cac617b5834,  containing 1 storage report(s), of which we sent 1. The reports had 2 total blocks and used 1 RPC(s). This took 2 msec to generate and 26 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-06-22 19:44:12,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1542253369-10.191.53.85-1622264819009
2021-06-22 21:12:09,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741987_1166 src: /10.191.53.85:62240 dest: /10.191.53.85:50010
2021-06-22 21:12:09,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:62240, dest: /10.191.53.85:50010, bytes: 34, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-296689884_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741987_1166, duration: 60815400
2021-06-22 21:12:09,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741987_1166, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-22 21:12:39,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1542253369-10.191.53.85-1622264819009:blk_1073741987_1166 src: /10.191.53.85:55500 dest: /10.191.53.85:50010
2021-06-22 21:12:39,136 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Appending to FinalizedReplica, blk_1073741987_1166, FINALIZED
  getNumBytes()     = 34
  getBytesOnDisk()  = 34
  getVisibleLength()= 34
  getVolume()       = /opt/hadoop-2.7.2/data/tmp/dfs/data/current
  getBlockFile()    = /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741987
  unlinked          =false
2021-06-22 21:12:39,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.191.53.85:55500, dest: /10.191.53.85:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-560418414_1, offset: 0, srvID: 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, blockid: BP-1542253369-10.191.53.85-1622264819009:blk_1073741987_1167, duration: 73119300
2021-06-22 21:12:39,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1542253369-10.191.53.85-1622264819009:blk_1073741987_1167, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-06-22 21:14:29,395 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741987_1167 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741987 for deletion
2021-06-22 21:14:29,400 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741987_1167 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741987
2021-06-22 21:15:29,569 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741983_1162 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741983 for deletion
2021-06-22 21:15:29,572 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1542253369-10.191.53.85-1622264819009 blk_1073741983_1162 file /opt/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1542253369-10.191.53.85-1622264819009/current/finalized/subdir0/subdir0/blk_1073741983
2021-06-22 21:22:15,327 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "DESKTOP-TSQQRSN/10.191.53.85"; destination host is: "DESKTOP-TSQQRSN":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2021-06-22 21:22:20,766 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-22 21:22:20,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
