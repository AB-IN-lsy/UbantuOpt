2021-05-25 14:21:34,190 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-25 14:21:34,197 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-25 14:21:34,202 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-25 14:21:35,072 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-25 14:21:36,373 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-25 14:21:36,373 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-25 14:21:36,386 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2021-05-25 14:21:36,389 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2021-05-25 14:21:37,823 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-25 14:21:38,422 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-25 14:21:38,441 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-25 14:21:38,544 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-25 14:21:38,563 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-25 14:21:38,570 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-25 14:21:38,570 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-25 14:21:38,571 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-25 14:21:38,798 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-25 14:21:38,801 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-25 14:21:39,208 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-25 14:21:39,208 INFO org.mortbay.log: jetty-6.1.26
2021-05-25 14:21:41,584 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-25 14:21:41,722 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-25 14:21:41,722 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-25 14:21:41,831 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-25 14:21:41,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-25 14:21:41,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-25 14:21:41,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-25 14:21:41,946 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-25 14:21:41,949 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 25 14:21:41
2021-05-25 14:21:41,954 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-25 14:21:41,954 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-25 14:21:41,957 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-25 14:21:41,957 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-25 14:21:41,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-25 14:21:41,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-25 14:21:41,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-25 14:21:41,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-25 14:21:41,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-25 14:21:41,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-25 14:21:41,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-25 14:21:41,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-25 14:21:42,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-25 14:21:42,002 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-25 14:21:42,002 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-25 14:21:42,003 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-25 14:21:42,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-25 14:21:42,600 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-25 14:21:42,600 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-25 14:21:42,600 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-25 14:21:42,601 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-25 14:21:42,602 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-25 14:21:42,602 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-25 14:21:42,602 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-25 14:21:42,602 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-25 14:21:42,618 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-25 14:21:42,618 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-25 14:21:42,618 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-25 14:21:42,618 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-25 14:21:42,622 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-25 14:21:42,622 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-25 14:21:42,622 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-25 14:21:42,629 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-25 14:21:42,630 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-25 14:21:42,630 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-25 14:21:42,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-25 14:21:42,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-25 14:21:42,637 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-25 14:21:42,637 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-25 14:21:42,637 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-25 14:21:42,637 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-25 14:21:42,712 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 255@DESKTOP-TSQQRSN.localdomain
2021-05-25 14:21:42,808 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2021-05-25 14:21:42,810 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2021-05-25 14:21:42,960 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-05-25 14:21:43,100 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-25 14:21:43,101 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2021-05-25 14:21:43,123 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-25 14:21:43,124 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2021-05-25 14:21:43,840 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-25 14:21:43,840 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1198 msecs
2021-05-25 14:21:46,609 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2021-05-25 14:21:47,049 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-25 14:21:47,245 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-25 14:21:47,547 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-25 14:21:47,869 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-25 14:21:47,869 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-25 14:21:47,870 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-25 14:21:47,871 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 6 secs
2021-05-25 14:21:47,871 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-05-25 14:21:47,872 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-05-25 14:21:47,949 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-25 14:21:47,951 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2021-05-25 14:21:47,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-25 14:21:47,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-25 14:21:47,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-25 14:21:47,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-25 14:21:47,953 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 82 msec
2021-05-25 14:21:48,238 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-25 14:21:48,239 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-25 14:21:48,251 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2021-05-25 14:21:48,252 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-25 14:21:48,270 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-25 14:22:41,185 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=41a0dad7-3f26-4b72-8e6f-6b063a25eb76, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-3d2fddef-6667-4fb7-81ab-9d11c7b2c2e6;nsid=283474137;c=0) storage 41a0dad7-3f26-4b72-8e6f-6b063a25eb76
2021-05-25 14:22:41,185 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-25 14:22:41,190 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2021-05-25 14:22:42,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-25 14:22:42,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-ff0c6f61-06a2-4db2-a868-33b42a7b5a6a for DN 127.0.0.1:50010
2021-05-25 14:22:42,828 INFO BlockStateChange: BLOCK* processReport: from storage DS-ff0c6f61-06a2-4db2-a868-33b42a7b5a6a node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=41a0dad7-3f26-4b72-8e6f-6b063a25eb76, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-3d2fddef-6667-4fb7-81ab-9d11c7b2c2e6;nsid=283474137;c=0), blocks: 0, hasStaleStorage: false, processing time: 23 msecs
2021-05-25 14:30:25,801 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-25 14:30:25,848 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-25 14:30:25,858 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-25 14:30:27,069 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-25 14:30:27,546 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-25 14:30:27,546 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-25 14:30:27,548 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
2021-05-25 14:30:27,550 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
2021-05-25 14:30:28,551 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-25 14:30:28,826 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-25 14:30:28,835 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-25 14:30:28,908 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-25 14:30:28,914 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-25 14:30:28,916 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-25 14:30:28,916 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-25 14:30:28,916 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-25 14:30:29,076 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-25 14:30:29,078 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-25 14:30:29,193 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-25 14:30:29,193 INFO org.mortbay.log: jetty-6.1.26
2021-05-25 14:30:29,912 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-25 14:30:30,099 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-25 14:30:30,099 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-25 14:30:30,258 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-25 14:30:30,258 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-25 14:30:30,412 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-25 14:30:30,412 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-25 14:30:30,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-25 14:30:30,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 25 14:30:30
2021-05-25 14:30:30,474 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-25 14:30:30,474 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-25 14:30:30,477 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-25 14:30:30,477 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-25 14:30:30,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-25 14:30:30,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-25 14:30:30,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-25 14:30:30,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-25 14:30:30,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-25 14:30:30,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-25 14:30:30,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-25 14:30:30,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-25 14:30:30,632 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-25 14:30:30,632 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-25 14:30:30,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-25 14:30:30,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-25 14:30:30,637 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-25 14:30:31,546 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-25 14:30:31,546 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-25 14:30:31,546 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-25 14:30:31,546 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-25 14:30:31,547 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-25 14:30:31,547 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-25 14:30:31,547 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-25 14:30:31,547 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-25 14:30:31,556 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-25 14:30:31,556 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-25 14:30:31,556 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-25 14:30:31,556 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-25 14:30:31,558 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-25 14:30:31,558 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-25 14:30:31,558 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-25 14:30:31,593 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-25 14:30:31,593 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-25 14:30:31,593 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-25 14:30:31,595 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-25 14:30:31,595 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-25 14:30:31,619 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-25 14:30:31,619 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-25 14:30:31,619 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-25 14:30:31,619 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-25 14:30:31,671 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 44@DESKTOP-TSQQRSN.localdomain
2021-05-25 14:30:31,785 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2021-05-25 14:30:31,887 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000001 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000001-0000000000000000001
2021-05-25 14:30:32,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-05-25 14:30:32,151 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-25 14:30:32,151 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2021-05-25 14:30:32,152 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2807bdeb expecting start txid #1
2021-05-25 14:30:32,152 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000001-0000000000000000001
2021-05-25 14:30:32,153 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/tmp/hadoop-root/dfs/name/current/edits_0000000000000000001-0000000000000000001' to transaction ID 1
2021-05-25 14:30:32,156 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000001-0000000000000000001 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-25 14:30:32,181 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-25 14:30:32,182 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2
2021-05-25 14:30:32,366 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-25 14:30:32,366 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 730 msecs
2021-05-25 14:30:32,925 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
2021-05-25 14:30:32,960 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-25 14:30:33,020 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-25 14:30:33,131 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-25 14:30:33,218 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-25 14:30:33,218 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-25 14:30:33,218 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-25 14:30:33,219 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 2 secs
2021-05-25 14:30:33,219 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-05-25 14:30:33,220 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-05-25 14:30:33,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-25 14:30:33,239 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2021-05-25 14:30:33,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-25 14:30:33,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-25 14:30:33,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-25 14:30:33,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-25 14:30:33,240 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 21 msec
2021-05-25 14:30:33,308 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-25 14:30:33,309 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-25 14:30:33,314 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
2021-05-25 14:30:33,314 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-25 14:30:33,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-25 14:31:59,680 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 54 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 4 
2021-05-25 14:37:04,517 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 76 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 6 
2021-05-25 14:37:04,719 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:50095 Call#5 Retry#0
java.io.IOException: File /user/root/input/core-site.xml._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1547)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNewBlockTargets(FSNamesystem.java:3107)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3031)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:724)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)
2021-05-25 14:39:15,207 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 7 Total time for transactions(ms): 77 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 8 
2021-05-25 14:39:15,403 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:50147 Call#5 Retry#0
java.io.IOException: File /user/root/input/WindowsPath.txt._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1547)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNewBlockTargets(FSNamesystem.java:3107)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3031)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:724)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)
2021-05-25 14:41:39,466 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 9 Total time for transactions(ms): 77 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 123 
2021-05-25 14:41:39,679 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 127.0.0.1:50212 Call#5 Retry#0
java.io.IOException: File /user/root/input/WindowsPath.txt._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1547)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNewBlockTargets(FSNamesystem.java:3107)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3031)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:724)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)
2021-05-25 14:41:42,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=41a0dad7-3f26-4b72-8e6f-6b063a25eb76, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-3d2fddef-6667-4fb7-81ab-9d11c7b2c2e6;nsid=283474137;c=0) storage 41a0dad7-3f26-4b72-8e6f-6b063a25eb76
2021-05-25 14:41:42,151 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-25 14:41:42,153 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2021-05-25 14:41:42,404 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-25 14:41:42,404 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-ff0c6f61-06a2-4db2-a868-33b42a7b5a6a for DN 127.0.0.1:50010
2021-05-25 14:41:42,598 INFO BlockStateChange: BLOCK* processReport: from storage DS-ff0c6f61-06a2-4db2-a868-33b42a7b5a6a node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=41a0dad7-3f26-4b72-8e6f-6b063a25eb76, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-3d2fddef-6667-4fb7-81ab-9d11c7b2c2e6;nsid=283474137;c=0), blocks: 0, hasStaleStorage: false, processing time: 7 msecs
2021-05-25 15:17:55,505 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 48792ms
No GCs detected
2021-05-25 19:30:16,795 INFO BlockStateChange: BLOCK* processReport: from storage DS-ff0c6f61-06a2-4db2-a868-33b42a7b5a6a node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=41a0dad7-3f26-4b72-8e6f-6b063a25eb76, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-3d2fddef-6667-4fb7-81ab-9d11c7b2c2e6;nsid=283474137;c=0), blocks: 0, hasStaleStorage: false, processing time: 384 msecs
2021-05-25 21:24:11,597 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-25 21:24:11,639 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-25 21:26:29,794 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-25 21:26:29,845 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-25 21:26:29,849 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-25 21:26:30,165 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-25 21:26:30,426 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-25 21:26:30,426 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-25 21:26:30,428 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-25 21:26:30,429 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-25 21:26:30,746 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-25 21:26:30,810 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-25 21:26:30,817 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-25 21:26:30,836 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-25 21:26:30,840 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-25 21:26:30,842 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-25 21:26:30,842 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-25 21:26:30,842 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-25 21:26:30,943 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-25 21:26:30,946 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-25 21:26:30,996 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-25 21:26:30,996 INFO org.mortbay.log: jetty-6.1.26
2021-05-25 21:26:31,275 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-25 21:26:36,356 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-25 21:26:36,357 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-25 21:26:36,428 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-25 21:26:36,428 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-25 21:26:36,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-25 21:26:36,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-25 21:26:36,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-25 21:26:36,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 25 21:26:36
2021-05-25 21:26:36,487 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-25 21:26:36,488 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-25 21:26:36,494 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-25 21:26:36,494 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-25 21:26:36,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-25 21:26:36,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-25 21:26:36,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-25 21:26:36,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-25 21:26:36,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-25 21:26:36,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-25 21:26:36,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-25 21:26:36,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-25 21:26:36,520 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-25 21:26:36,520 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-25 21:26:36,520 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-25 21:26:36,520 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-25 21:26:36,522 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-25 21:26:36,899 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-25 21:26:36,899 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-25 21:26:36,899 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-25 21:26:36,899 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-25 21:26:36,900 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-25 21:26:36,900 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-25 21:26:36,900 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-25 21:26:36,900 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-25 21:26:36,910 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-25 21:26:36,910 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-25 21:26:36,910 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-25 21:26:36,910 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-25 21:26:36,916 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-25 21:26:36,916 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-25 21:26:36,916 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-25 21:26:36,919 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-25 21:26:36,920 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-25 21:26:36,920 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-25 21:26:36,921 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-25 21:26:36,921 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-25 21:26:36,934 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-25 21:26:36,934 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-25 21:26:36,934 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-25 21:26:36,934 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-25 21:26:36,963 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 7312@DESKTOP-TSQQRSN.localdomain
2021-05-25 21:26:37,031 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-25 21:26:37,032 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2021-05-25 21:26:37,070 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-05-25 21:26:37,103 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-25 21:26:37,103 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000000
2021-05-25 21:26:37,134 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-05-25 21:26:37,134 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-05-25 21:26:37,285 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
2021-05-25 21:26:37,297 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2021-05-25 21:26:37,468 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-25 21:26:37,469 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 522 msecs
2021-05-25 21:26:38,167 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-25 21:26:38,199 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-25 21:26:38,258 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-25 21:26:38,295 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-25 21:26:38,341 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-25 21:26:38,341 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-25 21:26:38,341 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-25 21:26:38,342 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2021-05-25 21:26:38,342 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-05-25 21:26:38,342 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-05-25 21:26:38,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-25 21:26:38,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2021-05-25 21:26:38,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-25 21:26:38,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-25 21:26:38,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-25 21:26:38,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-25 21:26:38,350 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2021-05-25 21:26:38,429 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-25 21:26:38,429 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-25 21:26:38,434 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-25 21:26:38,434 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-25 21:26:38,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-25 21:26:42,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=b59d0002-a15c-41fc-8cc2-e7259ea1fe64, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-669bb093-4aad-46db-a358-5084b3d20f48;nsid=858105615;c=0) storage b59d0002-a15c-41fc-8cc2-e7259ea1fe64
2021-05-25 21:26:42,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-25 21:26:42,937 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2021-05-25 21:26:43,047 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-25 21:26:43,047 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-e02acc24-e10d-435a-912c-807057c6d093 for DN 127.0.0.1:50010
2021-05-25 21:26:43,094 INFO BlockStateChange: BLOCK* processReport: from storage DS-e02acc24-e10d-435a-912c-807057c6d093 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=b59d0002-a15c-41fc-8cc2-e7259ea1fe64, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-669bb093-4aad-46db-a358-5084b3d20f48;nsid=858105615;c=0), blocks: 0, hasStaleStorage: false, processing time: 2 msecs
2021-05-25 21:43:10,774 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 61 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-05-25 22:04:32,252 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2021-05-25 22:04:32,370 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-e02acc24-e10d-435a-912c-807057c6d093:NORMAL:127.0.0.1:50010|RBW]]} for /user/root/input/WindowsPath.txt._COPYING_
2021-05-25 22:04:32,710 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-e02acc24-e10d-435a-912c-807057c6d093:NORMAL:127.0.0.1:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/root/input/WindowsPath.txt._COPYING_
2021-05-25 22:04:32,710 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-05-25 22:04:32,723 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-e02acc24-e10d-435a-912c-807057c6d093:NORMAL:127.0.0.1:50010|RBW]]} size 42
2021-05-25 22:04:33,130 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/WindowsPath.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-190079206_1
2021-05-25 22:05:47,285 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 13 Total time for transactions(ms): 65 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 26 
2021-05-25 22:05:48,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-e02acc24-e10d-435a-912c-807057c6d093:NORMAL:127.0.0.1:50010|RBW]]} for /user/root/output/_temporary/0/_temporary/attempt_local213227243_0001_r_000000_0/part-r-00000
2021-05-25 22:05:48,258 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-e02acc24-e10d-435a-912c-807057c6d093:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-25 22:05:48,262 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_temporary/0/_temporary/attempt_local213227243_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_-856876756_1
2021-05-25 22:05:48,337 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-856876756_1
2021-05-25 22:12:34,082 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 26 Total time for transactions(ms): 67 Number of transactions batched in Syncs: 0 Number of syncs: 17 SyncTimes(ms): 35 
2021-05-25 22:12:34,083 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741826_1002 127.0.0.1:50010 
2021-05-25 22:12:36,377 INFO BlockStateChange: BLOCK* BlockManager: ask 127.0.0.1:50010 to delete [blk_1073741826_1002]
2021-05-25 22:12:53,788 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-e02acc24-e10d-435a-912c-807057c6d093:NORMAL:127.0.0.1:50010|RBW]]} for /user/root/output/_temporary/0/_temporary/attempt_local2061589101_0001_r_000000_0/part-r-00000
2021-05-25 22:12:53,867 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-e02acc24-e10d-435a-912c-807057c6d093:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-25 22:12:53,870 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_temporary/0/_temporary/attempt_local2061589101_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_-878156629_1
2021-05-25 22:12:53,915 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-878156629_1
2021-05-27 15:12:15,161 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 15:12:15,179 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 15:12:15,184 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-27 15:12:15,749 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 15:12:16,585 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 15:12:16,585 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-27 15:12:16,587 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-27 15:12:16,588 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-27 15:12:16,967 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-27 15:12:17,190 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 15:12:17,198 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 15:12:17,289 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-27 15:12:17,359 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 15:12:17,362 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-27 15:12:17,362 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 15:12:17,362 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 15:12:17,473 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-27 15:12:17,474 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-27 15:12:17,606 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-27 15:12:17,606 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 15:12:18,815 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-27 15:12:18,861 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 15:12:18,861 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 15:12:18,907 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-27 15:12:18,907 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-27 15:12:18,955 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-27 15:12:18,955 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-27 15:12:18,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-27 15:12:18,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 27 15:12:18
2021-05-27 15:12:18,959 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-27 15:12:18,959 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 15:12:18,961 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-27 15:12:18,961 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-27 15:12:18,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-27 15:12:18,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-27 15:12:18,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-27 15:12:18,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-27 15:12:18,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-27 15:12:18,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-27 15:12:18,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-27 15:12:18,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-27 15:12:19,002 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-27 15:12:19,003 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-27 15:12:19,003 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-27 15:12:19,003 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-27 15:12:19,007 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-27 15:12:19,277 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-27 15:12:19,277 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 15:12:19,277 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-27 15:12:19,277 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-27 15:12:19,278 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-27 15:12:19,278 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-27 15:12:19,278 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-27 15:12:19,278 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-27 15:12:19,289 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-27 15:12:19,289 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 15:12:19,289 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-27 15:12:19,289 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-27 15:12:19,290 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-27 15:12:19,290 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-27 15:12:19,290 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-27 15:12:19,294 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-27 15:12:19,294 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-27 15:12:19,294 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-27 15:12:19,296 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-27 15:12:19,296 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-27 15:12:19,300 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-27 15:12:19,300 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 15:12:19,300 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-27 15:12:19,300 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-27 15:12:19,312 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 2882@DESKTOP-TSQQRSN.localdomain
2021-05-27 15:12:19,369 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-27 15:12:19,370 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2021-05-27 15:12:19,506 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-05-27 15:12:19,742 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-27 15:12:19,742 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000000
2021-05-27 15:12:19,750 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-27 15:12:19,750 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2021-05-27 15:12:20,156 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-27 15:12:20,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 853 msecs
2021-05-27 15:12:24,300 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-27 15:12:24,354 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 15:12:24,387 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-27 15:12:24,576 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-27 15:12:24,658 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 15:12:24,658 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 15:12:24,658 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-27 15:12:24,659 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 5 secs
2021-05-27 15:12:24,659 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-05-27 15:12:24,659 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-05-27 15:12:24,668 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 15:12:24,669 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2021-05-27 15:12:24,670 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-27 15:12:24,670 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-27 15:12:24,670 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-27 15:12:24,670 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-27 15:12:24,670 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2021-05-27 15:12:24,821 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 15:12:24,822 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-27 15:12:24,827 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 15:12:24,827 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-27 15:12:24,833 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-27 15:16:14,026 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 15:16:14,032 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 15:17:08,377 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 15:17:08,384 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 15:17:08,390 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-27 15:17:08,657 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 15:17:08,733 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 15:17:08,733 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-27 15:17:08,736 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-27 15:17:08,736 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-27 15:17:08,922 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-27 15:17:08,975 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 15:17:08,982 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 15:17:08,995 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-27 15:17:09,000 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 15:17:09,002 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-27 15:17:09,002 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 15:17:09,002 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 15:17:09,022 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-27 15:17:09,024 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-27 15:17:09,036 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-27 15:17:09,036 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 15:17:09,144 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-27 15:17:09,180 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 15:17:09,180 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 15:17:09,218 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-27 15:17:09,218 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-27 15:17:09,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-27 15:17:09,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-27 15:17:09,266 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-27 15:17:09,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 27 15:17:09
2021-05-27 15:17:09,271 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-27 15:17:09,271 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 15:17:09,273 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-27 15:17:09,273 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-27 15:17:09,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-27 15:17:09,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-27 15:17:09,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-27 15:17:09,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-27 15:17:09,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-27 15:17:09,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-27 15:17:09,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-27 15:17:09,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-27 15:17:09,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-27 15:17:09,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-27 15:17:09,295 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-27 15:17:09,295 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-27 15:17:09,296 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-27 15:17:09,493 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-27 15:17:09,493 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 15:17:09,493 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-27 15:17:09,493 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-27 15:17:09,494 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-27 15:17:09,494 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-27 15:17:09,494 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-27 15:17:09,494 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-27 15:17:09,501 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-27 15:17:09,501 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 15:17:09,501 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-27 15:17:09,501 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-27 15:17:09,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-27 15:17:09,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-27 15:17:09,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-27 15:17:09,506 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-27 15:17:09,506 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-27 15:17:09,506 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-27 15:17:09,507 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-27 15:17:09,507 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-27 15:17:09,509 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-27 15:17:09,509 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 15:17:09,509 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-27 15:17:09,509 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-27 15:17:09,518 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 4081@DESKTOP-TSQQRSN.localdomain
2021-05-27 15:17:09,564 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-27 15:17:09,608 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000001
2021-05-27 15:17:09,647 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-05-27 15:17:09,675 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-27 15:17:09,675 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000000
2021-05-27 15:17:09,675 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2807bdeb expecting start txid #1
2021-05-27 15:17:09,675 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000001
2021-05-27 15:17:09,677 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000001' to transaction ID 1
2021-05-27 15:17:09,680 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000001 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-27 15:17:09,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-27 15:17:09,686 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2
2021-05-27 15:17:09,827 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-27 15:17:09,827 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 316 msecs
2021-05-27 15:17:10,044 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-27 15:17:10,049 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 15:17:10,059 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-27 15:17:10,080 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-27 15:17:10,099 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 15:17:10,099 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 15:17:10,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-27 15:17:10,099 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2021-05-27 15:17:10,099 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-05-27 15:17:10,099 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-05-27 15:17:10,106 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 15:17:10,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2021-05-27 15:17:10,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-27 15:17:10,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-27 15:17:10,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-27 15:17:10,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-27 15:17:10,108 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2021-05-27 15:17:10,131 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 15:17:10,131 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-27 15:17:10,135 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 15:17:10,135 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-27 15:17:10,139 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-27 15:21:11,081 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 15:21:11,084 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 15:29:03,697 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 15:29:03,705 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 15:29:03,709 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-27 15:29:03,972 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 15:29:04,048 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 15:29:04,048 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-27 15:29:04,050 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-27 15:29:04,051 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-27 15:29:04,230 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-27 15:29:04,282 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 15:29:04,289 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 15:29:04,303 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-27 15:29:04,307 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 15:29:04,309 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-27 15:29:04,309 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 15:29:04,309 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 15:29:04,329 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-27 15:29:04,331 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-27 15:29:04,343 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-27 15:29:04,344 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 15:29:04,450 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-27 15:29:04,491 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 15:29:04,492 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 15:29:04,528 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-27 15:29:04,528 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-27 15:29:04,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-27 15:29:04,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-27 15:29:04,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-27 15:29:04,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 27 15:29:04
2021-05-27 15:29:04,571 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-27 15:29:04,571 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 15:29:04,572 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-27 15:29:04,572 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-27 15:29:04,578 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-27 15:29:04,578 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-27 15:29:04,578 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-27 15:29:04,578 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-27 15:29:04,579 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-27 15:29:04,579 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-27 15:29:04,579 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-27 15:29:04,579 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-27 15:29:04,587 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-27 15:29:04,587 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-27 15:29:04,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-27 15:29:04,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-27 15:29:04,589 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-27 15:29:04,776 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-27 15:29:04,776 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 15:29:04,776 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-27 15:29:04,776 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-27 15:29:04,777 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-27 15:29:04,777 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-27 15:29:04,777 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-27 15:29:04,777 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-27 15:29:04,784 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-27 15:29:04,784 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 15:29:04,784 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-27 15:29:04,784 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-27 15:29:04,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-27 15:29:04,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-27 15:29:04,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-27 15:29:04,789 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-27 15:29:04,789 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-27 15:29:04,789 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-27 15:29:04,790 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-27 15:29:04,790 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-27 15:29:04,792 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-27 15:29:04,792 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 15:29:04,792 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-27 15:29:04,792 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-27 15:29:04,886 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 5325@DESKTOP-TSQQRSN.localdomain
2021-05-27 15:29:04,944 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-27 15:29:04,944 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2021-05-27 15:29:04,979 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-05-27 15:29:05,007 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-27 15:29:05,007 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000000
2021-05-27 15:29:05,014 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-27 15:29:05,015 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2021-05-27 15:29:05,165 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-27 15:29:05,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 371 msecs
2021-05-27 15:29:05,380 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-27 15:29:05,386 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 15:29:05,396 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-27 15:29:05,418 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-27 15:29:05,436 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 15:29:05,437 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 15:29:05,437 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-27 15:29:05,437 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2021-05-27 15:29:05,437 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-05-27 15:29:05,437 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-05-27 15:29:05,444 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 15:29:05,446 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2021-05-27 15:29:05,446 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-27 15:29:05,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-27 15:29:05,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-27 15:29:05,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-27 15:29:05,447 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2021-05-27 15:29:05,469 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 15:29:05,469 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-27 15:29:05,474 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 15:29:05,474 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-27 15:29:05,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-27 15:29:16,279 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0) storage 92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 15:29:16,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 15:29:16,280 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2021-05-27 15:29:16,412 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 15:29:16,412 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 for DN 127.0.0.1:50010
2021-05-27 15:29:16,483 INFO BlockStateChange: BLOCK* processReport: from storage DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0), blocks: 0, hasStaleStorage: false, processing time: 12 msecs
2021-05-27 15:31:36,665 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 41 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2021-05-27 15:47:50,363 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 42 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 6 
2021-05-27 15:47:50,444 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /user/root/input/wc.input._COPYING_
2021-05-27 15:47:50,740 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/root/input/wc.input._COPYING_
2021-05-27 15:47:50,740 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-05-27 15:47:50,755 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 53
2021-05-27 15:47:51,153 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/wc.input._COPYING_ is closed by DFSClient_NONMAPREDUCE_708297571_1
2021-05-27 15:52:34,635 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 13 Total time for transactions(ms): 42 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 9 
2021-05-27 15:52:35,397 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /user/root/output/_temporary/0/_temporary/attempt_local2138312505_0001_r_000000_0/part-r-00000
2021-05-27 15:52:35,477 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 15:52:35,480 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_temporary/0/_temporary/attempt_local2138312505_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_-935993219_1
2021-05-27 15:52:35,558 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-935993219_1
2021-05-27 17:34:19,222 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 26 Total time for transactions(ms): 43 Number of transactions batched in Syncs: 0 Number of syncs: 17 SyncTimes(ms): 16 
2021-05-27 17:34:19,223 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741826_1002 127.0.0.1:50010 
2021-05-27 17:34:19,802 INFO BlockStateChange: BLOCK* BlockManager: ask 127.0.0.1:50010 to delete [blk_1073741826_1002]
2021-05-27 17:36:33,209 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 31 Total time for transactions(ms): 44 Number of transactions batched in Syncs: 0 Number of syncs: 18 SyncTimes(ms): 17 
2021-05-27 17:36:33,687 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0001/job.jar
2021-05-27 17:36:33,912 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 17:36:33,916 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-181732907_1
2021-05-27 17:36:33,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0001/job.jar
2021-05-27 17:36:34,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0001/job.split
2021-05-27 17:36:34,065 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0001/job.split
2021-05-27 17:36:34,075 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 17:36:34,077 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0001/job.split is closed by DFSClient_NONMAPREDUCE_-181732907_1
2021-05-27 17:36:34,083 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0001/job.splitmetainfo
2021-05-27 17:36:34,091 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 17:36:34,092 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-181732907_1
2021-05-27 17:36:34,338 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0001/job.xml
2021-05-27 17:36:34,350 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 17:36:34,352 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-181732907_1
2021-05-27 17:41:12,272 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 60 Total time for transactions(ms): 47 Number of transactions batched in Syncs: 0 Number of syncs: 39 SyncTimes(ms): 46 
2021-05-27 17:41:12,342 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0002/job.jar
2021-05-27 17:41:12,461 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 17:41:12,467 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0002/job.jar is closed by DFSClient_NONMAPREDUCE_996484013_1
2021-05-27 17:41:12,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0002/job.jar
2021-05-27 17:41:12,524 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0002/job.split
2021-05-27 17:41:12,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0002/job.split
2021-05-27 17:41:12,544 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 17:41:12,546 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0002/job.split is closed by DFSClient_NONMAPREDUCE_996484013_1
2021-05-27 17:41:12,553 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0002/job.splitmetainfo
2021-05-27 17:41:12,655 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 17:41:12,658 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_996484013_1
2021-05-27 17:41:12,742 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0002/job.xml
2021-05-27 17:41:12,754 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 17:41:12,756 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0002/job.xml is closed by DFSClient_NONMAPREDUCE_996484013_1
2021-05-27 17:51:23,555 INFO BlockStateChange: BLOCK* processReport: from storage DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0), blocks: 9, hasStaleStorage: false, processing time: 7 msecs
2021-05-27 17:56:40,083 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 88 Total time for transactions(ms): 48 Number of transactions batched in Syncs: 0 Number of syncs: 59 SyncTimes(ms): 149 
2021-05-27 17:56:40,201 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0003/job.jar
2021-05-27 17:56:40,377 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 17:56:40,382 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0003/job.jar is closed by DFSClient_NONMAPREDUCE_-1705296237_1
2021-05-27 17:56:40,387 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0003/job.jar
2021-05-27 17:56:40,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0003/job.split
2021-05-27 17:56:40,458 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0003/job.split
2021-05-27 17:56:40,467 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 17:56:40,469 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0003/job.split is closed by DFSClient_NONMAPREDUCE_-1705296237_1
2021-05-27 17:56:40,477 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0003/job.splitmetainfo
2021-05-27 17:56:40,485 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 17:56:40,487 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0003/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1705296237_1
2021-05-27 17:56:40,676 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0003/job.xml
2021-05-27 17:56:40,686 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 17:56:40,688 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0003/job.xml is closed by DFSClient_NONMAPREDUCE_-1705296237_1
2021-05-27 18:06:34,870 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 121 Total time for transactions(ms): 48 Number of transactions batched in Syncs: 0 Number of syncs: 83 SyncTimes(ms): 177 
2021-05-27 18:06:34,949 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0004/job.jar
2021-05-27 18:06:35,083 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:06:35,086 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0004/job.jar is closed by DFSClient_NONMAPREDUCE_1893541551_1
2021-05-27 18:06:35,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0004/job.jar
2021-05-27 18:06:35,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0004/job.split
2021-05-27 18:06:35,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0004/job.split
2021-05-27 18:06:35,162 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:06:35,164 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0004/job.split is closed by DFSClient_NONMAPREDUCE_1893541551_1
2021-05-27 18:06:35,171 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0004/job.splitmetainfo
2021-05-27 18:06:35,179 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:06:35,181 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0004/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1893541551_1
2021-05-27 18:06:35,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0004/job.xml
2021-05-27 18:06:35,271 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:06:35,273 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0004/job.xml is closed by DFSClient_NONMAPREDUCE_1893541551_1
2021-05-27 18:11:57,606 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 149 Total time for transactions(ms): 50 Number of transactions batched in Syncs: 0 Number of syncs: 103 SyncTimes(ms): 188 
2021-05-27 18:11:57,683 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0005/job.jar
2021-05-27 18:11:57,806 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:11:57,809 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0005/job.jar is closed by DFSClient_NONMAPREDUCE_310915260_1
2021-05-27 18:11:57,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0005/job.jar
2021-05-27 18:11:57,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0005/job.split
2021-05-27 18:11:57,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0005/job.split
2021-05-27 18:11:57,997 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:11:57,999 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0005/job.split is closed by DFSClient_NONMAPREDUCE_310915260_1
2021-05-27 18:11:58,007 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0005/job.splitmetainfo
2021-05-27 18:11:58,015 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:11:58,017 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0005/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_310915260_1
2021-05-27 18:11:58,098 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0005/job.xml
2021-05-27 18:11:58,109 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:11:58,110 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622107629075_0005/job.xml is closed by DFSClient_NONMAPREDUCE_310915260_1
2021-05-27 18:15:54,707 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 18:15:54,713 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 18:17:50,526 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 18:17:50,535 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 18:17:50,539 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-27 18:17:50,823 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 18:17:50,906 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 18:17:50,906 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-27 18:17:50,908 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-27 18:17:50,909 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-27 18:17:51,236 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-27 18:17:51,338 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 18:17:51,358 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 18:17:51,374 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-27 18:17:51,384 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 18:17:51,388 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-27 18:17:51,388 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 18:17:51,388 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 18:17:51,425 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-27 18:17:51,427 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-27 18:17:51,462 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-27 18:17:51,462 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 18:17:51,719 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-27 18:17:51,793 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 18:17:51,793 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 18:17:51,885 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-27 18:17:51,885 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-27 18:17:51,945 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-27 18:17:51,945 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-27 18:17:51,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-27 18:17:51,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 27 18:17:51
2021-05-27 18:17:51,966 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-27 18:17:51,966 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 18:17:51,969 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-27 18:17:51,969 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-27 18:17:51,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-27 18:17:51,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-27 18:17:51,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-27 18:17:51,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-27 18:17:51,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-27 18:17:51,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-27 18:17:51,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-27 18:17:51,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-27 18:17:51,987 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-27 18:17:51,987 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-27 18:17:51,987 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-27 18:17:51,987 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-27 18:17:51,988 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-27 18:17:52,259 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-27 18:17:52,259 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 18:17:52,259 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-27 18:17:52,259 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-27 18:17:52,260 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-27 18:17:52,260 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-27 18:17:52,260 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-27 18:17:52,261 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-27 18:17:52,275 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-27 18:17:52,275 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 18:17:52,275 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-27 18:17:52,275 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-27 18:17:52,278 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-27 18:17:52,278 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-27 18:17:52,278 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-27 18:17:52,284 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-27 18:17:52,284 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-27 18:17:52,284 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-27 18:17:52,286 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-27 18:17:52,286 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-27 18:17:52,297 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-27 18:17:52,297 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 18:17:52,297 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-27 18:17:52,297 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-27 18:17:52,319 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 10154@DESKTOP-TSQQRSN.localdomain
2021-05-27 18:17:52,401 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-27 18:17:52,532 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000176
2021-05-27 18:17:52,585 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-05-27 18:17:52,667 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-27 18:17:52,668 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000000
2021-05-27 18:17:52,668 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@655ef322 expecting start txid #1
2021-05-27 18:17:52,668 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000176
2021-05-27 18:17:52,679 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000176' to transaction ID 1
2021-05-27 18:17:52,744 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000176 of size 1048576 edits # 176 loaded in 0 seconds
2021-05-27 18:17:52,745 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-05-27 18:17:52,745 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-05-27 18:17:52,924 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2021-05-27 18:17:52,932 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 177
2021-05-27 18:17:53,073 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-27 18:17:53,073 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 772 msecs
2021-05-27 18:17:53,380 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-27 18:17:53,386 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 18:17:53,396 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-27 18:17:53,425 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-27 18:17:53,482 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 18:17:53,482 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 18:17:53,483 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 21 blocks to reach the threshold 0.9990 of total blocks 21.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-27 18:17:53,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 18:17:53,516 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 18:17:53,516 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-27 18:17:53,520 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 18:17:53,520 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-27 18:17:53,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-27 18:18:02,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0) storage 92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 18:18:02,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 18:18:02,836 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2021-05-27 18:18:02,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 18:18:02,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 for DN 127.0.0.1:50010
2021-05-27 18:18:02,982 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 20 has reached the threshold 0.9990 of total blocks 21. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-27 18:18:02,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-27 18:18:02,983 INFO BlockStateChange: BLOCK* processReport: from storage DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0), blocks: 21, hasStaleStorage: false, processing time: 10 msecs
2021-05-27 18:18:02,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 21
2021-05-27 18:18:02,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-27 18:18:02,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 10
2021-05-27 18:18:02,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-27 18:18:02,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-27 18:18:02,985 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2021-05-27 18:18:23,124 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 21 has reached the threshold 0.9990 of total blocks 21. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-27 18:18:33,208 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 41 secs
2021-05-27 18:18:33,209 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-27 18:18:33,209 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-27 18:18:33,209 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 10 blocks
2021-05-27 18:19:13,976 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 138 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2021-05-27 18:19:14,067 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0001/job.jar
2021-05-27 18:19:14,335 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741847_1023{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0001/job.jar
2021-05-27 18:19:14,335 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-05-27 18:19:14,355 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741847_1023{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 273436
2021-05-27 18:19:14,746 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-576194475_1
2021-05-27 18:19:14,758 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0001/job.jar
2021-05-27 18:19:14,816 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0001/job.split
2021-05-27 18:19:14,828 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0001/job.split
2021-05-27 18:19:14,845 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:19:14,847 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0001/job.split is closed by DFSClient_NONMAPREDUCE_-576194475_1
2021-05-27 18:19:14,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0001/job.splitmetainfo
2021-05-27 18:19:14,865 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:19:14,867 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-576194475_1
2021-05-27 18:19:14,951 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0001/job.xml
2021-05-27 18:19:14,970 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:19:14,972 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-576194475_1
2021-05-27 18:31:19,595 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 30 Total time for transactions(ms): 141 Number of transactions batched in Syncs: 0 Number of syncs: 23 SyncTimes(ms): 19 
2021-05-27 18:31:19,677 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0002/job.jar
2021-05-27 18:31:19,798 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:31:19,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0002/job.jar is closed by DFSClient_NONMAPREDUCE_2127679153_1
2021-05-27 18:31:19,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0002/job.jar
2021-05-27 18:31:19,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0002/job.split
2021-05-27 18:31:19,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0002/job.split
2021-05-27 18:31:19,886 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:31:19,888 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0002/job.split is closed by DFSClient_NONMAPREDUCE_2127679153_1
2021-05-27 18:31:19,895 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0002/job.splitmetainfo
2021-05-27 18:31:19,903 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:31:19,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_2127679153_1
2021-05-27 18:31:19,984 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0002/job.xml
2021-05-27 18:31:19,994 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:31:19,996 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622110695752_0002/job.xml is closed by DFSClient_NONMAPREDUCE_2127679153_1
2021-05-27 18:33:09,215 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 18:33:09,219 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 18:33:45,714 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 18:33:45,721 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 18:33:45,725 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-27 18:33:45,988 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 18:33:46,071 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 18:33:46,071 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-27 18:33:46,073 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-27 18:33:46,074 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-27 18:33:46,243 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-27 18:33:46,299 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 18:33:46,306 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 18:33:46,320 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-27 18:33:46,325 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 18:33:46,327 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-27 18:33:46,327 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 18:33:46,327 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 18:33:46,349 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-27 18:33:46,350 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-27 18:33:46,363 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-27 18:33:46,363 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 18:33:46,468 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-27 18:33:46,502 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 18:33:46,502 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 18:33:46,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-27 18:33:46,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-27 18:33:46,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-27 18:33:46,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-27 18:33:46,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-27 18:33:46,587 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 27 18:33:46
2021-05-27 18:33:46,589 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-27 18:33:46,589 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 18:33:46,590 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-27 18:33:46,590 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-27 18:33:46,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-27 18:33:46,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-27 18:33:46,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-27 18:33:46,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-27 18:33:46,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-27 18:33:46,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-27 18:33:46,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-27 18:33:46,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-27 18:33:46,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-27 18:33:46,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-27 18:33:46,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-27 18:33:46,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-27 18:33:46,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-27 18:33:46,820 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-27 18:33:46,820 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 18:33:46,821 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-27 18:33:46,821 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-27 18:33:46,822 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-27 18:33:46,822 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-27 18:33:46,822 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-27 18:33:46,822 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-27 18:33:46,828 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-27 18:33:46,828 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 18:33:46,828 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-27 18:33:46,829 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-27 18:33:46,830 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-27 18:33:46,830 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-27 18:33:46,830 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-27 18:33:46,833 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-27 18:33:46,833 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-27 18:33:46,833 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-27 18:33:46,834 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-27 18:33:46,834 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-27 18:33:46,836 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-27 18:33:46,836 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 18:33:46,836 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-27 18:33:46,836 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-27 18:33:46,845 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 11904@DESKTOP-TSQQRSN.localdomain
2021-05-27 18:33:46,891 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-27 18:33:46,957 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000177 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000177-0000000000000000233
2021-05-27 18:33:46,987 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 38 INodes.
2021-05-27 18:33:47,078 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-27 18:33:47,079 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 176 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000176
2021-05-27 18:33:47,079 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@655ef322 expecting start txid #177
2021-05-27 18:33:47,079 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000177-0000000000000000233
2021-05-27 18:33:47,081 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000177-0000000000000000233' to transaction ID 177
2021-05-27 18:33:47,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000177-0000000000000000233 of size 1048576 edits # 57 loaded in 0 seconds
2021-05-27 18:33:47,107 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-27 18:33:47,108 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 234
2021-05-27 18:33:47,332 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-27 18:33:47,332 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 493 msecs
2021-05-27 18:33:47,471 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-27 18:33:47,477 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 18:33:47,487 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-27 18:33:47,509 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-27 18:33:47,528 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 18:33:47,528 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 18:33:47,528 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 29 blocks to reach the threshold 0.9990 of total blocks 29.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-27 18:33:47,534 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 18:33:47,561 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 18:33:47,561 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-27 18:33:47,565 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 18:33:47,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-27 18:33:47,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-27 18:33:58,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0) storage 92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 18:33:58,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 18:33:58,934 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2021-05-27 18:33:59,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 18:33:59,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 for DN 127.0.0.1:50010
2021-05-27 18:33:59,052 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 28 has reached the threshold 0.9990 of total blocks 29. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-27 18:33:59,052 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-27 18:33:59,054 INFO BlockStateChange: BLOCK* processReport: from storage DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0), blocks: 29, hasStaleStorage: false, processing time: 10 msecs
2021-05-27 18:33:59,056 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 29
2021-05-27 18:33:59,056 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-27 18:33:59,056 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 14
2021-05-27 18:33:59,056 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-27 18:33:59,056 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-27 18:33:59,056 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2021-05-27 18:34:19,113 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 29 has reached the threshold 0.9990 of total blocks 29. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-27 18:34:26,556 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.mkdirs from 127.0.0.1:62220 Call#5 Retry#0: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0001. Name node is in safe mode.
The reported blocks 29 has reached the threshold 0.9990 of total blocks 29. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds.
2021-05-27 18:34:26,568 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 127.0.0.1:62220 Call#6 Retry#0: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0001. Name node is in safe mode.
The reported blocks 29 has reached the threshold 0.9990 of total blocks 29. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds.
2021-05-27 18:34:29,168 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 42 secs
2021-05-27 18:34:29,169 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-27 18:34:29,169 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-27 18:34:29,169 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2021-05-27 18:38:53,566 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is already OFF
2021-05-27 18:39:01,909 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 8 
2021-05-27 18:39:02,007 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job.jar
2021-05-27 18:39:02,231 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741855_1031{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job.jar
2021-05-27 18:39:02,232 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-05-27 18:39:02,253 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741855_1031{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 273436
2021-05-27 18:39:02,664 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job.jar is closed by DFSClient_NONMAPREDUCE_706211513_1
2021-05-27 18:39:02,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job.jar
2021-05-27 18:39:02,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job.split
2021-05-27 18:39:02,744 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job.split
2021-05-27 18:39:02,754 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:39:02,756 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job.split is closed by DFSClient_NONMAPREDUCE_706211513_1
2021-05-27 18:39:02,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job.splitmetainfo
2021-05-27 18:39:02,774 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:39:02,776 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_706211513_1
2021-05-27 18:39:02,852 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job.xml
2021-05-27 18:39:02,864 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:39:02,866 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job.xml is closed by DFSClient_NONMAPREDUCE_706211513_1
2021-05-27 18:39:09,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job_1622111655401_0002_1_conf.xml
2021-05-27 18:39:09,835 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:39:09,839 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job_1622111655401_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1452325349_1
2021-05-27 18:39:14,721 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job_1622111655401_0002_1.jhist
2021-05-27 18:39:15,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job_1622111655401_0002_1.jhist for DFSClient_NONMAPREDUCE_1452325349_1
2021-05-27 18:39:20,289 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /user/root/output/_temporary/1/_temporary/attempt_1622111655401_0002_r_000000_0/part-r-00000
2021-05-27 18:39:20,420 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:39:20,423 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_temporary/1/_temporary/attempt_1622111655401_0002_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622111655401_0002_r_000000_0_1756284483_1
2021-05-27 18:39:20,576 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1452325349_1
2021-05-27 18:39:20,629 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1452325349_1
2021-05-27 18:39:20,635 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1452325349_1
2021-05-27 18:39:20,650 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 13175
2021-05-27 18:39:20,651 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622111655401_0002/job_1622111655401_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_1452325349_1
2021-05-27 18:39:20,657 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622111655401_0002.summary_tmp
2021-05-27 18:39:20,665 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:39:20,667 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622111655401_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_1452325349_1
2021-05-27 18:39:20,691 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622111655401_0002-1622111943070-root-word+count-1622111960636-1-1-SUCCEEDED-default-1622111949406.jhist_tmp
2021-05-27 18:39:20,700 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:39:20,701 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622111655401_0002-1622111943070-root-word+count-1622111960636-1-1-SUCCEEDED-default-1622111949406.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1452325349_1
2021-05-27 18:39:20,715 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622111655401_0002_conf.xml_tmp
2021-05-27 18:39:20,726 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 18:39:20,728 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622111655401_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1452325349_1
2021-05-27 18:39:21,774 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741855_1031 127.0.0.1:50010 
2021-05-27 18:39:21,775 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741856_1032 127.0.0.1:50010 
2021-05-27 18:39:21,775 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741857_1033 127.0.0.1:50010 
2021-05-27 18:39:21,775 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741858_1034 127.0.0.1:50010 
2021-05-27 18:39:21,775 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741860_1036 127.0.0.1:50010 
2021-05-27 18:39:21,775 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741859_1035 127.0.0.1:50010 
2021-05-27 18:39:24,180 INFO BlockStateChange: BLOCK* BlockManager: ask 127.0.0.1:50010 to delete [blk_1073741856_1032, blk_1073741857_1033, blk_1073741858_1034, blk_1073741859_1035, blk_1073741860_1036, blk_1073741855_1031]
2021-05-27 18:55:59,425 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 83 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 59 SyncTimes(ms): 367 
2021-05-27 18:59:10,447 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 84 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 60 SyncTimes(ms): 368 
2021-05-27 18:59:10,448 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741862_1038 127.0.0.1:50010 
2021-05-27 18:59:12,263 INFO BlockStateChange: BLOCK* BlockManager: ask 127.0.0.1:50010 to delete [blk_1073741862_1038]
2021-05-27 19:34:46,128 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 91 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 64 SyncTimes(ms): 370 
2021-05-27 19:34:46,129 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741861_1037 127.0.0.1:50010 
2021-05-27 19:34:47,640 INFO BlockStateChange: BLOCK* BlockManager: ask 127.0.0.1:50010 to delete [blk_1073741861_1037]
2021-05-27 19:35:50,446 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 19:35:50,451 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-27 19:36:29,471 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 19:36:29,498 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 19:36:29,506 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-27 19:36:29,859 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 19:36:30,107 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 19:36:30,107 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-27 19:36:30,110 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-27 19:36:30,111 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-27 19:36:30,307 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-27 19:36:30,360 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 19:36:30,368 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 19:36:30,383 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-27 19:36:30,388 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 19:36:30,390 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-27 19:36:30,390 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 19:36:30,390 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 19:36:30,427 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-27 19:36:30,430 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-27 19:36:30,478 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-27 19:36:30,478 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 19:36:30,707 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-27 19:36:30,800 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 19:36:30,801 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 19:36:30,905 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-27 19:36:30,905 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-27 19:36:30,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-27 19:36:30,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-27 19:36:30,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-27 19:36:30,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 27 19:36:30
2021-05-27 19:36:30,977 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-27 19:36:30,977 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 19:36:30,981 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-27 19:36:30,981 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-27 19:36:30,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-27 19:36:30,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-27 19:36:30,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-27 19:36:30,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-27 19:36:30,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-27 19:36:30,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-27 19:36:30,992 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-27 19:36:30,992 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-27 19:36:30,998 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-27 19:36:30,998 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-27 19:36:30,998 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-27 19:36:30,998 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-27 19:36:31,000 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-27 19:36:31,498 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-27 19:36:31,498 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 19:36:31,498 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-27 19:36:31,498 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-27 19:36:31,499 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-27 19:36:31,499 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-27 19:36:31,499 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-27 19:36:31,499 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-27 19:36:31,505 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-27 19:36:31,505 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 19:36:31,505 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-27 19:36:31,505 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-27 19:36:31,506 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-27 19:36:31,506 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-27 19:36:31,506 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-27 19:36:31,509 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-27 19:36:31,509 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-27 19:36:31,509 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-27 19:36:31,511 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-27 19:36:31,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-27 19:36:31,545 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-27 19:36:31,545 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 19:36:31,545 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-27 19:36:31,545 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-27 19:36:31,561 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 14501@DESKTOP-TSQQRSN
2021-05-27 19:36:31,617 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-27 19:36:31,773 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000234 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000234-0000000000000000324
2021-05-27 19:36:31,847 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 38 INodes.
2021-05-27 19:36:31,955 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-27 19:36:31,955 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 176 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000176
2021-05-27 19:36:31,955 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3bd418e4 expecting start txid #177
2021-05-27 19:36:31,956 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000177-0000000000000000233
2021-05-27 19:36:31,958 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000177-0000000000000000233' to transaction ID 177
2021-05-27 19:36:32,031 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000177-0000000000000000233 of size 1048576 edits # 57 loaded in 0 seconds
2021-05-27 19:36:32,031 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@544820b7 expecting start txid #234
2021-05-27 19:36:32,031 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000234-0000000000000000324
2021-05-27 19:36:32,031 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000234-0000000000000000324' to transaction ID 177
2021-05-27 19:36:32,050 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000234-0000000000000000324 of size 1048576 edits # 91 loaded in 0 seconds
2021-05-27 19:36:32,051 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-05-27 19:36:32,051 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-05-27 19:36:32,262 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 176
2021-05-27 19:36:32,263 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2021-05-27 19:36:32,271 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 325
2021-05-27 19:36:32,399 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-27 19:36:32,399 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 850 msecs
2021-05-27 19:36:32,709 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-27 19:36:32,716 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 19:36:32,733 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-27 19:36:32,783 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-27 19:36:32,829 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 19:36:32,829 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 19:36:32,830 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 31 blocks to reach the threshold 0.9990 of total blocks 31.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-27 19:36:32,839 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 19:36:32,874 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 19:36:32,874 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-27 19:36:32,878 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 19:36:32,878 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-27 19:36:32,883 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-27 19:36:36,725 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0) storage 92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 19:36:36,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 19:36:36,726 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2021-05-27 19:36:36,812 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 19:36:36,812 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 for DN 127.0.0.1:50010
2021-05-27 19:36:36,868 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 30 has reached the threshold 0.9990 of total blocks 31. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-27 19:36:36,869 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-27 19:36:36,870 INFO BlockStateChange: BLOCK* processReport: from storage DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0), blocks: 31, hasStaleStorage: false, processing time: 8 msecs
2021-05-27 19:36:36,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 31
2021-05-27 19:36:36,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-27 19:36:36,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 14
2021-05-27 19:36:36,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-27 19:36:36,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-27 19:36:36,872 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 2 msec
2021-05-27 19:36:56,977 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 31 has reached the threshold 0.9990 of total blocks 31. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-27 19:37:07,000 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 36 secs
2021-05-27 19:37:07,000 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-27 19:37:07,000 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-27 19:37:07,001 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2021-05-27 19:37:26,212 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job.jar
2021-05-27 19:37:26,505 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741865_1041{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job.jar
2021-05-27 19:37:26,505 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-05-27 19:37:26,522 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741865_1041{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 273436
2021-05-27 19:37:26,919 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job.jar is closed by DFSClient_NONMAPREDUCE_673399775_1
2021-05-27 19:37:26,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job.jar
2021-05-27 19:37:27,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job.split
2021-05-27 19:37:27,010 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job.split
2021-05-27 19:37:27,020 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 19:37:27,022 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job.split is closed by DFSClient_NONMAPREDUCE_673399775_1
2021-05-27 19:37:27,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job.splitmetainfo
2021-05-27 19:37:27,042 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 19:37:27,044 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_673399775_1
2021-05-27 19:37:27,303 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job.xml
2021-05-27 19:37:27,314 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741868_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 19:37:27,316 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job.xml is closed by DFSClient_NONMAPREDUCE_673399775_1
2021-05-27 19:37:34,616 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 30 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 23 SyncTimes(ms): 20 
2021-05-27 19:37:34,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job_1622115408185_0001_1_conf.xml
2021-05-27 19:37:34,863 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 19:37:34,868 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job_1622115408185_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-459669539_1
2021-05-27 19:37:39,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job_1622115408185_0001_1.jhist
2021-05-27 19:37:39,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job_1622115408185_0001_1.jhist for DFSClient_NONMAPREDUCE_-459669539_1
2021-05-27 19:37:42,070 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2021-05-27 19:37:42,070 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-05-27 19:37:42,070 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 325
2021-05-27 19:37:42,071 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 43 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 31 SyncTimes(ms): 27 
2021-05-27 19:37:42,072 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000325 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000325-0000000000000000367
2021-05-27 19:37:42,072 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 368
2021-05-27 19:37:43,281 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 217.39 KB/s
2021-05-27 19:37:43,282 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000367 size 5141 bytes.
2021-05-27 19:37:43,328 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 324
2021-05-27 19:37:43,328 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000176, cpktTxId=0000000000000000176)
2021-05-27 19:37:44,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /user/root/output/_temporary/1/_temporary/attempt_1622115408185_0001_r_000000_0/part-r-00000
2021-05-27 19:37:44,859 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741871_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 19:37:44,863 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_temporary/1/_temporary/attempt_1622115408185_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622115408185_0001_r_000000_0_803172870_1
2021-05-27 19:37:44,951 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-459669539_1
2021-05-27 19:37:45,010 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-459669539_1
2021-05-27 19:37:45,015 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-459669539_1
2021-05-27 19:37:45,029 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 13122
2021-05-27 19:37:45,031 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622115408185_0001/job_1622115408185_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_-459669539_1
2021-05-27 19:37:45,036 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622115408185_0001.summary_tmp
2021-05-27 19:37:45,045 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 19:37:45,046 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622115408185_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_-459669539_1
2021-05-27 19:37:45,068 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622115408185_0001-1622115447534-root-word+count-1622115465016-1-1-SUCCEEDED-default-1622115454607.jhist_tmp
2021-05-27 19:37:45,077 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 19:37:45,078 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622115408185_0001-1622115447534-root-word+count-1622115465016-1-1-SUCCEEDED-default-1622115454607.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-459669539_1
2021-05-27 19:37:45,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622115408185_0001_conf.xml_tmp
2021-05-27 19:37:45,104 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741874_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:127.0.0.1:50010|RBW]]} size 0
2021-05-27 19:37:45,105 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622115408185_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-459669539_1
2021-05-27 19:37:46,248 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741865_1041 127.0.0.1:50010 
2021-05-27 19:37:46,249 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741866_1042 127.0.0.1:50010 
2021-05-27 19:37:46,249 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741867_1043 127.0.0.1:50010 
2021-05-27 19:37:46,249 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741868_1044 127.0.0.1:50010 
2021-05-27 19:37:46,249 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741870_1046 127.0.0.1:50010 
2021-05-27 19:37:46,249 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741869_1045 127.0.0.1:50010 
2021-05-27 19:37:47,966 INFO BlockStateChange: BLOCK* BlockManager: ask 127.0.0.1:50010 to delete [blk_1073741865_1041, blk_1073741866_1042, blk_1073741867_1043, blk_1073741868_1044, blk_1073741869_1045, blk_1073741870_1046]
2021-05-27 19:38:10,082 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741872_1048 127.0.0.1:50010 
2021-05-27 19:38:12,039 INFO BlockStateChange: BLOCK* BlockManager: ask 127.0.0.1:50010 to delete [blk_1073741872_1048]
2021-05-27 20:18:57,992 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 20:18:57,995 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/127.0.1.1
************************************************************/
2021-05-27 20:34:12,507 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 20:34:12,546 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 20:34:12,557 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-27 20:34:12,966 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 20:34:13,186 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 20:34:13,186 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-27 20:34:13,188 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-27 20:34:13,189 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-27 20:34:18,479 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-27 20:34:18,547 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 20:34:18,555 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 20:34:18,574 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-27 20:34:18,581 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 20:34:18,584 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-27 20:34:18,584 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 20:34:18,584 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 20:34:18,628 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-27 20:34:18,630 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-27 20:34:18,667 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-27 20:34:18,668 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 20:34:18,912 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-27 20:34:18,967 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 20:34:18,967 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 20:34:19,017 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-27 20:34:19,017 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-27 20:34:19,074 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-27 20:34:19,074 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-27 20:34:19,076 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-27 20:34:19,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 27 20:34:19
2021-05-27 20:34:19,079 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-27 20:34:19,080 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 20:34:19,081 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-27 20:34:19,081 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-27 20:34:19,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-27 20:34:19,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-27 20:34:19,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-27 20:34:19,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-27 20:34:19,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-27 20:34:19,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-27 20:34:19,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-27 20:34:19,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-27 20:34:19,098 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-27 20:34:19,098 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-27 20:34:19,098 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-27 20:34:19,098 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-27 20:34:19,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-27 20:34:19,443 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-27 20:34:19,443 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 20:34:19,443 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-27 20:34:19,443 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-27 20:34:19,444 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-27 20:34:19,444 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-27 20:34:19,444 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-27 20:34:19,444 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-27 20:34:19,451 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-27 20:34:19,451 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 20:34:19,451 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-27 20:34:19,451 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-27 20:34:19,452 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-27 20:34:19,453 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-27 20:34:19,453 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-27 20:34:19,456 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-27 20:34:19,456 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-27 20:34:19,456 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-27 20:34:19,457 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-27 20:34:19,457 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-27 20:34:19,461 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-27 20:34:19,461 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 20:34:19,461 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-27 20:34:19,462 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-27 20:34:19,478 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 17435@DESKTOP-TSQQRSN
2021-05-27 20:34:19,552 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-27 20:34:19,774 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000368 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000368-0000000000000000410
2021-05-27 20:34:19,846 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 65 INodes.
2021-05-27 20:34:19,969 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-27 20:34:19,969 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 367 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000367
2021-05-27 20:34:19,969 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@555cf22 expecting start txid #368
2021-05-27 20:34:19,970 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000368-0000000000000000410
2021-05-27 20:34:19,972 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000368-0000000000000000410' to transaction ID 368
2021-05-27 20:34:20,021 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000368-0000000000000000410 of size 1048576 edits # 43 loaded in 0 seconds
2021-05-27 20:34:20,022 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-27 20:34:20,024 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 411
2021-05-27 20:34:20,156 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-27 20:34:20,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 693 msecs
2021-05-27 20:34:20,552 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-27 20:34:20,559 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 20:34:20,569 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-27 20:34:20,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-27 20:34:20,642 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 20:34:20,642 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 20:34:20,643 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 34 blocks to reach the threshold 0.9990 of total blocks 34.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-27 20:34:20,656 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 20:34:20,683 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 20:34:20,684 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-27 20:34:20,689 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-27 20:34:20,689 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-27 20:34:20,694 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-27 20:34:21,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0) storage 92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 20:34:21,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 20:34:21,739 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2021-05-27 20:34:21,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 20:34:21,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 for DN 127.0.0.1:50010
2021-05-27 20:34:21,996 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 33 has reached the threshold 0.9990 of total blocks 34. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-27 20:34:21,996 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-27 20:34:21,998 INFO BlockStateChange: BLOCK* processReport: from storage DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0), blocks: 34, hasStaleStorage: false, processing time: 24 msecs
2021-05-27 20:34:22,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 34
2021-05-27 20:34:22,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-27 20:34:22,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 14
2021-05-27 20:34:22,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-27 20:34:22,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-27 20:34:22,002 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2021-05-27 20:34:42,183 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 34 has reached the threshold 0.9990 of total blocks 34. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-27 20:34:52,289 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 33 secs
2021-05-27 20:34:52,290 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-27 20:34:52,290 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-27 20:34:52,290 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2021-05-27 20:34:54,566 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 20:34:54,572 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/127.0.1.1
************************************************************/
2021-05-27 20:36:13,448 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 20:36:13,455 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 20:36:13,460 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-27 20:36:13,740 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 20:36:13,816 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 20:36:13,816 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-27 20:36:13,818 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-27 20:36:13,819 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-27 20:36:14,007 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-27 20:36:14,061 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 20:36:14,069 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 20:36:14,083 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-27 20:36:14,087 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 20:36:14,089 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-27 20:36:14,089 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 20:36:14,090 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 20:36:14,110 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-27 20:36:14,112 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-27 20:36:14,125 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-27 20:36:14,125 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 20:36:14,236 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-27 20:36:19,272 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 20:36:19,272 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 20:36:19,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-27 20:36:19,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-27 20:36:19,358 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-27 20:36:19,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-27 20:36:19,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-27 20:36:19,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 27 20:36:19
2021-05-27 20:36:19,365 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-27 20:36:19,365 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 20:36:19,367 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-27 20:36:19,367 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-27 20:36:19,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-27 20:36:19,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-27 20:36:19,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-27 20:36:19,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-27 20:36:19,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-27 20:36:19,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-27 20:36:19,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-27 20:36:19,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-27 20:36:19,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-27 20:36:19,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-27 20:36:19,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-27 20:36:19,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-27 20:36:19,390 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-27 20:36:19,651 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-27 20:36:19,651 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 20:36:19,652 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-27 20:36:19,652 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-27 20:36:19,652 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-27 20:36:19,652 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-27 20:36:19,652 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-27 20:36:19,652 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-27 20:36:19,659 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-27 20:36:19,659 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 20:36:19,659 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-27 20:36:19,659 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-27 20:36:19,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-27 20:36:19,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-27 20:36:19,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-27 20:36:19,665 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-27 20:36:19,665 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-27 20:36:19,665 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-27 20:36:19,667 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-27 20:36:19,668 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-27 20:36:19,670 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-27 20:36:19,670 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 20:36:19,670 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-27 20:36:19,670 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-27 20:36:19,681 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 19277@DESKTOP-TSQQRSN
2021-05-27 20:36:19,734 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-27 20:36:19,765 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000411 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000411-0000000000000000411
2021-05-27 20:36:19,814 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 65 INodes.
2021-05-27 20:36:19,926 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-27 20:36:19,926 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 367 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000367
2021-05-27 20:36:19,926 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@51972dc7 expecting start txid #368
2021-05-27 20:36:19,927 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000368-0000000000000000410
2021-05-27 20:36:19,928 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000368-0000000000000000410' to transaction ID 368
2021-05-27 20:36:19,983 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000368-0000000000000000410 of size 1048576 edits # 43 loaded in 0 seconds
2021-05-27 20:36:19,983 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3700ec9c expecting start txid #411
2021-05-27 20:36:19,983 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000411-0000000000000000411
2021-05-27 20:36:19,983 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000411-0000000000000000411' to transaction ID 368
2021-05-27 20:36:19,984 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000411-0000000000000000411 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-27 20:36:19,984 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-27 20:36:19,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 412
2021-05-27 20:36:20,120 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-27 20:36:20,120 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 446 msecs
2021-05-27 20:36:20,293 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-27 20:36:20,300 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 20:36:20,312 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-27 20:36:20,334 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-27 20:36:20,354 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 20:36:20,354 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 20:36:20,354 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 34 blocks to reach the threshold 0.9990 of total blocks 34.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-27 20:36:20,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 20:36:20,391 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 20:36:20,391 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-27 20:36:20,396 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-27 20:36:20,396 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-27 20:36:20,404 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-27 20:36:20,901 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0) storage 92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 20:36:20,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 20:36:20,902 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-05-27 20:36:20,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 20:36:20,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 for DN 10.191.53.85:50010
2021-05-27 20:36:21,030 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 33 has reached the threshold 0.9990 of total blocks 34. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-27 20:36:21,030 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-27 20:36:21,032 INFO BlockStateChange: BLOCK* processReport: from storage DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0), blocks: 34, hasStaleStorage: false, processing time: 8 msecs
2021-05-27 20:36:21,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 34
2021-05-27 20:36:21,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-27 20:36:21,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 14
2021-05-27 20:36:21,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-27 20:36:21,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-27 20:36:21,035 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2021-05-27 20:36:41,193 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 34 has reached the threshold 0.9990 of total blocks 34. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-27 20:36:51,289 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 31 secs
2021-05-27 20:36:51,289 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-27 20:36:51,289 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-27 20:36:51,290 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2021-05-27 20:37:35,943 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-05-27 20:37:35,943 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-05-27 20:37:35,943 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 412
2021-05-27 20:37:35,944 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-05-27 20:37:35,947 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2021-05-27 20:37:35,949 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000412 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000412-0000000000000000413
2021-05-27 20:37:35,950 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 414
2021-05-27 20:37:37,884 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 108.11 KB/s
2021-05-27 20:37:37,885 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000413 size 4711 bytes.
2021-05-27 20:37:37,966 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 367
2021-05-27 20:37:37,967 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000324, cpktTxId=0000000000000000324)
2021-05-27 20:38:09,464 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741871_1047 10.191.53.85:50010 
2021-05-27 20:38:11,717 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741871_1047]
2021-05-27 20:38:33,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job.jar
2021-05-27 20:38:33,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741875_1051{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job.jar
2021-05-27 20:38:33,624 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-05-27 20:38:33,641 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741875_1051{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 273436
2021-05-27 20:38:34,043 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-276237265_1
2021-05-27 20:38:34,056 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job.jar
2021-05-27 20:38:34,124 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job.split
2021-05-27 20:38:34,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job.split
2021-05-27 20:38:34,148 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:38:34,149 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job.split is closed by DFSClient_NONMAPREDUCE_-276237265_1
2021-05-27 20:38:34,157 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job.splitmetainfo
2021-05-27 20:38:34,165 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741877_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:38:34,185 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-276237265_1
2021-05-27 20:38:34,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job.xml
2021-05-27 20:38:34,434 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:38:34,436 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-276237265_1
2021-05-27 20:38:41,810 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 31 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 24 SyncTimes(ms): 60 
2021-05-27 20:38:41,966 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job_1622119001821_0001_1_conf.xml
2021-05-27 20:38:42,112 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:38:42,116 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job_1622119001821_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_715595971_1
2021-05-27 20:38:47,069 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job_1622119001821_0001_1.jhist
2021-05-27 20:38:47,088 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job_1622119001821_0001_1.jhist for DFSClient_NONMAPREDUCE_715595971_1
2021-05-27 20:38:52,594 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/output/_temporary/1/_temporary/attempt_1622119001821_0001_r_000000_0/part-r-00000
2021-05-27 20:38:52,719 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:38:52,722 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_temporary/1/_temporary/attempt_1622119001821_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622119001821_0001_r_000000_0_-445556908_1
2021-05-27 20:38:52,852 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_715595971_1
2021-05-27 20:38:52,907 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_715595971_1
2021-05-27 20:38:52,913 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_715595971_1
2021-05-27 20:38:52,927 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 13115
2021-05-27 20:38:52,929 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119001821_0001/job_1622119001821_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_715595971_1
2021-05-27 20:38:52,934 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622119001821_0001.summary_tmp
2021-05-27 20:38:52,942 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:38:52,943 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622119001821_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_715595971_1
2021-05-27 20:38:52,964 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622119001821_0001-1622119114674-root-word+count-1622119132915-1-1-SUCCEEDED-default-1622119121793.jhist_tmp
2021-05-27 20:38:52,972 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:38:52,973 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622119001821_0001-1622119114674-root-word+count-1622119132915-1-1-SUCCEEDED-default-1622119121793.jhist_tmp is closed by DFSClient_NONMAPREDUCE_715595971_1
2021-05-27 20:38:52,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622119001821_0001_conf.xml_tmp
2021-05-27 20:38:52,998 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:38:52,999 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622119001821_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_715595971_1
2021-05-27 20:38:54,037 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741875_1051 10.191.53.85:50010 
2021-05-27 20:38:54,038 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741876_1052 10.191.53.85:50010 
2021-05-27 20:38:54,038 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741877_1053 10.191.53.85:50010 
2021-05-27 20:38:54,038 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741878_1054 10.191.53.85:50010 
2021-05-27 20:38:54,038 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741880_1056 10.191.53.85:50010 
2021-05-27 20:38:54,038 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741879_1055 10.191.53.85:50010 
2021-05-27 20:38:56,875 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741875_1051, blk_1073741876_1052, blk_1073741877_1053, blk_1073741878_1054, blk_1073741879_1055, blk_1073741880_1056]
2021-05-27 20:43:28,942 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 84 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 60 SyncTimes(ms): 78 
2021-05-27 20:43:28,944 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741881_1057 10.191.53.85:50010 
2021-05-27 20:43:30,585 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741881_1057]
2021-05-27 20:43:35,766 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job.jar
2021-05-27 20:43:35,888 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:43:35,895 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-508293523_1
2021-05-27 20:43:35,900 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job.jar
2021-05-27 20:43:35,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job.split
2021-05-27 20:43:35,961 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job.split
2021-05-27 20:43:35,974 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:43:35,976 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job.split is closed by DFSClient_NONMAPREDUCE_-508293523_1
2021-05-27 20:43:35,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job.splitmetainfo
2021-05-27 20:43:35,992 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:43:35,993 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-508293523_1
2021-05-27 20:43:36,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job.xml
2021-05-27 20:43:36,083 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:43:36,084 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-508293523_1
2021-05-27 20:43:43,145 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job_1622119389401_0001_1_conf.xml
2021-05-27 20:43:43,227 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741889_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:43:43,231 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job_1622119389401_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-641705300_1
2021-05-27 20:43:47,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job_1622119389401_0001_1.jhist
2021-05-27 20:43:47,743 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job_1622119389401_0001_1.jhist for DFSClient_NONMAPREDUCE_-641705300_1
2021-05-27 20:43:52,654 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/output/_temporary/1/_temporary/attempt_1622119389401_0001_r_000000_0/part-r-00000
2021-05-27 20:43:52,777 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:43:52,780 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_temporary/1/_temporary/attempt_1622119389401_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622119389401_0001_r_000000_0_-703067675_1
2021-05-27 20:43:52,878 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-641705300_1
2021-05-27 20:43:52,920 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-641705300_1
2021-05-27 20:43:52,925 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-641705300_1
2021-05-27 20:43:52,940 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 13116
2021-05-27 20:43:52,942 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622119389401_0001/job_1622119389401_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_-641705300_1
2021-05-27 20:43:52,947 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622119389401_0001.summary_tmp
2021-05-27 20:43:52,955 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:43:52,957 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622119389401_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_-641705300_1
2021-05-27 20:43:52,977 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622119389401_0001-1622119416279-root-word+count-1622119432926-1-1-SUCCEEDED-default-1622119422983.jhist_tmp
2021-05-27 20:43:52,985 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:43:52,987 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622119389401_0001-1622119416279-root-word+count-1622119432926-1-1-SUCCEEDED-default-1622119422983.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-641705300_1
2021-05-27 20:43:52,999 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622119389401_0001_conf.xml_tmp
2021-05-27 20:43:53,010 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-27 20:43:53,012 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622119389401_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-641705300_1
2021-05-27 20:43:54,048 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741885_1061 10.191.53.85:50010 
2021-05-27 20:43:54,048 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741886_1062 10.191.53.85:50010 
2021-05-27 20:43:54,048 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741887_1063 10.191.53.85:50010 
2021-05-27 20:43:54,048 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741888_1064 10.191.53.85:50010 
2021-05-27 20:43:54,048 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741890_1066 10.191.53.85:50010 
2021-05-27 20:43:54,048 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741889_1065 10.191.53.85:50010 
2021-05-27 20:43:54,652 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741888_1064, blk_1073741889_1065, blk_1073741890_1066, blk_1073741885_1061, blk_1073741886_1062, blk_1073741887_1063]
2021-05-27 20:48:20,129 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-27 20:48:20,132 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-27 21:00:34,565 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-27 21:00:34,619 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-27 21:00:34,628 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-27 21:00:34,923 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-27 21:00:35,008 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-27 21:00:35,008 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-27 21:00:35,010 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-27 21:00:35,011 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-27 21:00:35,302 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-27 21:00:35,371 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-27 21:00:35,379 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-27 21:00:35,392 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-27 21:00:35,397 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-27 21:00:35,399 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-27 21:00:35,399 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-27 21:00:35,399 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-27 21:00:35,428 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-27 21:00:35,429 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-27 21:00:35,453 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-27 21:00:35,453 INFO org.mortbay.log: jetty-6.1.26
2021-05-27 21:00:35,579 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-27 21:00:35,611 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 21:00:35,612 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-27 21:00:35,654 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-27 21:00:35,654 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-27 21:00:35,697 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-27 21:00:35,698 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-27 21:00:35,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-27 21:00:35,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 27 21:00:35
2021-05-27 21:00:35,702 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-27 21:00:35,702 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 21:00:35,704 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-27 21:00:35,704 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-27 21:00:35,711 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-27 21:00:35,711 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-27 21:00:35,711 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-27 21:00:35,711 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-27 21:00:35,711 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-27 21:00:35,711 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-27 21:00:35,711 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-27 21:00:35,711 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-27 21:00:35,717 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-27 21:00:35,717 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-27 21:00:35,717 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-27 21:00:35,717 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-27 21:00:35,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-27 21:00:35,919 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-27 21:00:35,920 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 21:00:35,920 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-27 21:00:35,920 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-27 21:00:35,921 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-27 21:00:35,921 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-27 21:00:35,921 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-27 21:00:35,921 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-27 21:00:35,927 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-27 21:00:35,928 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 21:00:35,928 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-27 21:00:35,928 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-27 21:00:35,929 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-27 21:00:35,930 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-27 21:00:35,930 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-27 21:00:35,934 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-27 21:00:35,934 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-27 21:00:35,934 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-27 21:00:35,935 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-27 21:00:35,936 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-27 21:00:35,957 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-27 21:00:35,957 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-27 21:00:35,957 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-27 21:00:35,957 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-27 21:00:35,980 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 24503@DESKTOP-TSQQRSN
2021-05-27 21:00:36,042 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-27 21:00:36,269 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000414 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000414-0000000000000000577
2021-05-27 21:00:36,375 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 60 INodes.
2021-05-27 21:00:36,506 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-27 21:00:36,506 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 413 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000413
2021-05-27 21:00:36,506 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@655ef322 expecting start txid #414
2021-05-27 21:00:36,506 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000414-0000000000000000577
2021-05-27 21:00:36,508 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000414-0000000000000000577' to transaction ID 414
2021-05-27 21:00:36,589 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000414-0000000000000000577 of size 1048576 edits # 164 loaded in 0 seconds
2021-05-27 21:00:36,590 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-27 21:00:36,591 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 578
2021-05-27 21:00:36,722 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-27 21:00:36,722 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 749 msecs
2021-05-27 21:00:37,175 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-27 21:00:37,181 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-27 21:00:37,192 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-27 21:00:37,220 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-27 21:00:37,253 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 21:00:37,253 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-27 21:00:37,254 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 40 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-27 21:00:37,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 21:00:37,307 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-27 21:00:37,307 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-27 21:00:37,310 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-27 21:00:37,310 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-27 21:00:37,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-27 21:00:46,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0) storage 92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-27 21:00:46,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 21:00:46,831 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-05-27 21:00:46,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-27 21:00:46,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 for DN 10.191.53.85:50010
2021-05-27 21:00:47,051 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 39 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-27 21:00:47,051 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-27 21:00:47,052 INFO BlockStateChange: BLOCK* processReport: from storage DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0), blocks: 40, hasStaleStorage: false, processing time: 7 msecs
2021-05-27 21:00:47,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 40
2021-05-27 21:00:47,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-27 21:00:47,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 14
2021-05-27 21:00:47,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-27 21:00:47,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-27 21:00:47,054 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2021-05-27 21:01:07,185 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 40 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-27 21:01:17,255 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 41 secs
2021-05-27 21:01:17,255 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-27 21:01:17,255 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-27 21:01:17,255 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2021-05-27 21:01:57,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-05-27 21:01:57,400 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-05-27 21:01:57,400 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 578
2021-05-27 21:01:57,400 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 4 
2021-05-27 21:01:57,401 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 5 
2021-05-27 21:01:57,402 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000578 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000578-0000000000000000579
2021-05-27 21:01:57,403 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 580
2021-05-27 21:01:58,460 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 135.14 KB/s
2021-05-27 21:01:58,460 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000579 size 5422 bytes.
2021-05-27 21:01:58,518 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 413
2021-05-27 21:01:58,518 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000367, cpktTxId=0000000000000000367)
2021-05-29 11:28:05,827 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 11:28:05,859 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 11:28:05,864 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 11:28:06,144 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 11:28:06,221 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 11:28:06,221 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 11:28:06,223 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 11:28:06,224 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 11:28:06,409 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 11:28:06,546 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 11:28:06,558 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 11:28:06,577 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 11:28:06,583 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 11:28:06,585 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 11:28:06,585 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 11:28:06,585 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 11:28:06,644 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 11:28:06,645 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 11:28:06,673 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-29 11:28:06,674 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 11:28:06,834 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-29 11:28:11,917 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 11:28:11,917 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 11:28:11,985 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-29 11:28:11,985 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-29 11:28:12,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-29 11:28:12,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-29 11:28:12,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-29 11:28:12,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 29 11:28:12
2021-05-29 11:28:12,083 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-29 11:28:12,083 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:28:12,134 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-29 11:28:12,134 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-29 11:28:12,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-29 11:28:12,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-29 11:28:12,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-29 11:28:12,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-29 11:28:12,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-29 11:28:12,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-29 11:28:12,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-29 11:28:12,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-29 11:28:12,148 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-29 11:28:12,148 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-29 11:28:12,148 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-29 11:28:12,149 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-29 11:28:12,150 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-29 11:28:12,494 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-29 11:28:12,494 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:28:12,494 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-29 11:28:12,494 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-29 11:28:12,495 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-29 11:28:12,495 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-29 11:28:12,495 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-29 11:28:12,496 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-29 11:28:12,503 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-29 11:28:12,503 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:28:12,503 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-29 11:28:12,503 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-29 11:28:12,505 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-29 11:28:12,505 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-29 11:28:12,505 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-29 11:28:12,520 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-29 11:28:12,520 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-29 11:28:12,520 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-29 11:28:12,523 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-29 11:28:12,523 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-29 11:28:12,551 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-29 11:28:12,551 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:28:12,552 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-29 11:28:12,552 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-29 11:28:12,573 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 6778@DESKTOP-TSQQRSN.localdomain
2021-05-29 11:28:12,679 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-29 11:28:12,748 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000580 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000580-0000000000000000580
2021-05-29 11:28:12,833 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 66 INodes.
2021-05-29 11:28:13,045 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-29 11:28:13,045 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 579 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000579
2021-05-29 11:28:13,046 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2807bdeb expecting start txid #580
2021-05-29 11:28:13,046 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000580-0000000000000000580
2021-05-29 11:28:13,048 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000580-0000000000000000580' to transaction ID 580
2021-05-29 11:28:13,052 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000580-0000000000000000580 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-29 11:28:13,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-05-29 11:28:13,060 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-05-29 11:28:13,215 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 579
2021-05-29 11:28:13,216 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000413, cpktTxId=0000000000000000413)
2021-05-29 11:28:13,308 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 581
2021-05-29 11:28:13,481 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-29 11:28:13,481 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 920 msecs
2021-05-29 11:28:13,849 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-29 11:28:13,855 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 11:28:13,864 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-29 11:28:13,886 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-29 11:28:13,948 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 11:28:13,948 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 11:28:13,949 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 40 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-29 11:28:13,964 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 11:28:13,996 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 11:28:13,996 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-29 11:28:14,001 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-29 11:28:14,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-29 11:28:14,006 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-29 11:28:15,873 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0) storage 92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-29 11:28:15,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 11:28:15,874 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2021-05-29 11:28:16,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 11:28:16,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 for DN 127.0.0.1:50010
2021-05-29 11:28:16,174 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 39 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-29 11:28:16,175 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-29 11:28:16,176 INFO BlockStateChange: BLOCK* processReport: from storage DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0), blocks: 40, hasStaleStorage: false, processing time: 17 msecs
2021-05-29 11:28:16,178 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 40
2021-05-29 11:28:16,179 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-29 11:28:16,179 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 14
2021-05-29 11:28:16,179 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-29 11:28:16,179 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-29 11:28:16,179 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2021-05-29 11:28:36,227 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 40 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-29 11:28:46,236 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 34 secs
2021-05-29 11:28:46,237 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-29 11:28:46,237 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-29 11:28:46,237 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2021-05-29 11:32:22,497 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 11:32:22,499 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-29 11:33:19,166 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 11:33:19,175 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 11:33:19,179 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 11:33:19,475 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 11:33:19,555 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 11:33:19,555 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 11:33:19,557 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 11:33:19,558 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 11:33:19,741 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 11:33:19,795 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 11:33:19,803 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 11:33:19,817 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 11:33:19,823 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 11:33:19,824 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 11:33:19,824 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 11:33:19,824 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 11:33:19,845 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 11:33:19,847 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 11:33:19,860 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-29 11:33:19,860 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 11:33:19,979 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-29 11:33:20,030 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 11:33:20,030 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 11:33:20,072 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-29 11:33:20,072 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-29 11:33:20,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-29 11:33:20,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-29 11:33:20,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-29 11:33:20,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 29 11:33:20
2021-05-29 11:33:20,122 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-29 11:33:20,122 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:33:20,123 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-29 11:33:20,123 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-29 11:33:20,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-29 11:33:20,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-29 11:33:20,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-29 11:33:20,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-29 11:33:20,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-29 11:33:20,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-29 11:33:20,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-29 11:33:20,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-29 11:33:20,137 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-29 11:33:20,137 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-29 11:33:20,138 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-29 11:33:20,138 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-29 11:33:20,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-29 11:33:20,334 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-29 11:33:20,334 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:33:20,334 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-29 11:33:20,334 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-29 11:33:20,335 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-29 11:33:20,335 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-29 11:33:20,335 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-29 11:33:20,335 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-29 11:33:20,342 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-29 11:33:20,342 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:33:20,342 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-29 11:33:20,342 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-29 11:33:20,343 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-29 11:33:20,343 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-29 11:33:20,343 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-29 11:33:20,346 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-29 11:33:20,346 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-29 11:33:20,346 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-29 11:33:20,348 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-29 11:33:20,348 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-29 11:33:20,350 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-29 11:33:20,350 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:33:20,350 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-29 11:33:20,350 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-29 11:33:20,359 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 8635@DESKTOP-TSQQRSN.localdomain
2021-05-29 11:33:20,406 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-29 11:33:20,435 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000581 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000581-0000000000000000581
2021-05-29 11:33:20,480 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 66 INodes.
2021-05-29 11:33:20,581 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-29 11:33:20,581 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 580 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000580
2021-05-29 11:33:20,582 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2807bdeb expecting start txid #581
2021-05-29 11:33:20,582 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000581-0000000000000000581
2021-05-29 11:33:20,584 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000581-0000000000000000581' to transaction ID 581
2021-05-29 11:33:20,587 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000581-0000000000000000581 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-29 11:33:20,593 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-29 11:33:20,594 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 582
2021-05-29 11:33:20,741 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-29 11:33:20,741 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 388 msecs
2021-05-29 11:33:20,883 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-29 11:33:20,889 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 11:33:20,899 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-29 11:33:20,922 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-29 11:33:20,941 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 11:33:20,941 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 11:33:20,941 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 40 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-29 11:33:20,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 11:33:20,973 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 11:33:20,973 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-29 11:33:20,977 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-29 11:33:20,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-29 11:33:20,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-29 11:33:26,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0) storage 92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-29 11:33:26,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 11:33:26,627 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2021-05-29 11:33:26,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 11:33:26,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 for DN 127.0.0.1:50010
2021-05-29 11:33:26,755 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 39 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-29 11:33:26,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-29 11:33:26,757 INFO BlockStateChange: BLOCK* processReport: from storage DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0), blocks: 40, hasStaleStorage: false, processing time: 10 msecs
2021-05-29 11:33:26,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 40
2021-05-29 11:33:26,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-29 11:33:26,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 14
2021-05-29 11:33:26,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-29 11:33:26,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-29 11:33:26,759 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2021-05-29 11:33:46,854 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 40 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-29 11:33:56,914 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 36 secs
2021-05-29 11:33:56,914 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-29 11:33:56,914 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-29 11:33:56,914 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2021-05-29 11:34:04,415 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 11:34:04,417 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-29 11:38:04,579 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 11:38:04,586 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 11:38:04,590 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 11:38:04,868 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 11:38:04,942 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 11:38:04,943 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 11:38:04,945 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 11:38:04,945 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 11:38:05,119 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 11:38:05,173 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 11:38:05,180 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 11:38:05,194 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 11:38:05,199 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 11:38:05,201 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 11:38:05,201 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 11:38:05,201 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 11:38:05,221 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 11:38:05,222 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 11:38:05,235 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-29 11:38:05,235 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 11:38:05,346 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-29 11:38:05,904 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 11:38:05,904 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 11:38:05,942 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-29 11:38:05,942 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-29 11:38:05,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-29 11:38:05,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-29 11:38:05,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-29 11:38:05,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 29 11:38:05
2021-05-29 11:38:05,990 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-29 11:38:05,990 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:38:05,992 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-29 11:38:05,992 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-29 11:38:06,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-29 11:38:06,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-29 11:38:06,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-29 11:38:06,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-29 11:38:06,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-29 11:38:06,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-29 11:38:06,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-29 11:38:06,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-29 11:38:06,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-29 11:38:06,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-29 11:38:06,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-29 11:38:06,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-29 11:38:06,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-29 11:38:06,213 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-29 11:38:06,214 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:38:06,214 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-29 11:38:06,214 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-29 11:38:06,215 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-29 11:38:06,215 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-29 11:38:06,215 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-29 11:38:06,215 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-29 11:38:06,222 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-29 11:38:06,222 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:38:06,222 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-29 11:38:06,222 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-29 11:38:06,223 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-29 11:38:06,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-29 11:38:06,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-29 11:38:06,227 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-29 11:38:06,227 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-29 11:38:06,227 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-29 11:38:06,229 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-29 11:38:06,229 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-29 11:38:06,232 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-29 11:38:06,232 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:38:06,232 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-29 11:38:06,232 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-29 11:38:06,242 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 10428@DESKTOP-TSQQRSN.localdomain
2021-05-29 11:38:06,291 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-29 11:38:06,321 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000582 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000582-0000000000000000582
2021-05-29 11:38:06,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 66 INodes.
2021-05-29 11:38:06,463 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-29 11:38:06,463 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 580 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000580
2021-05-29 11:38:06,463 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@51972dc7 expecting start txid #581
2021-05-29 11:38:06,463 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000581-0000000000000000581
2021-05-29 11:38:06,465 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000581-0000000000000000581' to transaction ID 581
2021-05-29 11:38:06,467 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000581-0000000000000000581 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-29 11:38:06,467 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3700ec9c expecting start txid #582
2021-05-29 11:38:06,467 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000582-0000000000000000582
2021-05-29 11:38:06,468 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000582-0000000000000000582' to transaction ID 581
2021-05-29 11:38:06,469 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000582-0000000000000000582 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-29 11:38:06,474 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-29 11:38:06,476 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 583
2021-05-29 11:38:06,844 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-29 11:38:06,844 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 609 msecs
2021-05-29 11:38:06,985 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-29 11:38:06,991 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 11:38:07,000 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-29 11:38:07,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-29 11:38:07,039 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 11:38:07,040 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 11:38:07,040 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 40 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-29 11:38:07,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 11:38:07,069 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 11:38:07,070 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-29 11:38:07,074 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-29 11:38:07,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-29 11:38:07,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-29 11:38:12,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0) storage 92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-29 11:38:12,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 11:38:12,433 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2021-05-29 11:38:12,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 11:38:12,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 for DN 127.0.0.1:50010
2021-05-29 11:38:12,561 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 39 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-29 11:38:12,562 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-29 11:38:12,563 INFO BlockStateChange: BLOCK* processReport: from storage DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 node DatanodeRegistration(127.0.0.1:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0), blocks: 40, hasStaleStorage: false, processing time: 9 msecs
2021-05-29 11:38:12,565 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 40
2021-05-29 11:38:12,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-29 11:38:12,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 14
2021-05-29 11:38:12,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-29 11:38:12,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-29 11:38:12,566 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2021-05-29 11:38:32,711 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 40 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-29 11:38:42,753 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 36 secs
2021-05-29 11:38:42,753 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-29 11:38:42,753 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-29 11:38:42,753 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2021-05-29 11:38:43,189 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 11:38:43,192 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-29 11:45:05,491 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 11:45:05,500 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 11:45:05,504 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 11:45:05,786 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 11:45:05,865 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 11:45:05,865 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 11:45:05,867 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 11:45:05,867 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 11:45:06,034 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 11:45:06,090 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 11:45:06,097 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 11:45:06,111 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 11:45:06,116 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 11:45:06,118 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 11:45:06,118 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 11:45:06,118 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 11:45:06,139 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 11:45:06,140 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 11:45:06,152 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-29 11:45:06,152 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 11:45:06,266 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-29 11:45:06,300 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 11:45:06,300 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 11:45:06,336 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-29 11:45:06,336 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-29 11:45:06,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-29 11:45:06,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-29 11:45:06,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-29 11:45:06,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 29 11:45:06
2021-05-29 11:45:06,382 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-29 11:45:06,382 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:45:06,384 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-29 11:45:06,384 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-29 11:45:06,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-29 11:45:06,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-29 11:45:06,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-29 11:45:06,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-29 11:45:06,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-29 11:45:06,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-29 11:45:06,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-29 11:45:06,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-29 11:45:06,397 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-29 11:45:06,397 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-29 11:45:06,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-29 11:45:06,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-29 11:45:06,399 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-29 11:45:06,594 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-29 11:45:06,594 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:45:06,594 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-29 11:45:06,594 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-29 11:45:06,595 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-29 11:45:06,595 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-29 11:45:06,595 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-29 11:45:06,595 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-29 11:45:06,602 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-29 11:45:06,602 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:45:06,602 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-29 11:45:06,602 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-29 11:45:06,603 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-29 11:45:06,603 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-29 11:45:06,603 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-29 11:45:06,607 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-29 11:45:06,607 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-29 11:45:06,607 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-29 11:45:06,608 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-29 11:45:06,608 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-29 11:45:06,610 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-29 11:45:06,610 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 11:45:06,610 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-29 11:45:06,610 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-29 11:45:06,619 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 12360@DESKTOP-TSQQRSN
2021-05-29 11:45:06,672 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-29 11:45:06,707 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000583 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000583-0000000000000000583
2021-05-29 11:45:06,750 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 66 INodes.
2021-05-29 11:45:06,851 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-29 11:45:06,852 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 580 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000580
2021-05-29 11:45:06,852 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@51972dc7 expecting start txid #581
2021-05-29 11:45:06,852 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000581-0000000000000000581
2021-05-29 11:45:06,854 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000581-0000000000000000581' to transaction ID 581
2021-05-29 11:45:06,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000581-0000000000000000581 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-29 11:45:06,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3700ec9c expecting start txid #582
2021-05-29 11:45:06,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000582-0000000000000000582
2021-05-29 11:45:06,858 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000582-0000000000000000582' to transaction ID 581
2021-05-29 11:45:06,860 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000582-0000000000000000582 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-29 11:45:06,860 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2002348 expecting start txid #583
2021-05-29 11:45:06,860 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000583-0000000000000000583
2021-05-29 11:45:06,860 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000583-0000000000000000583' to transaction ID 581
2021-05-29 11:45:06,862 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000583-0000000000000000583 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-29 11:45:06,870 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-29 11:45:06,871 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 584
2021-05-29 11:45:07,015 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-29 11:45:07,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 402 msecs
2021-05-29 11:45:07,181 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-29 11:45:07,186 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 11:45:07,198 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-29 11:45:07,219 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-29 11:45:07,238 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 11:45:07,238 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 11:45:07,238 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 40 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-29 11:45:07,245 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 11:45:07,270 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 11:45:07,271 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-29 11:45:07,275 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 11:45:07,275 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-29 11:45:07,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-29 11:45:12,666 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0) storage 92478c8c-8e85-4c7e-8076-628dcc214550
2021-05-29 11:45:12,666 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 11:45:12,667 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-05-29 11:45:12,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 11:45:12,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 for DN 10.191.53.85:50010
2021-05-29 11:45:12,814 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 39 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-29 11:45:12,814 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-29 11:45:12,819 INFO BlockStateChange: BLOCK* processReport: from storage DS-78ffbbaf-50a0-435a-b4d3-49c483fcce12 node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=92478c8c-8e85-4c7e-8076-628dcc214550, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-089604ef-9031-4047-bc1b-ed64c513ac3b;nsid=791526008;c=0), blocks: 40, hasStaleStorage: false, processing time: 15 msecs
2021-05-29 11:45:12,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 40
2021-05-29 11:45:12,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-29 11:45:12,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 14
2021-05-29 11:45:12,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-29 11:45:12,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-29 11:45:12,824 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2021-05-29 11:45:32,987 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 40 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-29 11:45:43,065 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 36 secs
2021-05-29 11:45:43,065 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-29 11:45:43,065 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-29 11:45:43,065 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 14 blocks
2021-05-29 11:48:58,783 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 59 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-05-29 11:48:58,784 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741882_1058 10.191.53.85:50010 
2021-05-29 11:48:58,785 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741892_1068 10.191.53.85:50010 
2021-05-29 11:48:58,877 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741892_1068, blk_1073741882_1058]
2021-05-29 12:05:54,208 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 12:05:54,210 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 12:14:34,056 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 12:14:34,064 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 12:14:34,068 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 12:14:34,444 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 12:14:34,556 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 12:14:34,556 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 12:14:34,558 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 12:14:34,559 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 12:14:34,824 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 12:14:34,887 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 12:14:34,895 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 12:14:34,914 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 12:14:34,923 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 12:14:34,925 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 12:14:34,925 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 12:14:34,925 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 12:14:34,954 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 12:14:34,955 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 12:14:35,238 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50070
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:142)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:752)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:638)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 8 more
2021-05-29 12:14:35,240 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...
2021-05-29 12:14:35,241 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.
2021-05-29 12:14:35,241 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
2021-05-29 12:14:35,241 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
java.net.BindException: Port in use: 0.0.0.0:50070
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:142)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:752)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:638)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 8 more
2021-05-29 12:14:35,242 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-05-29 12:14:35,243 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 12:31:07,139 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 12:31:07,146 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 12:31:07,150 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 12:31:07,421 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 12:31:07,509 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 12:31:07,509 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 12:31:07,512 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 12:31:07,513 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 12:31:07,711 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 12:31:07,769 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 12:31:07,776 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 12:31:07,790 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 12:31:07,795 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 12:31:07,797 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 12:31:07,797 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 12:31:07,797 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 12:31:07,817 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 12:31:07,819 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 12:31:07,833 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50070
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:142)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:752)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:638)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 8 more
2021-05-29 12:31:07,835 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...
2021-05-29 12:31:07,835 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.
2021-05-29 12:31:07,835 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
2021-05-29 12:31:07,836 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
java.net.BindException: Port in use: 0.0.0.0:50070
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:142)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:752)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:638)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 8 more
2021-05-29 12:31:07,837 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-05-29 12:31:07,839 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 12:36:56,634 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 12:36:56,643 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 12:36:56,651 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 12:36:57,097 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 12:36:57,211 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 12:36:57,211 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 12:36:57,218 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 12:36:57,221 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 12:36:57,521 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 12:36:57,608 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 12:36:57,623 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 12:36:57,642 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 12:36:57,648 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 12:36:57,651 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 12:36:57,651 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 12:36:57,651 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 12:36:57,678 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 12:36:57,680 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 12:36:57,700 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50070
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:142)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:752)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:638)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 8 more
2021-05-29 12:36:57,703 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...
2021-05-29 12:36:57,703 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.
2021-05-29 12:36:57,703 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
2021-05-29 12:36:57,703 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
java.net.BindException: Port in use: 0.0.0.0:50070
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:142)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:752)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:638)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 8 more
2021-05-29 12:36:57,706 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-05-29 12:36:57,707 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 12:44:24,578 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 12:44:24,676 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 12:44:24,686 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 12:44:25,075 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 12:44:25,186 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 12:44:25,187 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 12:44:25,189 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 12:44:25,189 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 12:44:25,523 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 12:44:25,589 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 12:44:25,598 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 12:44:25,617 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 12:44:25,628 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 12:44:25,632 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 12:44:25,632 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 12:44:25,632 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 12:44:25,676 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 12:44:25,677 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 12:44:25,702 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50070
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:142)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:752)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:638)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 8 more
2021-05-29 12:44:25,704 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...
2021-05-29 12:44:25,705 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.
2021-05-29 12:44:25,705 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
2021-05-29 12:44:25,705 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
java.net.BindException: Port in use: 0.0.0.0:50070
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:142)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:752)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:638)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 8 more
2021-05-29 12:44:25,706 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-05-29 12:44:25,707 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 12:48:06,678 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 12:48:06,689 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 12:48:06,693 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 12:48:07,161 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 12:48:07,274 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 12:48:07,274 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 12:48:07,276 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 12:48:07,277 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 12:48:07,569 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 12:48:07,651 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 12:48:07,662 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 12:48:07,676 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 12:48:07,686 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 12:48:07,688 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 12:48:07,688 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 12:48:07,688 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 12:48:07,722 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 12:48:07,723 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 12:48:07,754 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50070
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:142)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:752)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:638)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 8 more
2021-05-29 12:48:07,757 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...
2021-05-29 12:48:07,758 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.
2021-05-29 12:48:07,758 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
2021-05-29 12:48:07,758 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
java.net.BindException: Port in use: 0.0.0.0:50070
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:142)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:752)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:638)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 8 more
2021-05-29 12:48:07,760 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-05-29 12:48:07,762 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 12:51:59,463 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 12:51:59,470 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 12:51:59,474 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 12:51:59,755 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 12:51:59,838 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 12:51:59,838 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 12:51:59,840 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 12:51:59,841 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 12:52:00,020 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 12:52:00,071 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 12:52:00,078 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 12:52:00,091 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 12:52:00,096 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 12:52:00,098 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 12:52:00,098 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 12:52:00,098 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 12:52:00,118 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 12:52:00,119 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 12:52:00,132 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50070
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:142)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:752)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:638)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 8 more
2021-05-29 12:52:00,135 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...
2021-05-29 12:52:00,135 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.
2021-05-29 12:52:00,135 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
2021-05-29 12:52:00,135 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
java.net.BindException: Port in use: 0.0.0.0:50070
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:142)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:752)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:638)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 8 more
2021-05-29 12:52:00,137 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-05-29 12:52:00,138 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 12:59:40,264 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 12:59:40,313 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 12:59:40,328 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 12:59:40,956 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 12:59:41,303 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 12:59:41,303 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 12:59:41,306 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 12:59:41,307 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 12:59:42,302 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 12:59:42,623 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 12:59:42,631 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 12:59:42,672 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 12:59:42,678 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 12:59:42,680 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 12:59:42,681 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 12:59:42,681 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 12:59:42,839 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 12:59:42,841 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 12:59:43,069 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-29 12:59:43,069 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 12:59:44,066 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-29 12:59:44,310 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 12:59:44,310 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 12:59:44,442 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-29 12:59:44,442 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-29 12:59:44,838 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-29 12:59:44,839 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-29 12:59:44,840 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-29 12:59:44,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 29 12:59:44
2021-05-29 12:59:44,921 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-29 12:59:44,921 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 12:59:44,957 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-29 12:59:44,957 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-29 12:59:44,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-29 12:59:44,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-29 12:59:44,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-29 12:59:44,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-29 12:59:44,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-29 12:59:44,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-29 12:59:44,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-29 12:59:44,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-29 12:59:45,105 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-29 12:59:45,105 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-29 12:59:45,105 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-29 12:59:45,105 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-29 12:59:45,134 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-29 12:59:46,377 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-29 12:59:46,377 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 12:59:46,377 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-29 12:59:46,377 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-29 12:59:46,379 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-29 12:59:46,379 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-29 12:59:46,379 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-29 12:59:46,379 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-29 12:59:46,391 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-29 12:59:46,391 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 12:59:46,391 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-29 12:59:46,391 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-29 12:59:46,393 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-29 12:59:46,393 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-29 12:59:46,393 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-29 12:59:46,412 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-29 12:59:46,412 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-29 12:59:46,412 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-29 12:59:46,414 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-29 12:59:46,414 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-29 12:59:46,467 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-29 12:59:46,467 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 12:59:46,468 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-29 12:59:46,468 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-29 12:59:46,531 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /opt/hadoop-2.7.2/data/tmp/dfs/name does not exist
2021-05-29 12:59:46,535 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Encountered exception loading fsimage
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /opt/hadoop-2.7.2/data/tmp/dfs/name is in an inconsistent state: storage directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:327)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:215)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:975)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:584)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:644)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
2021-05-29 12:59:46,573 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-29 12:59:46,681 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...
2021-05-29 12:59:46,682 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.
2021-05-29 12:59:46,682 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
2021-05-29 12:59:46,682 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /opt/hadoop-2.7.2/data/tmp/dfs/name is in an inconsistent state: storage directory does not exist or is not accessible.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:327)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:215)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:975)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:584)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:644)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:811)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:795)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1554)
2021-05-29 12:59:46,684 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-05-29 12:59:46,702 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-29 13:04:30,995 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN.localdomain/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 13:04:31,003 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 13:04:31,007 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 13:04:31,274 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 13:04:31,348 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 13:04:31,348 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 13:04:31,350 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 13:04:31,351 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 13:04:31,562 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 13:04:31,613 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 13:04:31,620 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 13:04:31,635 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 13:04:31,639 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 13:04:31,641 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 13:04:31,641 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 13:04:31,641 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 13:04:31,661 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 13:04:31,663 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 13:04:31,675 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-29 13:04:31,675 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 13:04:31,785 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-29 13:04:31,825 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 13:04:31,825 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 13:04:31,859 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-29 13:04:31,859 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-29 13:04:31,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-29 13:04:31,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-29 13:04:31,899 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-29 13:04:31,900 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 29 13:04:31
2021-05-29 13:04:31,902 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-29 13:04:31,902 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 13:04:31,903 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-29 13:04:31,903 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-29 13:04:31,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-29 13:04:31,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-29 13:04:31,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-29 13:04:31,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-29 13:04:31,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-29 13:04:31,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-29 13:04:31,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-29 13:04:31,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-29 13:04:31,917 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-29 13:04:31,917 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-29 13:04:31,917 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-29 13:04:31,917 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-29 13:04:31,918 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-29 13:04:32,109 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-29 13:04:32,109 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 13:04:32,110 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-29 13:04:32,110 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-29 13:04:32,111 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-29 13:04:32,111 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-29 13:04:32,111 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-29 13:04:32,111 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-29 13:04:32,118 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-29 13:04:32,118 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 13:04:32,118 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-29 13:04:32,118 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-29 13:04:32,119 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-29 13:04:32,119 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-29 13:04:32,120 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-29 13:04:32,122 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-29 13:04:32,122 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-29 13:04:32,122 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-29 13:04:32,124 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-29 13:04:32,124 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-29 13:04:32,126 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-29 13:04:32,126 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 13:04:32,126 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-29 13:04:32,126 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-29 13:04:32,147 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 284@DESKTOP-TSQQRSN.localdomain
2021-05-29 13:04:32,203 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-29 13:04:32,204 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2021-05-29 13:04:32,249 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-05-29 13:04:32,277 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-29 13:04:32,278 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000000
2021-05-29 13:04:32,285 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-29 13:04:32,285 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2021-05-29 13:04:32,436 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-29 13:04:32,437 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 308 msecs
2021-05-29 13:04:32,927 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-29 13:04:32,951 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 13:04:33,010 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-29 13:04:33,123 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-29 13:04:33,185 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 13:04:33,185 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 13:04:33,185 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-29 13:04:33,185 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2021-05-29 13:04:33,185 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-05-29 13:04:33,185 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-05-29 13:04:33,193 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 13:04:33,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2021-05-29 13:04:33,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-29 13:04:33,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-29 13:04:33,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-29 13:04:33,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-29 13:04:33,194 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2021-05-29 13:04:33,231 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 13:04:33,231 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-29 13:04:33,235 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/127.0.1.1:9000
2021-05-29 13:04:33,236 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-29 13:04:33,239 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-29 13:05:37,349 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 13:05:37,351 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN.localdomain/127.0.1.1
************************************************************/
2021-05-29 13:07:09,155 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 13:07:09,163 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 13:07:09,167 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 13:07:09,428 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 13:07:09,502 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 13:07:09,502 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 13:07:09,504 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 13:07:09,505 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 13:07:09,676 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 13:07:09,728 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 13:07:09,735 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 13:07:09,750 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 13:07:09,754 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 13:07:09,759 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 13:07:09,759 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 13:07:09,759 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 13:07:09,785 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 13:07:09,787 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 13:07:09,800 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-29 13:07:09,800 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 13:07:09,909 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-29 13:07:09,956 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 13:07:09,956 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 13:07:09,995 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-29 13:07:09,995 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-29 13:07:10,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-29 13:07:10,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-29 13:07:10,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-29 13:07:10,042 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 29 13:07:10
2021-05-29 13:07:10,044 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-29 13:07:10,044 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 13:07:10,045 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-29 13:07:10,045 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-29 13:07:10,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-29 13:07:10,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-29 13:07:10,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-29 13:07:10,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-29 13:07:10,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-29 13:07:10,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-29 13:07:10,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-29 13:07:10,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-29 13:07:10,063 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-29 13:07:10,064 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-29 13:07:10,064 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-29 13:07:10,064 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-29 13:07:10,065 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-29 13:07:10,259 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-29 13:07:10,259 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 13:07:10,259 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-29 13:07:10,259 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-29 13:07:10,260 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-29 13:07:10,260 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-29 13:07:10,260 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-29 13:07:10,260 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-29 13:07:10,266 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-29 13:07:10,266 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 13:07:10,266 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-29 13:07:10,266 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-29 13:07:10,267 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-29 13:07:10,267 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-29 13:07:10,267 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-29 13:07:10,270 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-29 13:07:10,270 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-29 13:07:10,270 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-29 13:07:10,272 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-29 13:07:10,272 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-29 13:07:10,274 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-29 13:07:10,274 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 13:07:10,274 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-29 13:07:10,274 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-29 13:07:10,282 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 676@DESKTOP-TSQQRSN
2021-05-29 13:07:10,325 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-29 13:07:10,326 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2021-05-29 13:07:10,358 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-05-29 13:07:10,384 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-29 13:07:10,384 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000000
2021-05-29 13:07:10,392 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-29 13:07:10,392 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2021-05-29 13:07:10,540 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-29 13:07:10,540 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 264 msecs
2021-05-29 13:07:10,760 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-29 13:07:10,770 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 13:07:10,780 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-29 13:07:10,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-29 13:07:10,818 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 13:07:10,818 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 13:07:10,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-29 13:07:10,819 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2021-05-29 13:07:10,819 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-05-29 13:07:10,819 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-05-29 13:07:10,825 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 13:07:10,827 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2021-05-29 13:07:10,828 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-29 13:07:10,828 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-29 13:07:10,828 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-29 13:07:10,828 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-29 13:07:10,828 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2021-05-29 13:07:10,848 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 13:07:10,848 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-29 13:07:10,852 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 13:07:10,852 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-29 13:07:10,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-29 13:07:42,467 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-05-29 13:07:42,467 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 13:07:42,468 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-05-29 13:07:42,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 13:07:42,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-05-29 13:07:42,623 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 0, hasStaleStorage: false, processing time: 12 msecs
2021-05-29 13:08:40,974 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 39 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 7 
2021-05-29 13:08:50,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/wc.input._COPYING_
2021-05-29 13:08:50,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/root/input/wc.input._COPYING_
2021-05-29 13:08:50,485 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 53
2021-05-29 13:08:50,886 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/wc.input._COPYING_ is closed by DFSClient_NONMAPREDUCE_867993242_1
2021-05-29 13:09:15,448 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job.jar
2021-05-29 13:09:15,679 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 13:09:15,683 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job.jar is closed by DFSClient_NONMAPREDUCE_1939157955_1
2021-05-29 13:09:15,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job.jar
2021-05-29 13:09:15,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job.split
2021-05-29 13:09:15,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job.split
2021-05-29 13:09:15,906 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 13:09:15,908 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job.split is closed by DFSClient_NONMAPREDUCE_1939157955_1
2021-05-29 13:09:15,923 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job.splitmetainfo
2021-05-29 13:09:15,931 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 13:09:15,936 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1939157955_1
2021-05-29 13:09:16,279 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job.xml
2021-05-29 13:09:16,309 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 13:09:16,311 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job.xml is closed by DFSClient_NONMAPREDUCE_1939157955_1
2021-05-29 13:09:25,471 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job_1622264873807_0001_1_conf.xml
2021-05-29 13:09:25,553 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 13:09:25,557 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job_1622264873807_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-594974019_1
2021-05-29 13:09:30,335 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job_1622264873807_0001_1.jhist
2021-05-29 13:09:30,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job_1622264873807_0001_1.jhist for DFSClient_NONMAPREDUCE_-594974019_1
2021-05-29 13:09:36,832 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/output/_temporary/1/_temporary/attempt_1622264873807_0001_r_000000_0/part-r-00000
2021-05-29 13:09:37,106 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 13:09:37,111 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_temporary/1/_temporary/attempt_1622264873807_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622264873807_0001_r_000000_0_-233333853_1
2021-05-29 13:09:37,252 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-594974019_1
2021-05-29 13:09:37,328 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-594974019_1
2021-05-29 13:09:37,334 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-594974019_1
2021-05-29 13:09:37,368 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 13121
2021-05-29 13:09:37,370 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622264873807_0001/job_1622264873807_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_-594974019_1
2021-05-29 13:09:37,379 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622264873807_0001.summary_tmp
2021-05-29 13:09:37,397 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 13:09:37,399 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622264873807_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_-594974019_1
2021-05-29 13:09:37,433 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622264873807_0001-1622264956723-root-word+count-1622264977336-1-1-SUCCEEDED-default-1622264965297.jhist_tmp
2021-05-29 13:09:37,447 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 13:09:37,449 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622264873807_0001-1622264956723-root-word+count-1622264977336-1-1-SUCCEEDED-default-1622264965297.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-594974019_1
2021-05-29 13:09:37,466 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622264873807_0001_conf.xml_tmp
2021-05-29 13:09:37,478 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 13:09:37,479 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622264873807_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-594974019_1
2021-05-29 13:09:38,516 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741826_1002 10.191.53.85:50010 
2021-05-29 13:09:38,516 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741827_1003 10.191.53.85:50010 
2021-05-29 13:09:38,516 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741828_1004 10.191.53.85:50010 
2021-05-29 13:09:38,516 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741829_1005 10.191.53.85:50010 
2021-05-29 13:09:38,517 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741831_1007 10.191.53.85:50010 
2021-05-29 13:09:38,517 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741830_1006 10.191.53.85:50010 
2021-05-29 13:09:41,222 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741826_1002, blk_1073741827_1003, blk_1073741828_1004, blk_1073741829_1005, blk_1073741830_1006, blk_1073741831_1007]
2021-05-29 13:09:44,359 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 110 Total time for transactions(ms): 50 Number of transactions batched in Syncs: 1 Number of syncs: 77 SyncTimes(ms): 64 
2021-05-29 13:09:44,425 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/logs/root/logs/application_1622264873807_0001/DESKTOP-TSQQRSN_49828.tmp
2021-05-29 13:09:44,500 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 13:09:44,504 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/logs/root/logs/application_1622264873807_0001/DESKTOP-TSQQRSN_49828.tmp is closed by DFSClient_NONMAPREDUCE_1797568578_93
2021-05-29 13:09:54,112 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741833_1009 10.191.53.85:50010 
2021-05-29 13:09:56,270 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741833_1009]
2021-05-29 14:06:05,594 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 14:06:05,690 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 14:06:05,699 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 14:06:06,155 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 14:06:06,472 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 14:06:06,472 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 14:06:06,475 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 14:06:06,476 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 14:06:06,768 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 14:06:07,047 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 14:06:07,058 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 14:06:07,106 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 14:06:07,116 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 14:06:07,119 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 14:06:07,119 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 14:06:07,119 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 14:06:07,212 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 14:06:07,214 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 14:06:07,292 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-29 14:06:07,292 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 14:06:07,705 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-29 14:06:07,775 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 14:06:07,775 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 14:06:07,834 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-29 14:06:07,834 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-29 14:06:07,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-29 14:06:07,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-29 14:06:07,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-29 14:06:07,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 29 14:06:07
2021-05-29 14:06:07,958 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-29 14:06:07,958 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 14:06:07,961 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-29 14:06:07,962 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-29 14:06:07,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-29 14:06:07,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-29 14:06:07,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-29 14:06:07,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-29 14:06:07,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-29 14:06:07,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-29 14:06:07,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-29 14:06:07,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-29 14:06:07,979 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-29 14:06:07,979 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-29 14:06:07,979 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-29 14:06:07,979 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-29 14:06:07,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-29 14:06:08,571 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-29 14:06:08,571 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 14:06:08,571 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-29 14:06:08,571 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-29 14:06:08,572 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-29 14:06:08,572 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-29 14:06:08,572 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-29 14:06:08,572 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-29 14:06:08,581 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-29 14:06:08,581 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 14:06:08,581 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-29 14:06:08,581 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-29 14:06:08,582 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-29 14:06:08,582 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-29 14:06:08,582 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-29 14:06:08,587 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-29 14:06:08,587 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-29 14:06:08,587 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-29 14:06:08,589 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-29 14:06:08,589 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-29 14:06:08,612 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-29 14:06:08,612 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 14:06:08,612 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-29 14:06:08,612 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-29 14:06:08,694 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 935@DESKTOP-TSQQRSN
2021-05-29 14:06:08,802 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-29 14:06:09,197 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000122
2021-05-29 14:06:09,279 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-05-29 14:06:09,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-29 14:06:09,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000000
2021-05-29 14:06:09,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@555cf22 expecting start txid #1
2021-05-29 14:06:09,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000122
2021-05-29 14:06:09,357 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000122' to transaction ID 1
2021-05-29 14:06:09,426 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000122 of size 1048576 edits # 122 loaded in 0 seconds
2021-05-29 14:06:09,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-29 14:06:09,428 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 123
2021-05-29 14:06:09,571 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-29 14:06:09,572 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 929 msecs
2021-05-29 14:06:09,971 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-29 14:06:10,006 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 14:06:10,050 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-29 14:06:10,136 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-29 14:06:10,188 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 14:06:10,188 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 14:06:10,189 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 5 blocks to reach the threshold 0.9990 of total blocks 5.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-29 14:06:10,203 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 14:06:10,233 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 14:06:10,233 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-29 14:06:10,237 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 14:06:10,237 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-29 14:06:10,241 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-29 14:06:13,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-05-29 14:06:13,587 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 14:06:13,588 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-05-29 14:06:13,701 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 14:06:13,701 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-05-29 14:06:13,775 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 4 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-29 14:06:13,775 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-29 14:06:13,777 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 5, hasStaleStorage: false, processing time: 22 msecs
2021-05-29 14:06:13,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 5
2021-05-29 14:06:13,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-29 14:06:13,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-29 14:06:13,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-29 14:06:13,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-29 14:06:13,779 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2021-05-29 14:06:33,852 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-29 14:06:43,905 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 36 secs
2021-05-29 14:06:43,906 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-29 14:06:43,906 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-29 14:06:43,906 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-05-29 14:10:42,762 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 14:10:42,766 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 14:29:46,683 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 14:29:46,690 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 14:29:46,696 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 14:29:46,961 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 14:29:47,037 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 14:29:47,037 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 14:29:47,039 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 14:29:47,040 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 14:29:47,204 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 14:29:47,265 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 14:29:47,272 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 14:29:47,285 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 14:29:47,290 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 14:29:47,291 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 14:29:47,291 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 14:29:47,292 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 14:29:47,311 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 14:29:47,312 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 14:29:47,325 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-29 14:29:47,325 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 14:29:47,464 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-29 14:29:47,500 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 14:29:47,500 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 14:29:47,535 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-29 14:29:47,535 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-29 14:29:47,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-29 14:29:47,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-29 14:29:47,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-29 14:29:47,575 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 29 14:29:47
2021-05-29 14:29:47,577 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-29 14:29:47,577 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 14:29:47,579 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-29 14:29:47,579 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-29 14:29:47,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-29 14:29:47,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-29 14:29:47,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-29 14:29:47,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-29 14:29:47,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-29 14:29:47,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-29 14:29:47,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-29 14:29:47,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-29 14:29:47,592 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-29 14:29:47,592 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-29 14:29:47,592 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-29 14:29:47,593 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-29 14:29:47,594 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-29 14:29:47,777 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-29 14:29:47,777 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 14:29:47,777 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-29 14:29:47,777 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-29 14:29:47,778 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-29 14:29:47,778 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-29 14:29:47,778 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-29 14:29:47,778 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-29 14:29:47,784 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-29 14:29:47,785 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 14:29:47,785 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-29 14:29:47,785 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-29 14:29:47,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-29 14:29:47,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-29 14:29:47,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-29 14:29:47,789 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-29 14:29:47,789 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-29 14:29:47,789 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-29 14:29:47,790 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-29 14:29:47,790 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-29 14:29:47,792 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-29 14:29:47,792 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 14:29:47,792 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-29 14:29:47,792 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-29 14:29:47,801 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 3350@DESKTOP-TSQQRSN
2021-05-29 14:29:47,850 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-29 14:29:47,880 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000123 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000123-0000000000000000123
2021-05-29 14:29:47,960 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2021-05-29 14:29:47,987 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-29 14:29:47,988 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000000
2021-05-29 14:29:47,988 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@51972dc7 expecting start txid #1
2021-05-29 14:29:47,988 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000122
2021-05-29 14:29:47,989 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000122' to transaction ID 1
2021-05-29 14:29:48,108 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000122 of size 1048576 edits # 122 loaded in 0 seconds
2021-05-29 14:29:48,108 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3700ec9c expecting start txid #123
2021-05-29 14:29:48,109 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000123-0000000000000000123
2021-05-29 14:29:48,109 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000123-0000000000000000123' to transaction ID 1
2021-05-29 14:29:48,110 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000123-0000000000000000123 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-29 14:29:48,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-05-29 14:29:48,111 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-05-29 14:29:48,298 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2021-05-29 14:29:48,313 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 124
2021-05-29 14:29:48,447 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-29 14:29:48,447 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 653 msecs
2021-05-29 14:29:48,610 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-29 14:29:48,616 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 14:29:48,625 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-29 14:29:48,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-29 14:29:48,669 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 14:29:48,669 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 14:29:48,670 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 5 blocks to reach the threshold 0.9990 of total blocks 5.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-29 14:29:48,676 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 14:29:48,699 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 14:29:48,699 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-29 14:29:48,703 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 14:29:48,703 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-29 14:29:48,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-29 14:29:53,446 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-05-29 14:29:53,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 14:29:53,447 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-05-29 14:29:53,538 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 14:29:53,538 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-05-29 14:29:53,579 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 4 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-29 14:29:53,579 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-29 14:29:53,581 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 5, hasStaleStorage: false, processing time: 5 msecs
2021-05-29 14:29:53,582 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 5
2021-05-29 14:29:53,582 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-29 14:29:53,582 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-29 14:29:53,582 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-29 14:29:53,582 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-29 14:29:53,582 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 2 msec
2021-05-29 14:30:12,857 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 14:30:12,860 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 14:30:51,506 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.7.2/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 14:30:51,514 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 14:30:51,518 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 14:30:51,780 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 14:30:51,853 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 14:30:51,853 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 14:30:51,855 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 14:30:51,856 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 14:30:52,083 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 14:30:52,144 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 14:30:52,151 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 14:30:52,165 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 14:30:52,170 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 14:30:52,172 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 14:30:52,172 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 14:30:52,172 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 14:30:52,192 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 14:30:52,193 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 14:30:52,206 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-29 14:30:52,206 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 14:30:52,309 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-29 14:30:52,640 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 14:30:52,640 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 14:30:52,679 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-29 14:30:52,679 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-29 14:30:52,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-29 14:30:52,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-29 14:30:52,721 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-29 14:30:52,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 29 14:30:52
2021-05-29 14:30:52,724 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-29 14:30:52,724 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 14:30:52,726 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-29 14:30:52,726 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-29 14:30:52,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-29 14:30:52,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-29 14:30:52,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-29 14:30:52,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-29 14:30:52,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-29 14:30:52,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-29 14:30:52,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-29 14:30:52,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-29 14:30:52,745 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-29 14:30:52,745 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-29 14:30:52,745 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-29 14:30:52,745 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-29 14:30:52,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-29 14:30:52,952 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-29 14:30:52,952 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 14:30:52,953 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-29 14:30:52,953 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-29 14:30:52,953 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-29 14:30:52,953 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-29 14:30:52,953 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-29 14:30:52,953 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-29 14:30:52,960 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-29 14:30:52,960 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 14:30:52,960 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-29 14:30:52,960 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-29 14:30:52,961 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-29 14:30:52,961 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-29 14:30:52,961 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-29 14:30:52,964 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-29 14:30:52,964 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-29 14:30:52,964 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-29 14:30:52,966 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-29 14:30:52,966 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-29 14:30:52,968 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-29 14:30:52,968 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 14:30:52,968 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-29 14:30:52,968 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-29 14:30:52,977 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 4328@DESKTOP-TSQQRSN
2021-05-29 14:30:53,027 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-29 14:30:53,062 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000124 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000124-0000000000000000124
2021-05-29 14:30:53,100 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 28 INodes.
2021-05-29 14:30:53,193 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-29 14:30:53,193 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 123 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000123
2021-05-29 14:30:53,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2807bdeb expecting start txid #124
2021-05-29 14:30:53,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000124-0000000000000000124
2021-05-29 14:30:53,195 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000124-0000000000000000124' to transaction ID 124
2021-05-29 14:30:53,198 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000124-0000000000000000124 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-29 14:30:53,203 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-05-29 14:30:53,204 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 125
2021-05-29 14:30:53,370 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-29 14:30:53,370 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 400 msecs
2021-05-29 14:30:53,517 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-29 14:30:53,522 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 14:30:53,532 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-29 14:30:53,553 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-29 14:30:53,571 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 14:30:53,571 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 14:30:53,572 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 5 blocks to reach the threshold 0.9990 of total blocks 5.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-29 14:30:53,578 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 14:30:53,605 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 14:30:53,605 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-29 14:30:53,608 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 14:30:53,609 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-29 14:30:53,615 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-29 14:32:11,018 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-05-29 14:32:11,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 14:32:11,018 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-05-29 14:32:11,020 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 5 blocks to reach the threshold 0.9990 of total blocks 5.
The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-29 14:32:11,106 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 14:32:11,106 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-05-29 14:32:11,151 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 4 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-29 14:32:11,151 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-29 14:32:11,153 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 5, hasStaleStorage: false, processing time: 8 msecs
2021-05-29 14:32:11,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 5
2021-05-29 14:32:11,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-29 14:32:11,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-29 14:32:11,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-29 14:32:11,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-29 14:32:11,158 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2021-05-29 14:32:31,231 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-29 14:32:41,323 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 108 secs
2021-05-29 14:32:41,324 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-29 14:32:41,324 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-29 14:32:41,324 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-05-29 14:34:11,970 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2021-05-29 14:41:13,914 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 6 
2021-05-29 14:41:57,793 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/capacity-scheduler.xml._COPYING_
2021-05-29 14:41:58,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741837_1013{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/root/input0x00/capacity-scheduler.xml._COPYING_
2021-05-29 14:41:58,016 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-05-29 14:41:58,029 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741837_1013{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 4436
2021-05-29 14:41:58,431 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/capacity-scheduler.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/configuration.xsl._COPYING_
2021-05-29 14:41:58,528 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,531 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/configuration.xsl._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,552 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/container-executor.cfg._COPYING_
2021-05-29 14:41:58,565 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,567 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/container-executor.cfg._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/core-site.xml._COPYING_
2021-05-29 14:41:58,590 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,592 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/core-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,611 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/hadoop-env.cmd._COPYING_
2021-05-29 14:41:58,621 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,624 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/hadoop-env.cmd._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,636 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/hadoop-env.sh._COPYING_
2021-05-29 14:41:58,647 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,649 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/hadoop-env.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,670 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/hadoop-metrics.properties._COPYING_
2021-05-29 14:41:58,681 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,683 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/hadoop-metrics.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,698 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/hadoop-metrics2.properties._COPYING_
2021-05-29 14:41:58,709 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,710 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/hadoop-metrics2.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,737 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/hadoop-policy.xml._COPYING_
2021-05-29 14:41:58,750 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,751 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/hadoop-policy.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,764 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/hdfs-site.xml._COPYING_
2021-05-29 14:41:58,776 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,779 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/hdfs-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,806 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/httpfs-env.sh._COPYING_
2021-05-29 14:41:58,817 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,819 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/httpfs-env.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/httpfs-log4j.properties._COPYING_
2021-05-29 14:41:58,845 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,847 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/httpfs-log4j.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,859 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/httpfs-signature.secret._COPYING_
2021-05-29 14:41:58,870 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,872 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/httpfs-signature.secret._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/httpfs-site.xml._COPYING_
2021-05-29 14:41:58,897 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,899 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/httpfs-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,926 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/kms-acls.xml._COPYING_
2021-05-29 14:41:58,936 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,939 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/kms-acls.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,962 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/kms-env.sh._COPYING_
2021-05-29 14:41:58,974 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:58,976 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/kms-env.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:58,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/kms-log4j.properties._COPYING_
2021-05-29 14:41:59,008 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,010 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/kms-log4j.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:59,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/kms-site.xml._COPYING_
2021-05-29 14:41:59,044 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,046 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/kms-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:59,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/log4j.properties._COPYING_
2021-05-29 14:41:59,070 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,072 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/log4j.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:59,094 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/mapred-env.cmd._COPYING_
2021-05-29 14:41:59,105 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741856_1032{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,107 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/mapred-env.cmd._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:59,119 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/mapred-env.sh._COPYING_
2021-05-29 14:41:59,128 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741857_1033{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,146 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/mapred-env.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:59,171 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/mapred-queues.xml.template._COPYING_
2021-05-29 14:41:59,181 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741858_1034{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,183 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/mapred-queues.xml.template._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:59,196 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/mapred-site.xml._COPYING_
2021-05-29 14:41:59,206 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741859_1035{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,208 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/mapred-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:59,221 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/slaves._COPYING_
2021-05-29 14:41:59,230 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741860_1036{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,232 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/slaves._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:59,255 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/ssl-client.xml.example._COPYING_
2021-05-29 14:41:59,265 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741861_1037{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,289 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/ssl-client.xml.example._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:59,317 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/ssl-server.xml.example._COPYING_
2021-05-29 14:41:59,333 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741862_1038{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,337 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/ssl-server.xml.example._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:59,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/yarn-env.cmd._COPYING_
2021-05-29 14:41:59,375 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741863_1039{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,377 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/yarn-env.cmd._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:59,393 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/yarn-env.sh._COPYING_
2021-05-29 14:41:59,406 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741864_1040{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,408 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/yarn-env.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:41:59,424 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input0x00/yarn-site.xml._COPYING_
2021-05-29 14:41:59,437 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741865_1041{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:41:59,440 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input0x00/yarn-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_854206194_1
2021-05-29 14:43:03,299 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 179 Total time for transactions(ms): 38 Number of transactions batched in Syncs: 0 Number of syncs: 121 SyncTimes(ms): 132 
2021-05-29 14:43:03,370 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job.jar
2021-05-29 14:43:03,488 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741866_1042{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:43:03,493 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-626930045_1
2021-05-29 14:43:03,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job.jar
2021-05-29 14:43:03,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job.split
2021-05-29 14:43:03,675 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job.split
2021-05-29 14:43:03,684 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741867_1043{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:43:03,686 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job.split is closed by DFSClient_NONMAPREDUCE_-626930045_1
2021-05-29 14:43:03,696 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job.splitmetainfo
2021-05-29 14:43:03,706 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741868_1044{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:43:03,708 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-626930045_1
2021-05-29 14:43:03,795 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job.xml
2021-05-29 14:43:03,804 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741869_1045{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:43:03,806 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-626930045_1
2021-05-29 14:43:11,411 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job_1622270333365_0001_1_conf.xml
2021-05-29 14:43:11,490 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741870_1046{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:43:11,494 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job_1622270333365_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1024477442_1
2021-05-29 14:43:21,814 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job_1622270333365_0001_1.jhist
2021-05-29 14:43:21,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job_1622270333365_0001_1.jhist for DFSClient_NONMAPREDUCE_-1024477442_1
2021-05-29 14:44:06,978 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 224 Total time for transactions(ms): 42 Number of transactions batched in Syncs: 0 Number of syncs: 150 SyncTimes(ms): 156 
2021-05-29 14:44:07,180 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/output0x00/_temporary/1/_temporary/attempt_1622270333365_0001_r_000000_0/part-r-00000
2021-05-29 14:44:07,365 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741872_1048{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:44:07,373 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output0x00/_temporary/1/_temporary/attempt_1622270333365_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622270333365_0001_r_000000_0_905241161_1
2021-05-29 14:44:07,457 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1024477442_1
2021-05-29 14:44:07,585 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output0x00/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1024477442_1
2021-05-29 14:44:07,595 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1024477442_1
2021-05-29 14:44:07,628 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741871_1047{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 21236
2021-05-29 14:44:07,944 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622270333365_0001/job_1622270333365_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_-1024477442_1
2021-05-29 14:44:07,992 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622270333365_0001.summary_tmp
2021-05-29 14:44:08,329 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741873_1049{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:44:08,332 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622270333365_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1024477442_1
2021-05-29 14:44:08,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622270333365_0001-1622270584104-root-word+count-1622270647597-29-1-SUCCEEDED-default-1622270591192.jhist_tmp
2021-05-29 14:44:08,390 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741874_1050{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:44:08,392 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622270333365_0001-1622270584104-root-word+count-1622270647597-29-1-SUCCEEDED-default-1622270591192.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1024477442_1
2021-05-29 14:44:08,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622270333365_0001_conf.xml_tmp
2021-05-29 14:44:08,419 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741875_1051{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:44:08,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622270333365_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1024477442_1
2021-05-29 14:44:09,472 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741866_1042 10.191.53.85:50010 
2021-05-29 14:44:09,472 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741867_1043 10.191.53.85:50010 
2021-05-29 14:44:09,472 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741868_1044 10.191.53.85:50010 
2021-05-29 14:44:09,472 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741869_1045 10.191.53.85:50010 
2021-05-29 14:44:09,472 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741871_1047 10.191.53.85:50010 
2021-05-29 14:44:09,473 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741870_1046 10.191.53.85:50010 
2021-05-29 14:44:10,505 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741866_1042, blk_1073741867_1043, blk_1073741868_1044, blk_1073741869_1045, blk_1073741870_1046, blk_1073741871_1047]
2021-05-29 14:44:15,668 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/logs/root/logs/application_1622270333365_0001/DESKTOP-TSQQRSN_52483.tmp
2021-05-29 14:44:15,726 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741876_1052{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-29 14:44:15,729 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/logs/root/logs/application_1622270333365_0001/DESKTOP-TSQQRSN_52483.tmp is closed by DFSClient_NONMAPREDUCE_-1532685249_105
2021-05-29 14:46:24,952 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 267 Total time for transactions(ms): 44 Number of transactions batched in Syncs: 0 Number of syncs: 183 SyncTimes(ms): 893 
2021-05-29 14:46:24,954 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741873_1049 10.191.53.85:50010 
2021-05-29 14:46:25,809 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741873_1049]
2021-05-29 14:49:05,262 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-05-29 14:49:05,262 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 0
2021-05-29 14:49:05,262 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2021-05-29 14:49:05,262 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-05-29 14:49:05,262 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2021-05-29 14:49:05,262 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2021-05-29 14:49:05,262 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2021-05-29 14:49:05,262 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2021-05-29 14:49:05,262 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2021-05-29 14:49:05,262 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-05-29 14:49:05,262 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2021-05-29 14:49:05,272 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 2
2021-05-29 14:49:05,273 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 1
2021-05-29 14:49:05,273 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-05-29 14:49:05,273 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-05-29 14:49:05,273 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2021-05-29 14:49:05,273 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-05-29 14:49:05,273 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2021-05-29 14:49:05,273 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2021-05-29 14:49:05,273 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2021-05-29 14:49:05,273 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2021-05-29 14:49:05,273 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 2
2021-05-29 14:49:05,273 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 2
2021-05-29 14:49:05,274 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 1
2021-05-29 14:49:05,274 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-05-29 14:49:05,274 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2021-05-29 14:49:05,274 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2021-05-29 14:49:05,274 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-05-29 14:49:05,274 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2021-05-29 14:49:05,274 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2021-05-29 14:49:05,274 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 1
2021-05-29 14:49:05,274 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2021-05-29 14:49:05,274 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 2
2021-05-29 14:57:46,945 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-05-29 14:57:46,946 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 0
2021-05-29 14:57:46,946 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2021-05-29 14:57:46,946 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-05-29 14:57:46,946 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-05-29 14:57:46,946 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2021-05-29 14:57:46,947 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 2
2021-05-29 14:57:46,948 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 1
2021-05-29 14:57:46,948 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-05-29 14:57:46,948 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2021-05-29 14:57:46,948 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2021-05-29 14:57:46,948 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-05-29 14:57:46,948 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2021-05-29 14:57:46,948 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2021-05-29 14:57:46,948 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 1
2021-05-29 14:57:46,948 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2021-05-29 14:57:46,948 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 2
2021-05-29 14:57:52,097 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-05-29 14:57:52,097 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 0
2021-05-29 14:57:52,097 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2021-05-29 14:57:52,097 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-05-29 14:57:52,097 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-05-29 14:57:52,097 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2021-05-29 14:57:52,097 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 2
2021-05-29 14:57:52,098 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 1
2021-05-29 14:57:52,099 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-05-29 14:57:52,099 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2021-05-29 14:57:52,099 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2021-05-29 14:57:52,099 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-05-29 14:57:52,099 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2021-05-29 14:57:52,099 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2021-05-29 14:57:52,099 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 1
2021-05-29 14:57:52,099 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2021-05-29 14:57:52,099 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 2
2021-05-29 15:00:48,505 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2221ms
No GCs detected
2021-05-29 15:06:50,966 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 15:06:50,969 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-29 15:59:20,563 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-29 15:59:20,692 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-29 15:59:20,706 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-29 15:59:21,224 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-29 15:59:21,842 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-29 15:59:21,842 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-29 15:59:21,844 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-29 15:59:21,845 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-29 15:59:22,196 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-29 15:59:22,368 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-29 15:59:22,376 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-29 15:59:22,426 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-29 15:59:22,431 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-29 15:59:22,433 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-29 15:59:22,434 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-29 15:59:22,434 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-29 15:59:22,478 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-29 15:59:22,481 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-29 15:59:22,528 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-29 15:59:22,528 INFO org.mortbay.log: jetty-6.1.26
2021-05-29 15:59:22,962 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-29 15:59:23,050 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 15:59:23,050 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-29 15:59:23,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-29 15:59:23,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-29 15:59:23,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-29 15:59:23,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-29 15:59:23,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-29 15:59:23,304 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 29 15:59:23
2021-05-29 15:59:23,310 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-29 15:59:23,310 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 15:59:23,318 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-29 15:59:23,318 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-29 15:59:23,341 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-29 15:59:23,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-29 15:59:23,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-29 15:59:23,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-29 15:59:23,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-29 15:59:23,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-29 15:59:23,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-29 15:59:23,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-29 15:59:23,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-29 15:59:23,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-29 15:59:23,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-29 15:59:23,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-29 15:59:23,380 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-29 15:59:24,219 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-29 15:59:24,219 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 15:59:24,219 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-29 15:59:24,219 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-29 15:59:24,221 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-29 15:59:24,221 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-29 15:59:24,221 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-29 15:59:24,221 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-29 15:59:24,230 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-29 15:59:24,230 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 15:59:24,230 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-29 15:59:24,230 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-29 15:59:24,236 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-29 15:59:24,236 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-29 15:59:24,237 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-29 15:59:24,244 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-29 15:59:24,244 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-29 15:59:24,244 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-29 15:59:24,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-29 15:59:24,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-29 15:59:24,299 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-29 15:59:24,300 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-29 15:59:24,300 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-29 15:59:24,300 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-29 15:59:24,342 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 9060@DESKTOP-TSQQRSN
2021-05-29 15:59:24,545 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-29 15:59:24,962 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000125 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000125-0000000000000000393
2021-05-29 15:59:25,044 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 28 INodes.
2021-05-29 15:59:25,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-29 15:59:25,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 123 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000123
2021-05-29 15:59:25,211 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3bd418e4 expecting start txid #124
2021-05-29 15:59:25,211 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000124-0000000000000000124
2021-05-29 15:59:25,221 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000124-0000000000000000124' to transaction ID 124
2021-05-29 15:59:25,241 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000124-0000000000000000124 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-29 15:59:25,241 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@544820b7 expecting start txid #125
2021-05-29 15:59:25,241 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000125-0000000000000000393
2021-05-29 15:59:25,241 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000125-0000000000000000393' to transaction ID 124
2021-05-29 15:59:25,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000125-0000000000000000393 of size 1048576 edits # 269 loaded in 0 seconds
2021-05-29 15:59:25,361 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-05-29 15:59:25,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-05-29 15:59:25,498 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 123
2021-05-29 15:59:25,499 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2021-05-29 15:59:25,511 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 394
2021-05-29 15:59:25,678 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-29 15:59:25,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1367 msecs
2021-05-29 15:59:26,050 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-29 15:59:26,060 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-29 15:59:26,087 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-29 15:59:26,178 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-29 15:59:26,225 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 15:59:26,225 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-29 15:59:26,226 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 38 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-29 15:59:26,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 15:59:26,291 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-29 15:59:26,291 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-29 15:59:26,295 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-29 15:59:26,295 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-29 15:59:26,309 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-29 15:59:30,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-05-29 15:59:30,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 15:59:30,067 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-05-29 15:59:30,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-29 15:59:30,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-05-29 15:59:30,353 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 37 has reached the threshold 0.9990 of total blocks 38. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-29 15:59:30,354 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-29 15:59:30,356 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 38, hasStaleStorage: false, processing time: 13 msecs
2021-05-29 15:59:30,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 38
2021-05-29 15:59:30,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-29 15:59:30,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-29 15:59:30,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-29 15:59:30,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-29 15:59:30,360 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2021-05-29 15:59:50,566 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 38 has reached the threshold 0.9990 of total blocks 38. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-29 16:00:00,633 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 37 secs
2021-05-29 16:00:00,634 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-29 16:00:00,635 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-29 16:00:00,635 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-05-29 16:00:35,905 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-05-29 16:00:35,905 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-05-29 16:00:35,905 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 394
2021-05-29 16:00:35,906 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 4 
2021-05-29 16:00:35,907 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 5 
2021-05-29 16:00:35,909 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000394 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000394-0000000000000000395
2021-05-29 16:00:35,910 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 396
2021-05-29 16:00:36,949 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 172.41 KB/s
2021-05-29 16:00:36,949 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000395 size 5247 bytes.
2021-05-29 16:00:37,006 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 393
2021-05-29 16:00:37,006 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000123, cpktTxId=0000000000000000123)
2021-05-29 16:05:54,674 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-29 16:05:54,678 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-05-31 19:00:12,731 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-05-31 19:00:12,801 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-05-31 19:00:12,807 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-05-31 19:00:13,270 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-05-31 19:00:13,798 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-05-31 19:00:13,798 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-05-31 19:00:13,801 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-05-31 19:00:13,802 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-05-31 19:00:14,128 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-05-31 19:00:14,247 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-05-31 19:00:14,254 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-05-31 19:00:14,280 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-05-31 19:00:14,286 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-05-31 19:00:14,288 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-05-31 19:00:14,288 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-05-31 19:00:14,288 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-05-31 19:00:14,324 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-05-31 19:00:14,326 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-05-31 19:00:14,455 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-05-31 19:00:14,455 INFO org.mortbay.log: jetty-6.1.26
2021-05-31 19:00:14,929 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-05-31 19:00:15,003 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-31 19:00:15,003 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-05-31 19:00:15,052 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-05-31 19:00:15,052 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-05-31 19:00:15,126 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-05-31 19:00:15,126 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-05-31 19:00:15,127 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-05-31 19:00:15,128 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 May 31 19:00:15
2021-05-31 19:00:15,131 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-05-31 19:00:15,131 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-31 19:00:15,142 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-05-31 19:00:15,142 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-05-31 19:00:15,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-05-31 19:00:15,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-05-31 19:00:15,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-05-31 19:00:15,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-05-31 19:00:15,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-05-31 19:00:15,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-05-31 19:00:15,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-05-31 19:00:15,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-05-31 19:00:15,156 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-05-31 19:00:15,156 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-05-31 19:00:15,156 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-05-31 19:00:15,156 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-05-31 19:00:15,158 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-05-31 19:00:15,651 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-05-31 19:00:15,651 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-31 19:00:15,651 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-05-31 19:00:15,651 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-05-31 19:00:15,652 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-05-31 19:00:15,652 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-05-31 19:00:15,652 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-05-31 19:00:15,652 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-05-31 19:00:15,659 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-05-31 19:00:15,659 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-31 19:00:15,659 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-05-31 19:00:15,659 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-05-31 19:00:15,660 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-05-31 19:00:15,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-05-31 19:00:15,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-05-31 19:00:15,663 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-05-31 19:00:15,664 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-05-31 19:00:15,664 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-05-31 19:00:15,665 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-05-31 19:00:15,665 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-05-31 19:00:15,677 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-05-31 19:00:15,677 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-05-31 19:00:15,677 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-05-31 19:00:15,677 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-05-31 19:00:15,731 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 393@DESKTOP-TSQQRSN
2021-05-31 19:00:15,823 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-05-31 19:00:15,923 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000396 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000396-0000000000000000396
2021-05-31 19:00:15,987 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 66 INodes.
2021-05-31 19:00:16,172 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-05-31 19:00:16,173 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 395 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000395
2021-05-31 19:00:16,173 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2807bdeb expecting start txid #396
2021-05-31 19:00:16,173 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000396-0000000000000000396
2021-05-31 19:00:16,175 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000396-0000000000000000396' to transaction ID 396
2021-05-31 19:00:16,178 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000396-0000000000000000396 of size 1048576 edits # 1 loaded in 0 seconds
2021-05-31 19:00:16,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-05-31 19:00:16,200 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-05-31 19:00:16,326 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 395
2021-05-31 19:00:16,326 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000393, cpktTxId=0000000000000000393)
2021-05-31 19:00:16,388 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 397
2021-05-31 19:00:16,550 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-05-31 19:00:16,551 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 868 msecs
2021-05-31 19:00:16,775 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-05-31 19:00:16,782 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-05-31 19:00:16,825 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-05-31 19:00:16,876 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-05-31 19:00:16,923 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-31 19:00:16,923 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-05-31 19:00:16,924 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 38 blocks to reach the threshold 0.9990 of total blocks 38.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-05-31 19:00:16,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-31 19:00:16,975 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-05-31 19:00:16,976 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-05-31 19:00:16,980 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-05-31 19:00:16,980 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-05-31 19:00:16,984 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-05-31 19:00:30,769 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-05-31 19:00:30,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-31 19:00:30,771 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-05-31 19:00:30,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-05-31 19:00:30,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-05-31 19:00:30,977 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 37 has reached the threshold 0.9990 of total blocks 38. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-05-31 19:00:30,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-05-31 19:00:30,979 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 38, hasStaleStorage: false, processing time: 23 msecs
2021-05-31 19:00:30,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 38
2021-05-31 19:00:30,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-05-31 19:00:30,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-05-31 19:00:30,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-05-31 19:00:30,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-05-31 19:00:30,982 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2021-05-31 19:00:51,192 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 38 has reached the threshold 0.9990 of total blocks 38. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-05-31 19:01:01,294 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 46 secs
2021-05-31 19:01:01,294 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-05-31 19:01:01,294 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-05-31 19:01:01,294 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-05-31 19:02:28,761 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 69 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 20 
2021-05-31 19:02:28,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job.jar
2021-05-31 19:02:29,110 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741877_1053{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job.jar
2021-05-31 19:02:29,110 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-05-31 19:02:29,126 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741877_1053{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 273436
2021-05-31 19:02:29,542 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job.jar is closed by DFSClient_NONMAPREDUCE_404430562_1
2021-05-31 19:02:29,556 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job.jar
2021-05-31 19:02:29,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job.split
2021-05-31 19:02:29,649 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job.split
2021-05-31 19:02:29,660 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741878_1054{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:02:29,661 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job.split is closed by DFSClient_NONMAPREDUCE_404430562_1
2021-05-31 19:02:29,670 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job.splitmetainfo
2021-05-31 19:02:29,678 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741879_1055{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:02:29,680 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_404430562_1
2021-05-31 19:02:29,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job.xml
2021-05-31 19:02:29,997 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741880_1056{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:02:29,999 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job.xml is closed by DFSClient_NONMAPREDUCE_404430562_1
2021-05-31 19:02:37,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job_1622458832718_0001_1_conf.xml
2021-05-31 19:02:37,119 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741881_1057{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:02:37,123 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job_1622458832718_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_375595400_1
2021-05-31 19:02:41,745 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job_1622458832718_0001_1.jhist
2021-05-31 19:02:41,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job_1622458832718_0001_1.jhist for DFSClient_NONMAPREDUCE_375595400_1
2021-05-31 19:02:46,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/grep-temp-127977743/_temporary/1/_temporary/attempt_1622458832718_0001_r_000000_0/part-r-00000
2021-05-31 19:02:46,741 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741883_1059{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:02:46,744 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/grep-temp-127977743/_temporary/1/_temporary/attempt_1622458832718_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622458832718_0001_r_000000_0_1906262704_1
2021-05-31 19:02:46,820 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_375595400_1
2021-05-31 19:02:46,875 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/grep-temp-127977743/_SUCCESS is closed by DFSClient_NONMAPREDUCE_375595400_1
2021-05-31 19:02:46,880 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_375595400_1
2021-05-31 19:02:46,894 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741882_1058{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 13120
2021-05-31 19:02:46,896 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0001/job_1622458832718_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_375595400_1
2021-05-31 19:02:46,901 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0001.summary_tmp
2021-05-31 19:02:46,922 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741884_1060{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:02:46,924 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_375595400_1
2021-05-31 19:02:46,949 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0001-1622458950230-root-grep%2Dsearch-1622458966881-1-1-SUCCEEDED-default-1622458956830.jhist_tmp
2021-05-31 19:02:46,975 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741885_1061{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:02:46,976 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0001-1622458950230-root-grep%2Dsearch-1622458966881-1-1-SUCCEEDED-default-1622458956830.jhist_tmp is closed by DFSClient_NONMAPREDUCE_375595400_1
2021-05-31 19:02:46,990 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0001_conf.xml_tmp
2021-05-31 19:02:47,000 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741886_1062{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:02:47,001 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_375595400_1
2021-05-31 19:02:48,053 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741877_1053 10.191.53.85:50010 
2021-05-31 19:02:48,054 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741878_1054 10.191.53.85:50010 
2021-05-31 19:02:48,054 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741879_1055 10.191.53.85:50010 
2021-05-31 19:02:48,054 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741880_1056 10.191.53.85:50010 
2021-05-31 19:02:48,054 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741882_1058 10.191.53.85:50010 
2021-05-31 19:02:48,054 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741881_1057 10.191.53.85:50010 
2021-05-31 19:02:49,307 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741883_1059 10.191.53.85:50010 
2021-05-31 19:02:50,322 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741877_1053, blk_1073741878_1054, blk_1073741879_1055, blk_1073741880_1056, blk_1073741881_1057, blk_1073741882_1058, blk_1073741883_1059]
2021-05-31 19:02:54,536 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/logs/root/logs/application_1622458832718_0001/DESKTOP-TSQQRSN_55180.tmp
2021-05-31 19:02:54,609 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741887_1063{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:02:54,613 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/logs/root/logs/application_1622458832718_0001/DESKTOP-TSQQRSN_55180.tmp is closed by DFSClient_NONMAPREDUCE_-787079911_105
2021-05-31 19:03:48,218 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 92 Total time for transactions(ms): 91 Number of transactions batched in Syncs: 0 Number of syncs: 66 SyncTimes(ms): 594 
2021-05-31 19:03:48,219 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741884_1060 10.191.53.85:50010 
2021-05-31 19:03:50,438 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741884_1060]
2021-05-31 19:05:23,313 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 97 Total time for transactions(ms): 93 Number of transactions batched in Syncs: 0 Number of syncs: 70 SyncTimes(ms): 596 
2021-05-31 19:05:23,316 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741832_1008 10.191.53.85:50010 
2021-05-31 19:05:23,327 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741825_1001 10.191.53.85:50010 
2021-05-31 19:05:23,743 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741825_1001, blk_1073741832_1008]
2021-05-31 19:05:34,998 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0002/job.jar
2021-05-31 19:05:35,117 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741888_1064{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:05:35,120 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0002/job.jar is closed by DFSClient_NONMAPREDUCE_225455994_1
2021-05-31 19:05:35,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0002/job.jar
2021-05-31 19:05:35,147 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741888_1064 10.191.53.85:50010 
2021-05-31 19:05:35,770 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741888_1064]
2021-05-31 19:07:07,111 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 109 Total time for transactions(ms): 93 Number of transactions batched in Syncs: 1 Number of syncs: 80 SyncTimes(ms): 604 
2021-05-31 19:07:07,205 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/capacity-scheduler.xml._COPYING_
2021-05-31 19:07:07,341 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741889_1065{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:07,349 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/capacity-scheduler.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-926628778_1
2021-05-31 19:07:07,370 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/core-site.xml._COPYING_
2021-05-31 19:07:07,379 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741890_1066{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:07,381 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/core-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-926628778_1
2021-05-31 19:07:07,389 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/hadoop-policy.xml._COPYING_
2021-05-31 19:07:07,397 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741891_1067{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:07,399 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/hadoop-policy.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-926628778_1
2021-05-31 19:07:07,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/hdfs-site.xml._COPYING_
2021-05-31 19:07:07,420 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741892_1068{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:07,421 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/hdfs-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-926628778_1
2021-05-31 19:07:07,437 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/httpfs-site.xml._COPYING_
2021-05-31 19:07:07,450 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741893_1069{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:07,451 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/httpfs-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-926628778_1
2021-05-31 19:07:07,464 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/kms-acls.xml._COPYING_
2021-05-31 19:07:07,475 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741894_1070{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:07,493 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/kms-acls.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-926628778_1
2021-05-31 19:07:07,506 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/kms-site.xml._COPYING_
2021-05-31 19:07:07,521 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741895_1071{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:07,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/kms-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-926628778_1
2021-05-31 19:07:07,538 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/mapred-site.xml._COPYING_
2021-05-31 19:07:07,551 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741896_1072{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:07,553 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/mapred-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-926628778_1
2021-05-31 19:07:07,567 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/yarn-site.xml._COPYING_
2021-05-31 19:07:07,579 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741897_1073{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:07,581 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/yarn-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-926628778_1
2021-05-31 19:07:24,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job.jar
2021-05-31 19:07:24,296 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741898_1074{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:24,300 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job.jar is closed by DFSClient_NONMAPREDUCE_-157872653_1
2021-05-31 19:07:24,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job.jar
2021-05-31 19:07:24,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job.split
2021-05-31 19:07:24,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job.split
2021-05-31 19:07:24,407 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741899_1075{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:24,408 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job.split is closed by DFSClient_NONMAPREDUCE_-157872653_1
2021-05-31 19:07:24,417 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job.splitmetainfo
2021-05-31 19:07:24,430 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741900_1076{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:24,432 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-157872653_1
2021-05-31 19:07:24,527 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job.xml
2021-05-31 19:07:24,543 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741901_1077{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:24,559 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job.xml is closed by DFSClient_NONMAPREDUCE_-157872653_1
2021-05-31 19:07:32,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job_1622458832718_0003_1_conf.xml
2021-05-31 19:07:32,224 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741902_1078{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:32,228 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job_1622458832718_0003_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1664413794_1
2021-05-31 19:07:45,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job_1622458832718_0003_1.jhist
2021-05-31 19:07:45,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job_1622458832718_0003_1.jhist for DFSClient_NONMAPREDUCE_1664413794_1
2021-05-31 19:07:56,379 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/grep-temp-233899763/_temporary/1/_temporary/attempt_1622458832718_0003_r_000000_0/part-r-00000
2021-05-31 19:07:57,096 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741904_1080{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:57,102 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/grep-temp-233899763/_temporary/1/_temporary/attempt_1622458832718_0003_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622458832718_0003_r_000000_0_123207895_1
2021-05-31 19:07:57,250 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1664413794_1
2021-05-31 19:07:57,297 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/grep-temp-233899763/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1664413794_1
2021-05-31 19:07:57,302 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1664413794_1
2021-05-31 19:07:57,330 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741903_1079{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 16974
2021-05-31 19:07:57,331 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0003/job_1622458832718_0003_1.jhist is closed by DFSClient_NONMAPREDUCE_1664413794_1
2021-05-31 19:07:57,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0003.summary_tmp
2021-05-31 19:07:57,349 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741905_1081{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:57,351 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0003.summary_tmp is closed by DFSClient_NONMAPREDUCE_1664413794_1
2021-05-31 19:07:57,379 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0003-1622459244805-root-grep%2Dsearch-1622459277307-9-1-SUCCEEDED-default-1622459251894.jhist_tmp
2021-05-31 19:07:57,391 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741906_1082{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:57,393 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0003-1622459244805-root-grep%2Dsearch-1622459277307-9-1-SUCCEEDED-default-1622459251894.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1664413794_1
2021-05-31 19:07:57,424 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0003_conf.xml_tmp
2021-05-31 19:07:57,444 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741907_1083{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:57,445 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0003_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1664413794_1
2021-05-31 19:07:58,475 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741898_1074 10.191.53.85:50010 
2021-05-31 19:07:58,475 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741899_1075 10.191.53.85:50010 
2021-05-31 19:07:58,475 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741900_1076 10.191.53.85:50010 
2021-05-31 19:07:58,475 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741901_1077 10.191.53.85:50010 
2021-05-31 19:07:58,475 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741903_1079 10.191.53.85:50010 
2021-05-31 19:07:58,475 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741902_1078 10.191.53.85:50010 
2021-05-31 19:07:58,790 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job.jar
2021-05-31 19:07:58,800 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741908_1084{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:58,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job.jar is closed by DFSClient_NONMAPREDUCE_-157872653_1
2021-05-31 19:07:58,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job.jar
2021-05-31 19:07:58,816 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job.split
2021-05-31 19:07:58,818 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job.split
2021-05-31 19:07:58,826 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741909_1085{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:58,827 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job.split is closed by DFSClient_NONMAPREDUCE_-157872653_1
2021-05-31 19:07:58,832 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job.splitmetainfo
2021-05-31 19:07:58,843 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741910_1086{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:58,846 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-157872653_1
2021-05-31 19:07:58,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job.xml
2021-05-31 19:07:58,876 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741911_1087{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:07:58,877 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job.xml is closed by DFSClient_NONMAPREDUCE_-157872653_1
2021-05-31 19:08:00,239 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741898_1074, blk_1073741899_1075, blk_1073741900_1076, blk_1073741901_1077, blk_1073741902_1078, blk_1073741903_1079]
2021-05-31 19:08:04,384 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/logs/root/logs/application_1622458832718_0003/DESKTOP-TSQQRSN_55180.tmp
2021-05-31 19:08:04,400 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741912_1088{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:08:04,402 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/logs/root/logs/application_1622458832718_0003/DESKTOP-TSQQRSN_55180.tmp is closed by DFSClient_NONMAPREDUCE_-944223701_161
2021-05-31 19:08:11,016 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 282 Total time for transactions(ms): 105 Number of transactions batched in Syncs: 1 Number of syncs: 201 SyncTimes(ms): 1390 
2021-05-31 19:08:11,235 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job_1622458832718_0004_1_conf.xml
2021-05-31 19:08:11,328 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741913_1089{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:08:11,332 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job_1622458832718_0004_1_conf.xml is closed by DFSClient_NONMAPREDUCE_898503872_1
2021-05-31 19:08:15,820 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job_1622458832718_0004_1.jhist
2021-05-31 19:08:15,833 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job_1622458832718_0004_1.jhist for DFSClient_NONMAPREDUCE_898503872_1
2021-05-31 19:08:20,617 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/output/_temporary/1/_temporary/attempt_1622458832718_0004_r_000000_0/part-r-00000
2021-05-31 19:08:20,734 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741915_1091{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:08:20,736 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_temporary/1/_temporary/attempt_1622458832718_0004_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622458832718_0004_r_000000_0_-1368497864_1
2021-05-31 19:08:20,828 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_898503872_1
2021-05-31 19:08:20,919 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_898503872_1
2021-05-31 19:08:20,924 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_898503872_1
2021-05-31 19:08:20,944 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741914_1090{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 13038
2021-05-31 19:08:20,952 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0004/job_1622458832718_0004_1.jhist is closed by DFSClient_NONMAPREDUCE_898503872_1
2021-05-31 19:08:20,957 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0004.summary_tmp
2021-05-31 19:08:20,965 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741916_1092{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:08:20,966 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0004.summary_tmp is closed by DFSClient_NONMAPREDUCE_898503872_1
2021-05-31 19:08:20,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0004-1622459278895-root-grep%2Dsort-1622459300926-1-1-SUCCEEDED-default-1622459290996.jhist_tmp
2021-05-31 19:08:20,995 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741917_1093{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:08:20,996 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0004-1622459278895-root-grep%2Dsort-1622459300926-1-1-SUCCEEDED-default-1622459290996.jhist_tmp is closed by DFSClient_NONMAPREDUCE_898503872_1
2021-05-31 19:08:21,006 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0004_conf.xml_tmp
2021-05-31 19:08:21,017 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741918_1094{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:08:21,018 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0004_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_898503872_1
2021-05-31 19:08:22,049 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741908_1084 10.191.53.85:50010 
2021-05-31 19:08:22,049 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741909_1085 10.191.53.85:50010 
2021-05-31 19:08:22,049 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741910_1086 10.191.53.85:50010 
2021-05-31 19:08:22,049 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741911_1087 10.191.53.85:50010 
2021-05-31 19:08:22,049 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741914_1090 10.191.53.85:50010 
2021-05-31 19:08:22,049 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741913_1089 10.191.53.85:50010 
2021-05-31 19:08:22,596 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741904_1080 10.191.53.85:50010 
2021-05-31 19:08:24,312 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741904_1080, blk_1073741908_1084, blk_1073741909_1085, blk_1073741910_1086, blk_1073741911_1087, blk_1073741913_1089, blk_1073741914_1090]
2021-05-31 19:08:27,915 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/logs/root/logs/application_1622458832718_0004/DESKTOP-TSQQRSN_55180.tmp
2021-05-31 19:08:27,927 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741919_1095{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:08:27,929 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/logs/root/logs/application_1622458832718_0004/DESKTOP-TSQQRSN_55180.tmp is closed by DFSClient_NONMAPREDUCE_44581544_264
2021-05-31 19:09:48,131 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 341 Total time for transactions(ms): 109 Number of transactions batched in Syncs: 1 Number of syncs: 242 SyncTimes(ms): 1542 
2021-05-31 19:09:48,132 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741916_1092 10.191.53.85:50010 
2021-05-31 19:09:48,133 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741905_1081 10.191.53.85:50010 
2021-05-31 19:09:48,499 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741905_1081, blk_1073741916_1092]
2021-05-31 19:10:27,222 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2021-05-31 19:10:27,224 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-05-31 19:10:27,225 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-05-31 19:10:27,225 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-05-31 19:10:27,225 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2021-05-31 19:10:27,225 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 1
2021-05-31 19:10:27,225 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2021-05-31 19:10:27,225 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2021-05-31 19:13:26,450 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 348 Total time for transactions(ms): 109 Number of transactions batched in Syncs: 1 Number of syncs: 248 SyncTimes(ms): 1546 
2021-05-31 19:13:26,522 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/wcinput/wc.input._COPYING_
2021-05-31 19:13:26,633 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741920_1096{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:13:26,636 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/wcinput/wc.input._COPYING_ is closed by DFSClient_NONMAPREDUCE_2030016880_1
2021-05-31 19:15:20,478 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 355 Total time for transactions(ms): 109 Number of transactions batched in Syncs: 1 Number of syncs: 253 SyncTimes(ms): 1551 
2021-05-31 19:15:20,545 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job.jar
2021-05-31 19:15:20,662 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741921_1097{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:15:20,666 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job.jar is closed by DFSClient_NONMAPREDUCE_643965434_1
2021-05-31 19:15:20,670 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job.jar
2021-05-31 19:15:20,716 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job.split
2021-05-31 19:15:20,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job.split
2021-05-31 19:15:20,739 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741922_1098{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:15:20,742 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job.split is closed by DFSClient_NONMAPREDUCE_643965434_1
2021-05-31 19:15:20,751 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job.splitmetainfo
2021-05-31 19:15:20,759 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741923_1099{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:15:20,774 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_643965434_1
2021-05-31 19:15:20,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job.xml
2021-05-31 19:15:20,865 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741924_1100{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:15:20,866 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job.xml is closed by DFSClient_NONMAPREDUCE_643965434_1
2021-05-31 19:15:27,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job_1622458832718_0005_1_conf.xml
2021-05-31 19:15:27,210 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741925_1101{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:15:27,215 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job_1622458832718_0005_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1628696393_1
2021-05-31 19:15:31,634 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job_1622458832718_0005_1.jhist
2021-05-31 19:15:31,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job_1622458832718_0005_1.jhist for DFSClient_NONMAPREDUCE_-1628696393_1
2021-05-31 19:15:36,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/wcoutput/_temporary/1/_temporary/attempt_1622458832718_0005_r_000000_0/part-r-00000
2021-05-31 19:15:36,996 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741927_1103{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:15:37,000 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/wcoutput/_temporary/1/_temporary/attempt_1622458832718_0005_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622458832718_0005_r_000000_0_1785779676_1
2021-05-31 19:15:37,049 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1628696393_1
2021-05-31 19:15:37,076 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/wcoutput/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1628696393_1
2021-05-31 19:15:37,081 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1628696393_1
2021-05-31 19:15:37,097 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741926_1102{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 13122
2021-05-31 19:15:37,099 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0005/job_1622458832718_0005_1.jhist is closed by DFSClient_NONMAPREDUCE_-1628696393_1
2021-05-31 19:15:37,104 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0005.summary_tmp
2021-05-31 19:15:37,112 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741928_1104{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:15:37,113 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0005.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1628696393_1
2021-05-31 19:15:37,132 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0005-1622459721041-root-word+count-1622459737082-1-1-SUCCEEDED-default-1622459726915.jhist_tmp
2021-05-31 19:15:37,140 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741929_1105{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:15:37,141 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0005-1622459721041-root-word+count-1622459737082-1-1-SUCCEEDED-default-1622459726915.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1628696393_1
2021-05-31 19:15:37,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1106{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0005_conf.xml_tmp
2021-05-31 19:15:37,161 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741930_1106{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:15:37,162 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0005_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1628696393_1
2021-05-31 19:15:38,185 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741921_1097 10.191.53.85:50010 
2021-05-31 19:15:38,186 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741922_1098 10.191.53.85:50010 
2021-05-31 19:15:38,186 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741923_1099 10.191.53.85:50010 
2021-05-31 19:15:38,186 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741924_1100 10.191.53.85:50010 
2021-05-31 19:15:38,186 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741926_1102 10.191.53.85:50010 
2021-05-31 19:15:38,186 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741925_1101 10.191.53.85:50010 
2021-05-31 19:15:40,263 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741921_1097, blk_1073741922_1098, blk_1073741923_1099, blk_1073741924_1100, blk_1073741925_1101, blk_1073741926_1102]
2021-05-31 19:15:44,175 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1107{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/logs/root/logs/application_1622458832718_0005/DESKTOP-TSQQRSN_55180.tmp
2021-05-31 19:15:44,184 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741931_1107{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:15:44,187 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/logs/root/logs/application_1622458832718_0005/DESKTOP-TSQQRSN_55180.tmp is closed by DFSClient_NONMAPREDUCE_-1999028167_312
2021-05-31 19:15:48,158 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741928_1104 10.191.53.85:50010 
2021-05-31 19:15:49,274 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741928_1104]
2021-05-31 19:24:28,836 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-05-31 19:24:28,836 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 0
2021-05-31 19:24:28,836 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2021-05-31 19:24:28,836 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-05-31 19:24:28,836 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2021-05-31 19:24:28,836 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2021-05-31 19:24:28,836 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2021-05-31 19:24:28,836 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2021-05-31 19:24:28,836 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2021-05-31 19:24:28,836 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-05-31 19:24:28,836 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2021-05-31 19:24:28,837 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-05-31 19:24:28,837 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 0
2021-05-31 19:24:28,837 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2021-05-31 19:24:28,837 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-05-31 19:24:28,837 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-05-31 19:24:28,838 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2021-05-31 19:24:28,838 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-05-31 19:24:28,839 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2021-05-31 19:24:28,839 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2021-05-31 19:24:28,839 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-05-31 19:24:28,839 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2021-05-31 19:24:28,839 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-05-31 19:24:28,840 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 1
2021-05-31 19:24:28,840 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-05-31 19:24:28,840 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2021-05-31 19:24:28,840 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2021-05-31 19:24:28,840 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-05-31 19:24:28,840 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2021-05-31 19:24:28,840 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2021-05-31 19:24:28,840 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 1
2021-05-31 19:24:28,840 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2021-05-31 19:24:28,840 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 2
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-05-31 19:25:16,437 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename (options=[NONE]) is: 1
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 1
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2021-05-31 19:25:16,438 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 2
2021-05-31 19:27:55,692 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 446 Total time for transactions(ms): 112 Number of transactions batched in Syncs: 1 Number of syncs: 318 SyncTimes(ms): 1595 
2021-05-31 19:27:55,693 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741889_1065 10.191.53.85:50010 
2021-05-31 19:27:55,693 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741890_1066 10.191.53.85:50010 
2021-05-31 19:27:55,694 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741891_1067 10.191.53.85:50010 
2021-05-31 19:27:55,694 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741892_1068 10.191.53.85:50010 
2021-05-31 19:27:55,694 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741893_1069 10.191.53.85:50010 
2021-05-31 19:27:55,694 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741894_1070 10.191.53.85:50010 
2021-05-31 19:27:55,694 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741895_1071 10.191.53.85:50010 
2021-05-31 19:27:55,694 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741896_1072 10.191.53.85:50010 
2021-05-31 19:27:55,694 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741897_1073 10.191.53.85:50010 
2021-05-31 19:27:55,700 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741915_1091 10.191.53.85:50010 
2021-05-31 19:27:56,490 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741889_1065, blk_1073741890_1066, blk_1073741891_1067, blk_1073741892_1068, blk_1073741893_1069, blk_1073741894_1070, blk_1073741895_1071, blk_1073741896_1072, blk_1073741897_1073, blk_1073741915_1091]
2021-05-31 19:28:44,380 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1108{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/capacity-scheduler.xml._COPYING_
2021-05-31 19:28:44,596 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741932_1108{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:28:44,600 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/capacity-scheduler.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-249603971_1
2021-05-31 19:28:44,621 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1109{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/core-site.xml._COPYING_
2021-05-31 19:28:44,629 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741933_1109{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:28:44,631 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/core-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-249603971_1
2021-05-31 19:28:44,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1110{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/hadoop-policy.xml._COPYING_
2021-05-31 19:28:44,657 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741934_1110{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:28:44,669 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/hadoop-policy.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-249603971_1
2021-05-31 19:28:44,681 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1111{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/hdfs-site.xml._COPYING_
2021-05-31 19:28:44,688 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741935_1111{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:28:44,690 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/hdfs-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-249603971_1
2021-05-31 19:28:44,698 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1112{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/httpfs-site.xml._COPYING_
2021-05-31 19:28:44,705 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741936_1112{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:28:44,707 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/httpfs-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-249603971_1
2021-05-31 19:28:44,715 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1113{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/kms-acls.xml._COPYING_
2021-05-31 19:28:44,722 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741937_1113{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:28:44,724 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/kms-acls.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-249603971_1
2021-05-31 19:28:44,732 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1114{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/kms-site.xml._COPYING_
2021-05-31 19:28:44,739 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741938_1114{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:28:44,740 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/kms-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-249603971_1
2021-05-31 19:28:44,748 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1115{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/mapred-site.xml._COPYING_
2021-05-31 19:28:44,756 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741939_1115{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:28:44,757 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/mapred-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-249603971_1
2021-05-31 19:28:44,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1116{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/input/yarn-site.xml._COPYING_
2021-05-31 19:28:44,773 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741940_1116{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:28:44,774 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/input/yarn-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-249603971_1
2021-05-31 19:29:51,514 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 503 Total time for transactions(ms): 116 Number of transactions batched in Syncs: 1 Number of syncs: 357 SyncTimes(ms): 1717 
2021-05-31 19:29:51,589 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1117{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job.jar
2021-05-31 19:29:51,704 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741941_1117{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:29:51,708 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job.jar is closed by DFSClient_NONMAPREDUCE_1446240431_1
2021-05-31 19:29:51,713 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job.jar
2021-05-31 19:29:51,771 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job.split
2021-05-31 19:29:51,780 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1118{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job.split
2021-05-31 19:29:51,793 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741942_1118{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:29:51,795 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job.split is closed by DFSClient_NONMAPREDUCE_1446240431_1
2021-05-31 19:29:51,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1119{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job.splitmetainfo
2021-05-31 19:29:51,814 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741943_1119{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:29:51,815 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1446240431_1
2021-05-31 19:29:51,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1120{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job.xml
2021-05-31 19:29:51,901 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741944_1120{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:29:51,903 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job.xml is closed by DFSClient_NONMAPREDUCE_1446240431_1
2021-05-31 19:29:57,652 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1121{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job_1622458832718_0006_1_conf.xml
2021-05-31 19:29:57,745 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741945_1121{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:29:57,749 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job_1622458832718_0006_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1481771991_1
2021-05-31 19:30:07,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1122{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job_1622458832718_0006_1.jhist
2021-05-31 19:30:07,610 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job_1622458832718_0006_1.jhist for DFSClient_NONMAPREDUCE_-1481771991_1
2021-05-31 19:30:16,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1123{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/grep-temp-2066434207/_temporary/1/_temporary/attempt_1622458832718_0006_r_000000_0/part-r-00000
2021-05-31 19:30:16,673 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741947_1123{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:16,677 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/grep-temp-2066434207/_temporary/1/_temporary/attempt_1622458832718_0006_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622458832718_0006_r_000000_0_1194131175_1
2021-05-31 19:30:16,737 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1481771991_1
2021-05-31 19:30:17,266 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/grep-temp-2066434207/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1481771991_1
2021-05-31 19:30:17,272 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1481771991_1
2021-05-31 19:30:17,295 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741946_1122{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 16977
2021-05-31 19:30:17,328 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0006/job_1622458832718_0006_1.jhist is closed by DFSClient_NONMAPREDUCE_-1481771991_1
2021-05-31 19:30:17,333 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1124{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0006.summary_tmp
2021-05-31 19:30:17,341 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741948_1124{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:17,342 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0006.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1481771991_1
2021-05-31 19:30:17,367 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1125{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0006-1622460592066-root-grep%2Dsearch-1622460617276-9-1-SUCCEEDED-default-1622460597507.jhist_tmp
2021-05-31 19:30:17,376 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741949_1125{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:17,377 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0006-1622460592066-root-grep%2Dsearch-1622460617276-9-1-SUCCEEDED-default-1622460597507.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1481771991_1
2021-05-31 19:30:17,402 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1126{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0006_conf.xml_tmp
2021-05-31 19:30:17,417 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741950_1126{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:17,419 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0006_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1481771991_1
2021-05-31 19:30:18,457 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741941_1117 10.191.53.85:50010 
2021-05-31 19:30:18,457 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741942_1118 10.191.53.85:50010 
2021-05-31 19:30:18,457 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741943_1119 10.191.53.85:50010 
2021-05-31 19:30:18,457 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741944_1120 10.191.53.85:50010 
2021-05-31 19:30:18,458 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741946_1122 10.191.53.85:50010 
2021-05-31 19:30:18,458 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741945_1121 10.191.53.85:50010 
2021-05-31 19:30:19,512 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1127{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job.jar
2021-05-31 19:30:19,528 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741951_1127{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:19,530 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job.jar is closed by DFSClient_NONMAPREDUCE_1446240431_1
2021-05-31 19:30:19,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job.jar
2021-05-31 19:30:19,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job.split
2021-05-31 19:30:19,551 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1128{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job.split
2021-05-31 19:30:19,565 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741952_1128{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:19,566 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job.split is closed by DFSClient_NONMAPREDUCE_1446240431_1
2021-05-31 19:30:19,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1129{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job.splitmetainfo
2021-05-31 19:30:19,587 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741953_1129{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:19,588 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1446240431_1
2021-05-31 19:30:19,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1130{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job.xml
2021-05-31 19:30:19,635 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741954_1130{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:19,637 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job.xml is closed by DFSClient_NONMAPREDUCE_1446240431_1
2021-05-31 19:30:20,697 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741941_1117, blk_1073741942_1118, blk_1073741943_1119, blk_1073741944_1120, blk_1073741945_1121, blk_1073741946_1122]
2021-05-31 19:30:23,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1131{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/logs/root/logs/application_1622458832718_0006/DESKTOP-TSQQRSN_55180.tmp
2021-05-31 19:30:23,903 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741955_1131{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:23,904 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/logs/root/logs/application_1622458832718_0006/DESKTOP-TSQQRSN_55180.tmp is closed by DFSClient_NONMAPREDUCE_-1088867715_364
2021-05-31 19:30:29,134 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1132{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job_1622458832718_0007_1_conf.xml
2021-05-31 19:30:29,220 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741956_1132{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:29,223 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job_1622458832718_0007_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-2049630402_1
2021-05-31 19:30:33,601 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1133{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job_1622458832718_0007_1.jhist
2021-05-31 19:30:33,611 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job_1622458832718_0007_1.jhist for DFSClient_NONMAPREDUCE_-2049630402_1
2021-05-31 19:30:38,831 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1134{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/output/_temporary/1/_temporary/attempt_1622458832718_0007_r_000000_0/part-r-00000
2021-05-31 19:30:38,949 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741958_1134{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:38,952 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_temporary/1/_temporary/attempt_1622458832718_0007_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622458832718_0007_r_000000_0_1858213551_1
2021-05-31 19:30:39,003 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-2049630402_1
2021-05-31 19:30:39,029 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-2049630402_1
2021-05-31 19:30:39,034 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-2049630402_1
2021-05-31 19:30:39,054 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741957_1133{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 13034
2021-05-31 19:30:39,055 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0007/job_1622458832718_0007_1.jhist is closed by DFSClient_NONMAPREDUCE_-2049630402_1
2021-05-31 19:30:39,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1135{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0007.summary_tmp
2021-05-31 19:30:39,068 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741959_1135{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:39,070 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0007.summary_tmp is closed by DFSClient_NONMAPREDUCE_-2049630402_1
2021-05-31 19:30:39,106 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1136{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0007-1622460619652-root-grep%2Dsort-1622460639036-1-1-SUCCEEDED-default-1622460628987.jhist_tmp
2021-05-31 19:30:39,114 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741960_1136{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:39,115 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0007-1622460619652-root-grep%2Dsort-1622460639036-1-1-SUCCEEDED-default-1622460628987.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-2049630402_1
2021-05-31 19:30:39,125 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1137{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0007_conf.xml_tmp
2021-05-31 19:30:39,135 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741961_1137{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:39,137 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0007_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-2049630402_1
2021-05-31 19:30:40,167 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741951_1127 10.191.53.85:50010 
2021-05-31 19:30:40,168 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741952_1128 10.191.53.85:50010 
2021-05-31 19:30:40,168 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741953_1129 10.191.53.85:50010 
2021-05-31 19:30:40,168 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741954_1130 10.191.53.85:50010 
2021-05-31 19:30:40,169 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741957_1133 10.191.53.85:50010 
2021-05-31 19:30:40,169 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741956_1132 10.191.53.85:50010 
2021-05-31 19:30:41,223 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741947_1123 10.191.53.85:50010 
2021-05-31 19:30:41,744 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741952_1128, blk_1073741953_1129, blk_1073741954_1130, blk_1073741956_1132, blk_1073741957_1133, blk_1073741947_1123, blk_1073741951_1127]
2021-05-31 19:30:46,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1138{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/logs/root/logs/application_1622458832718_0007/DESKTOP-TSQQRSN_55180.tmp
2021-05-31 19:30:46,156 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741962_1138{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:30:46,158 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/logs/root/logs/application_1622458832718_0007/DESKTOP-TSQQRSN_55180.tmp is closed by DFSClient_NONMAPREDUCE_-1572411227_468
2021-05-31 19:30:48,122 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741948_1124 10.191.53.85:50010 
2021-05-31 19:30:48,122 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741959_1135 10.191.53.85:50010 
2021-05-31 19:30:50,757 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741959_1135, blk_1073741948_1124]
2021-05-31 19:32:40,018 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 686 Total time for transactions(ms): 122 Number of transactions batched in Syncs: 1 Number of syncs: 488 SyncTimes(ms): 2067 
2021-05-31 19:32:40,019 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741927_1103 10.191.53.85:50010 
2021-05-31 19:32:41,928 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741927_1103]
2021-05-31 19:33:04,985 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741920_1096 10.191.53.85:50010 
2021-05-31 19:33:05,958 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741920_1096]
2021-05-31 19:33:40,866 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 688 Total time for transactions(ms): 122 Number of transactions batched in Syncs: 1 Number of syncs: 490 SyncTimes(ms): 2093 
2021-05-31 19:33:40,928 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741963_1139{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/wcinput/wc.input._COPYING_
2021-05-31 19:33:41,044 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741963_1139{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:33:41,047 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/wcinput/wc.input._COPYING_ is closed by DFSClient_NONMAPREDUCE_917289971_1
2021-05-31 19:34:02,757 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741964_1140{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job.jar
2021-05-31 19:34:02,875 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741964_1140{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:34:02,879 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job.jar is closed by DFSClient_NONMAPREDUCE_1949910088_1
2021-05-31 19:34:02,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job.jar
2021-05-31 19:34:02,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job.split
2021-05-31 19:34:02,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741965_1141{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job.split
2021-05-31 19:34:02,966 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741965_1141{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:34:02,968 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job.split is closed by DFSClient_NONMAPREDUCE_1949910088_1
2021-05-31 19:34:02,975 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741966_1142{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job.splitmetainfo
2021-05-31 19:34:02,983 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741966_1142{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:34:02,985 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1949910088_1
2021-05-31 19:34:03,065 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741967_1143{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job.xml
2021-05-31 19:34:03,074 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741967_1143{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:34:03,076 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job.xml is closed by DFSClient_NONMAPREDUCE_1949910088_1
2021-05-31 19:34:08,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741968_1144{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job_1622458832718_0008_1_conf.xml
2021-05-31 19:34:08,614 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741968_1144{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:34:08,618 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job_1622458832718_0008_1_conf.xml is closed by DFSClient_NONMAPREDUCE_735513374_1
2021-05-31 19:34:13,019 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741969_1145{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job_1622458832718_0008_1.jhist
2021-05-31 19:34:13,029 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job_1622458832718_0008_1.jhist for DFSClient_NONMAPREDUCE_735513374_1
2021-05-31 19:34:17,890 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741970_1146{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/wcoutput/_temporary/1/_temporary/attempt_1622458832718_0008_r_000000_0/part-r-00000
2021-05-31 19:34:18,013 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741970_1146{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:34:18,239 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/wcoutput/_temporary/1/_temporary/attempt_1622458832718_0008_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1622458832718_0008_r_000000_0_-1262499070_1
2021-05-31 19:34:18,296 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_735513374_1
2021-05-31 19:34:18,324 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/wcoutput/_SUCCESS is closed by DFSClient_NONMAPREDUCE_735513374_1
2021-05-31 19:34:18,328 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_735513374_1
2021-05-31 19:34:18,346 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741969_1145{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 13118
2021-05-31 19:34:18,348 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1622458832718_0008/job_1622458832718_0008_1.jhist is closed by DFSClient_NONMAPREDUCE_735513374_1
2021-05-31 19:34:18,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741971_1147{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0008.summary_tmp
2021-05-31 19:34:18,361 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741971_1147{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:34:18,362 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0008.summary_tmp is closed by DFSClient_NONMAPREDUCE_735513374_1
2021-05-31 19:34:18,383 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741972_1148{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0008-1622460843229-root-word+count-1622460858329-1-1-SUCCEEDED-default-1622460848372.jhist_tmp
2021-05-31 19:34:18,390 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741972_1148{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:34:18,392 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0008-1622460843229-root-word+count-1622460858329-1-1-SUCCEEDED-default-1622460848372.jhist_tmp is closed by DFSClient_NONMAPREDUCE_735513374_1
2021-05-31 19:34:18,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741973_1149{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0008_conf.xml_tmp
2021-05-31 19:34:18,413 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741973_1149{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:34:18,414 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1622458832718_0008_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_735513374_1
2021-05-31 19:34:19,444 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741964_1140 10.191.53.85:50010 
2021-05-31 19:34:19,444 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741965_1141 10.191.53.85:50010 
2021-05-31 19:34:19,444 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741966_1142 10.191.53.85:50010 
2021-05-31 19:34:19,444 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741967_1143 10.191.53.85:50010 
2021-05-31 19:34:19,444 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741969_1145 10.191.53.85:50010 
2021-05-31 19:34:19,444 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741968_1144 10.191.53.85:50010 
2021-05-31 19:34:21,074 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741968_1144, blk_1073741969_1145, blk_1073741964_1140, blk_1073741965_1141, blk_1073741966_1142, blk_1073741967_1143]
2021-05-31 19:34:25,430 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741974_1150{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/logs/root/logs/application_1622458832718_0008/DESKTOP-TSQQRSN_55180.tmp
2021-05-31 19:34:25,440 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741974_1150{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-05-31 19:34:25,441 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/logs/root/logs/application_1622458832718_0008/DESKTOP-TSQQRSN_55180.tmp is closed by DFSClient_NONMAPREDUCE_1232899637_517
2021-05-31 19:34:31,603 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741971_1147 10.191.53.85:50010 
2021-05-31 19:34:33,088 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741971_1147]
2021-05-31 19:42:32,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-05-31 19:42:32,101 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-05-31 19:42:32,101 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 397
2021-05-31 19:42:32,101 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 786 Total time for transactions(ms): 125 Number of transactions batched in Syncs: 1 Number of syncs: 560 SyncTimes(ms): 2368 
2021-05-31 19:42:32,102 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 786 Total time for transactions(ms): 125 Number of transactions batched in Syncs: 1 Number of syncs: 561 SyncTimes(ms): 2368 
2021-05-31 19:42:32,104 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000000397 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000000397-0000000000000001182
2021-05-31 19:42:32,105 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1183
2021-05-31 19:42:33,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 321.43 KB/s
2021-05-31 19:42:33,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001182 size 9345 bytes.
2021-05-31 19:42:33,602 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 396
2021-05-31 19:42:33,602 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000395, cpktTxId=0000000000000000395)
2021-05-31 19:43:08,688 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-05-31 19:43:08,691 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-13 23:51:02,043 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-13 23:51:02,122 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-13 23:51:02,137 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-13 23:51:02,955 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-13 23:51:03,552 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-13 23:51:03,553 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-13 23:51:03,556 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-06-13 23:51:03,557 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-06-13 23:51:03,984 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-06-13 23:51:04,165 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-13 23:51:04,178 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-13 23:51:04,233 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-13 23:51:04,244 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-13 23:51:04,249 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-13 23:51:04,249 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-13 23:51:04,249 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-13 23:51:04,652 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-13 23:51:04,655 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-13 23:51:04,716 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-06-13 23:51:04,717 INFO org.mortbay.log: jetty-6.1.26
2021-06-13 23:51:05,225 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-06-13 23:51:05,566 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-13 23:51:05,566 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-13 23:51:05,698 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-06-13 23:51:05,698 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-06-13 23:51:05,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-06-13 23:51:05,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-13 23:51:05,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-13 23:51:05,938 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 13 23:51:05
2021-06-13 23:51:05,948 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-13 23:51:05,949 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-13 23:51:05,978 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-06-13 23:51:05,978 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-13 23:51:06,000 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-06-13 23:51:06,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-13 23:51:06,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-13 23:51:06,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-13 23:51:06,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-13 23:51:06,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-06-13 23:51:06,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-13 23:51:06,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-13 23:51:06,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-06-13 23:51:06,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-13 23:51:06,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-13 23:51:06,032 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-13 23:51:06,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-06-13 23:51:07,031 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-13 23:51:07,031 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-13 23:51:07,031 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-06-13 23:51:07,031 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-13 23:51:07,033 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-13 23:51:07,034 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-13 23:51:07,034 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-06-13 23:51:07,035 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-06-13 23:51:07,054 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-13 23:51:07,054 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-13 23:51:07,054 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-06-13 23:51:07,054 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-13 23:51:07,058 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-13 23:51:07,058 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-06-13 23:51:07,058 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-06-13 23:51:07,067 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-13 23:51:07,067 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-13 23:51:07,067 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-13 23:51:07,070 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-13 23:51:07,070 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-13 23:51:07,078 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-13 23:51:07,078 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-13 23:51:07,078 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-06-13 23:51:07,078 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-13 23:51:07,156 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 511@DESKTOP-TSQQRSN
2021-06-13 23:51:07,295 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-06-13 23:51:07,426 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001183 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001183-0000000000000001183
2021-06-13 23:51:07,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 109 INodes.
2021-06-13 23:51:07,899 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-13 23:51:07,900 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1182 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001182
2021-06-13 23:51:07,900 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2807bdeb expecting start txid #1183
2021-06-13 23:51:07,900 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001183-0000000000000001183
2021-06-13 23:51:07,905 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001183-0000000000000001183' to transaction ID 1183
2021-06-13 23:51:07,915 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001183-0000000000000001183 of size 1048576 edits # 1 loaded in 0 seconds
2021-06-13 23:51:07,933 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-06-13 23:51:07,933 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-06-13 23:51:08,477 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1182
2021-06-13 23:51:08,478 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000000396, cpktTxId=0000000000000000396)
2021-06-13 23:51:08,543 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1184
2021-06-13 23:51:08,729 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-13 23:51:08,729 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1645 msecs
2021-06-13 23:51:09,396 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-06-13 23:51:09,414 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-13 23:51:09,443 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-13 23:51:09,536 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-06-13 23:51:09,636 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-13 23:51:09,636 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-13 23:51:09,636 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 69 blocks to reach the threshold 0.9990 of total blocks 69.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-06-13 23:51:09,660 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-13 23:51:09,753 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-13 23:51:09,754 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-13 23:51:09,766 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-13 23:51:09,766 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-13 23:51:09,783 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-13 23:51:14,797 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-13 23:51:14,797 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-13 23:51:14,798 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-06-13 23:51:15,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-13 23:51:15,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-06-13 23:51:15,194 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 68 has reached the threshold 0.9990 of total blocks 69. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-06-13 23:51:15,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-06-13 23:51:15,197 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 69, hasStaleStorage: false, processing time: 21 msecs
2021-06-13 23:51:15,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 69
2021-06-13 23:51:15,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-13 23:51:15,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-13 23:51:15,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-13 23:51:15,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-13 23:51:15,201 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2021-06-13 23:51:35,402 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 69 has reached the threshold 0.9990 of total blocks 69. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-06-13 23:51:45,501 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 39 secs
2021-06-13 23:51:45,501 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-06-13 23:51:45,502 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-06-13 23:51:45,502 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-13 23:51:48,946 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741836_1012 10.191.53.85:50010 
2021-06-13 23:51:48,961 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741876_1052 10.191.53.85:50010 
2021-06-13 23:51:48,968 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741887_1063 10.191.53.85:50010 
2021-06-13 23:51:48,977 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741912_1088 10.191.53.85:50010 
2021-06-13 23:51:48,984 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741919_1095 10.191.53.85:50010 
2021-06-13 23:51:48,992 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741931_1107 10.191.53.85:50010 
2021-06-13 23:51:49,000 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741955_1131 10.191.53.85:50010 
2021-06-13 23:51:49,008 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741962_1138 10.191.53.85:50010 
2021-06-13 23:51:49,014 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741974_1150 10.191.53.85:50010 
2021-06-13 23:51:51,534 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-13 23:51:51,538 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-14 18:57:52,839 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-14 18:57:52,940 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-14 18:57:52,950 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-14 18:57:53,441 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-14 18:57:53,779 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-14 18:57:53,779 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-14 18:57:53,782 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-06-14 18:57:53,783 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-06-14 18:57:54,109 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-06-14 18:57:54,211 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-14 18:57:54,222 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-14 18:57:54,260 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-14 18:57:54,268 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-14 18:57:54,272 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-14 18:57:54,272 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-14 18:57:54,272 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-14 18:57:54,330 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-14 18:57:54,332 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-14 18:57:54,434 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-06-14 18:57:54,435 INFO org.mortbay.log: jetty-6.1.26
2021-06-14 18:57:54,963 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-06-14 18:57:55,072 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-14 18:57:55,073 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-14 18:57:55,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-06-14 18:57:55,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-06-14 18:57:55,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-06-14 18:57:55,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-14 18:57:55,251 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-14 18:57:55,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 14 18:57:55
2021-06-14 18:57:55,256 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-14 18:57:55,256 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-14 18:57:55,293 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-06-14 18:57:55,293 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-14 18:57:55,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-06-14 18:57:55,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-14 18:57:55,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-14 18:57:55,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-14 18:57:55,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-14 18:57:55,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-06-14 18:57:55,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-14 18:57:55,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-14 18:57:55,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-06-14 18:57:55,312 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-14 18:57:55,312 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-14 18:57:55,312 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-14 18:57:55,316 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-06-14 18:57:55,870 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-14 18:57:55,870 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-14 18:57:55,870 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-06-14 18:57:55,870 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-14 18:57:55,871 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-14 18:57:55,871 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-14 18:57:55,871 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-06-14 18:57:55,872 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-06-14 18:57:55,882 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-14 18:57:55,882 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-14 18:57:55,882 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-06-14 18:57:55,882 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-14 18:57:55,884 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-14 18:57:55,884 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-06-14 18:57:55,884 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-06-14 18:57:55,889 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-14 18:57:55,889 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-14 18:57:55,889 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-14 18:57:55,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-14 18:57:55,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-14 18:57:55,896 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-14 18:57:55,897 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-14 18:57:55,897 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-06-14 18:57:55,897 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-14 18:57:55,980 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 348@DESKTOP-TSQQRSN
2021-06-14 18:57:56,064 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-06-14 18:57:56,249 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001184 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001184-0000000000000001193
2021-06-14 18:57:56,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 109 INodes.
2021-06-14 18:57:56,543 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-14 18:57:56,544 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1183 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001183
2021-06-14 18:57:56,544 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5e1fa5b1 expecting start txid #1184
2021-06-14 18:57:56,544 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001184-0000000000000001193
2021-06-14 18:57:56,547 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001184-0000000000000001193' to transaction ID 1184
2021-06-14 18:57:56,585 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001184-0000000000000001193 of size 1048576 edits # 10 loaded in 0 seconds
2021-06-14 18:57:56,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-06-14 18:57:56,605 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-06-14 18:57:56,742 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1183
2021-06-14 18:57:56,743 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001182, cpktTxId=0000000000000001182)
2021-06-14 18:57:56,767 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1194
2021-06-14 18:57:56,910 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-14 18:57:56,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 990 msecs
2021-06-14 18:57:57,302 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-06-14 18:57:57,311 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-14 18:57:57,326 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-14 18:57:57,392 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-06-14 18:57:57,443 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-14 18:57:57,444 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-14 18:57:57,444 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 60 blocks to reach the threshold 0.9990 of total blocks 60.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-06-14 18:57:57,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-14 18:57:57,492 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-14 18:57:57,492 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-14 18:57:57,496 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-14 18:57:57,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-14 18:57:57,503 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-14 18:58:01,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-14 18:58:01,755 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-14 18:58:01,757 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-06-14 18:58:01,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-14 18:58:01,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-06-14 18:58:02,000 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 59 has reached the threshold 0.9990 of total blocks 60. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-06-14 18:58:02,000 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-06-14 18:58:02,002 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 69, hasStaleStorage: false, processing time: 12 msecs
2021-06-14 18:58:02,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 60
2021-06-14 18:58:02,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-14 18:58:02,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-14 18:58:02,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-14 18:58:02,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-14 18:58:02,005 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2021-06-14 18:58:22,022 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 60 has reached the threshold 0.9990 of total blocks 60. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-06-14 18:58:32,037 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 36 secs
2021-06-14 18:58:32,037 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-06-14 18:58:32,037 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-06-14 18:58:32,037 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-14 18:59:00,508 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 4 
2021-06-14 18:59:00,511 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741834_1010 10.191.53.85:50010 
2021-06-14 18:59:00,521 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741835_1011 10.191.53.85:50010 
2021-06-14 18:59:00,523 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741874_1050 10.191.53.85:50010 
2021-06-14 18:59:00,526 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741875_1051 10.191.53.85:50010 
2021-06-14 18:59:00,533 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741885_1061 10.191.53.85:50010 
2021-06-14 18:59:00,535 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741886_1062 10.191.53.85:50010 
2021-06-14 18:59:00,537 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741906_1082 10.191.53.85:50010 
2021-06-14 18:59:00,540 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741907_1083 10.191.53.85:50010 
2021-06-14 18:59:00,543 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741917_1093 10.191.53.85:50010 
2021-06-14 18:59:00,547 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741918_1094 10.191.53.85:50010 
2021-06-14 18:59:00,551 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741929_1105 10.191.53.85:50010 
2021-06-14 18:59:00,554 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741930_1106 10.191.53.85:50010 
2021-06-14 18:59:00,559 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741949_1125 10.191.53.85:50010 
2021-06-14 18:59:00,568 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741950_1126 10.191.53.85:50010 
2021-06-14 18:59:00,571 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741960_1136 10.191.53.85:50010 
2021-06-14 18:59:00,575 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741961_1137 10.191.53.85:50010 
2021-06-14 18:59:00,581 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741972_1148 10.191.53.85:50010 
2021-06-14 18:59:00,583 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741973_1149 10.191.53.85:50010 
2021-06-14 18:59:03,482 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741960_1136, blk_1073741961_1137, blk_1073741929_1105, blk_1073741834_1010, blk_1073741930_1106, blk_1073741835_1011, blk_1073741874_1050, blk_1073741906_1082, blk_1073741875_1051, blk_1073741907_1083, blk_1073741972_1148, blk_1073741973_1149, blk_1073741885_1061, blk_1073741917_1093, blk_1073741949_1125, blk_1073741950_1126, blk_1073741886_1062, blk_1073741918_1094]
2021-06-14 19:11:27,014 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-14 19:11:27,018 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-14 19:16:33,401 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-14 19:16:33,410 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-14 19:16:33,415 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-14 19:16:33,755 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-14 19:16:33,843 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-14 19:16:33,843 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-14 19:16:33,845 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-06-14 19:16:33,846 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-06-14 19:16:39,059 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-06-14 19:16:39,164 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-14 19:16:39,174 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-14 19:16:39,191 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-14 19:16:39,199 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-14 19:16:39,202 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-14 19:16:39,203 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-14 19:16:39,203 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-14 19:16:39,246 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-14 19:16:39,248 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-14 19:16:39,265 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-06-14 19:16:39,266 INFO org.mortbay.log: jetty-6.1.26
2021-06-14 19:16:39,405 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-06-14 19:16:39,456 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-14 19:16:39,456 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-14 19:16:39,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-06-14 19:16:39,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-06-14 19:16:39,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-06-14 19:16:39,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-14 19:16:39,578 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-14 19:16:39,579 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 14 19:16:39
2021-06-14 19:16:39,583 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-14 19:16:39,583 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-14 19:16:39,585 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-06-14 19:16:39,585 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-14 19:16:39,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-06-14 19:16:39,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-14 19:16:39,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-14 19:16:39,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-14 19:16:39,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-14 19:16:39,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-06-14 19:16:39,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-14 19:16:39,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-14 19:16:39,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-06-14 19:16:39,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-14 19:16:39,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-14 19:16:39,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-14 19:16:39,607 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-06-14 19:16:39,936 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-14 19:16:39,936 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-14 19:16:39,936 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-06-14 19:16:39,936 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-14 19:16:39,937 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-14 19:16:39,937 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-14 19:16:39,937 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-06-14 19:16:39,937 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-06-14 19:16:39,946 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-14 19:16:39,947 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-14 19:16:39,947 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-06-14 19:16:39,947 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-14 19:16:39,949 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-14 19:16:39,949 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-06-14 19:16:39,949 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-06-14 19:16:39,957 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-14 19:16:39,957 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-14 19:16:39,957 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-14 19:16:39,959 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-14 19:16:39,959 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-14 19:16:39,962 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-14 19:16:39,963 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-14 19:16:39,963 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-06-14 19:16:39,963 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-14 19:16:39,980 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 2936@DESKTOP-TSQQRSN
2021-06-14 19:16:40,045 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-06-14 19:16:40,101 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001194 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001194-0000000000000001214
2021-06-14 19:16:40,168 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 91 INodes.
2021-06-14 19:16:40,317 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-14 19:16:40,318 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1193 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001193
2021-06-14 19:16:40,318 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5e1fa5b1 expecting start txid #1194
2021-06-14 19:16:40,318 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001194-0000000000000001214
2021-06-14 19:16:40,323 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001194-0000000000000001214' to transaction ID 1194
2021-06-14 19:16:40,353 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001194-0000000000000001214 of size 1048576 edits # 21 loaded in 0 seconds
2021-06-14 19:16:40,358 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2021-06-14 19:16:40,360 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1215
2021-06-14 19:16:40,508 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-14 19:16:40,508 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 537 msecs
2021-06-14 19:16:40,784 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-06-14 19:16:40,792 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-14 19:16:40,811 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-14 19:16:40,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-06-14 19:16:40,907 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-14 19:16:40,907 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-14 19:16:40,908 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 42 blocks to reach the threshold 0.9990 of total blocks 42.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-06-14 19:16:40,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-14 19:16:40,975 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-14 19:16:40,975 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-14 19:16:40,978 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-14 19:16:40,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-14 19:16:40,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-14 19:16:41,903 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-14 19:16:41,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-14 19:16:41,904 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-06-14 19:16:42,006 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-14 19:16:42,006 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-06-14 19:16:42,075 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 41 has reached the threshold 0.9990 of total blocks 42. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-06-14 19:16:42,075 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-06-14 19:16:42,078 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 51, hasStaleStorage: false, processing time: 10 msecs
2021-06-14 19:16:42,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 42
2021-06-14 19:16:42,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-14 19:16:42,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-14 19:16:42,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-14 19:16:42,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-14 19:16:42,081 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2021-06-14 19:17:02,104 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 42 has reached the threshold 0.9990 of total blocks 42. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-06-14 19:17:12,129 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 32 secs
2021-06-14 19:17:12,129 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-06-14 19:17:12,129 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-06-14 19:17:12,129 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-14 19:31:34,686 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-14 19:31:34,689 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-20 21:01:06,525 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-20 21:01:06,599 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-20 21:01:06,635 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-20 21:01:07,380 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-20 21:01:08,062 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-20 21:01:08,062 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-20 21:01:08,065 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-06-20 21:01:08,066 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-06-20 21:01:13,601 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-06-20 21:01:13,672 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-20 21:01:13,688 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-20 21:01:13,706 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-20 21:01:13,713 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-20 21:01:13,716 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-20 21:01:13,716 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-20 21:01:13,716 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-20 21:01:13,749 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-20 21:01:13,751 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-20 21:01:13,811 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-06-20 21:01:13,812 INFO org.mortbay.log: jetty-6.1.26
2021-06-20 21:01:13,995 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-06-20 21:01:14,056 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-20 21:01:14,056 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-20 21:01:14,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-06-20 21:01:14,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-06-20 21:01:14,247 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-06-20 21:01:14,247 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-20 21:01:14,249 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-20 21:01:14,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 20 21:01:14
2021-06-20 21:01:14,252 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-20 21:01:14,252 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-20 21:01:14,270 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-06-20 21:01:14,270 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-20 21:01:14,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-06-20 21:01:14,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-20 21:01:14,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-20 21:01:14,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-20 21:01:14,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-20 21:01:14,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-06-20 21:01:14,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-20 21:01:14,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-20 21:01:14,288 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-06-20 21:01:14,288 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-20 21:01:14,288 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-20 21:01:14,288 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-20 21:01:14,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-06-20 21:01:14,623 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-20 21:01:14,623 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-20 21:01:14,624 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-06-20 21:01:14,624 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-20 21:01:14,624 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-20 21:01:14,625 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-20 21:01:14,625 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-06-20 21:01:14,625 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-06-20 21:01:14,632 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-20 21:01:14,633 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-20 21:01:14,633 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-06-20 21:01:14,633 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-20 21:01:14,634 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-20 21:01:14,634 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-06-20 21:01:14,634 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-06-20 21:01:14,639 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-20 21:01:14,639 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-20 21:01:14,639 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-20 21:01:14,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-20 21:01:14,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-20 21:01:14,645 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-20 21:01:14,645 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-20 21:01:14,645 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-06-20 21:01:14,645 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-20 21:01:14,659 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 898@DESKTOP-TSQQRSN
2021-06-20 21:01:14,769 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-06-20 21:01:14,837 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001215 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001215-0000000000000001215
2021-06-20 21:01:14,941 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 91 INodes.
2021-06-20 21:01:15,129 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-20 21:01:15,129 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1193 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001193
2021-06-20 21:01:15,130 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@51972dc7 expecting start txid #1194
2021-06-20 21:01:15,130 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001194-0000000000000001214
2021-06-20 21:01:15,132 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001194-0000000000000001214' to transaction ID 1194
2021-06-20 21:01:15,187 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001194-0000000000000001214 of size 1048576 edits # 21 loaded in 0 seconds
2021-06-20 21:01:15,187 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3700ec9c expecting start txid #1215
2021-06-20 21:01:15,187 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001215-0000000000000001215
2021-06-20 21:01:15,187 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001215-0000000000000001215' to transaction ID 1194
2021-06-20 21:01:15,189 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001215-0000000000000001215 of size 1048576 edits # 1 loaded in 0 seconds
2021-06-20 21:01:15,196 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-06-20 21:01:15,196 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-06-20 21:01:15,678 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1193
2021-06-20 21:01:15,678 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001183, cpktTxId=0000000000000001183)
2021-06-20 21:01:15,693 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1216
2021-06-20 21:01:15,845 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-20 21:01:15,845 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1196 msecs
2021-06-20 21:01:16,242 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-06-20 21:01:16,252 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-20 21:01:16,270 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-20 21:01:16,332 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-06-20 21:01:16,399 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-20 21:01:16,399 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-20 21:01:16,400 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 42 blocks to reach the threshold 0.9990 of total blocks 42.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-06-20 21:01:16,410 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-20 21:01:16,455 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-20 21:01:16,455 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-20 21:01:16,460 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-20 21:01:16,460 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-20 21:01:16,467 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-20 21:01:21,149 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-20 21:01:21,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-20 21:01:21,150 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-06-20 21:01:21,325 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-20 21:01:21,325 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-06-20 21:01:21,390 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 41 has reached the threshold 0.9990 of total blocks 42. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-06-20 21:01:21,390 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-06-20 21:01:21,392 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 51, hasStaleStorage: false, processing time: 9 msecs
2021-06-20 21:01:21,394 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 42
2021-06-20 21:01:21,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-20 21:01:21,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-20 21:01:21,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-20 21:01:21,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-20 21:01:21,395 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2021-06-20 21:01:41,560 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 42 has reached the threshold 0.9990 of total blocks 42. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-06-20 21:01:51,631 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 37 secs
2021-06-20 21:01:51,631 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-06-20 21:01:51,631 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-06-20 21:01:51,631 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-20 21:02:21,136 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-20 21:02:21,136 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-20 21:02:21,136 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1216
2021-06-20 21:02:21,137 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-20 21:02:21,138 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2021-06-20 21:02:21,140 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001216 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001216-0000000000000001217
2021-06-20 21:02:21,141 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1218
2021-06-20 21:02:22,189 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 128.21 KB/s
2021-06-20 21:02:22,190 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001217 size 5285 bytes.
2021-06-20 21:02:22,258 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1215
2021-06-20 21:02:22,259 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001193, cpktTxId=0000000000000001193)
2021-06-20 21:23:57,516 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-06-20 21:23:57,516 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2021-06-20 21:23:57,516 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2021-06-20 21:23:57,517 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-20 21:23:57,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-20 21:23:57,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-20 21:23:57,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-20 21:23:57,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-20 21:23:57,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-20 21:24:09,947 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 172 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2021-06-20 21:24:09,995 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741975_1151{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /name.txt._COPYING_
2021-06-20 21:24:10,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741975_1151{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /name.txt._COPYING_
2021-06-20 21:24:10,232 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-06-20 21:24:10,250 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741975_1151{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 21
2021-06-20 21:24:10,655 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /name.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-727550756_1
2021-06-20 21:28:17,618 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 8 Total time for transactions(ms): 173 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 11 
2021-06-20 21:28:17,643 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/name.txt is closed by DFSClient_NONMAPREDUCE_-477728251_1
2021-06-20 21:28:17,676 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741976_1152{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /user/root/name.txt
2021-06-20 21:28:17,904 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741976_1152{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-20 21:28:17,906 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/name.txt is closed by DFSClient_NONMAPREDUCE_-477728251_1
2021-06-20 21:29:53,773 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 15 Total time for transactions(ms): 173 Number of transactions batched in Syncs: 0 Number of syncs: 12 SyncTimes(ms): 99 
2021-06-20 21:29:54,003 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741976_1152, newGS=1153, newLength=16, newNodes=[10.191.53.85:50010], client=DFSClient_NONMAPREDUCE_-981909271_1)
2021-06-20 21:29:54,004 INFO BlockStateChange: BLOCK* Removing stale replica from location: [DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010
2021-06-20 21:29:54,005 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741976_1152 => blk_1073741976_1153) success
2021-06-20 21:29:54,021 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741976_1153{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 16
2021-06-20 21:29:54,024 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/name.txt is closed by DFSClient_NONMAPREDUCE_-981909271_1
2021-06-20 21:34:22,482 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 19 Total time for transactions(ms): 173 Number of transactions batched in Syncs: 0 Number of syncs: 16 SyncTimes(ms): 104 
2021-06-20 21:35:47,973 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-20 21:35:47,976 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2021-06-20 21:35:47,976 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2021-06-20 21:35:47,976 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2021-06-20 21:35:47,976 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2021-06-20 21:35:47,976 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2021-06-20 21:35:47,976 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2021-06-20 21:35:47,976 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command append is: 0
2021-06-20 21:35:47,976 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setOwner is: 1
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command append is: 0
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setOwner is: 1
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 2
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 2
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 2
2021-06-20 21:35:47,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2021-06-20 21:35:47,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 2
2021-06-20 21:35:47,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command append is: 1
2021-06-20 21:35:47,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setOwner is: 1
2021-06-20 21:39:18,207 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 21 Total time for transactions(ms): 173 Number of transactions batched in Syncs: 0 Number of syncs: 18 SyncTimes(ms): 106 
2021-06-20 21:39:18,242 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741977_1154{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /hosts._COPYING_
2021-06-20 21:39:18,391 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741977_1154{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-20 21:39:18,395 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hosts._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1177663384_1
2021-06-20 21:40:42,680 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 27 Total time for transactions(ms): 174 Number of transactions batched in Syncs: 0 Number of syncs: 22 SyncTimes(ms): 109 
2021-06-20 21:40:42,682 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741976_1153 10.191.53.85:50010 
2021-06-20 21:40:45,613 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741976_1153]
2021-06-20 21:42:32,695 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1073741955_1131 to 10.191.53.85:50010
2021-06-20 21:42:32,695 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1073741962_1138 to 10.191.53.85:50010
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1073741836_1012 to 10.191.53.85:50010
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1073741974_1150 to 10.191.53.85:50010
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1073741876_1052 to 10.191.53.85:50010
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1073741887_1063 to 10.191.53.85:50010
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1073741912_1088 to 10.191.53.85:50010
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1073741919_1095 to 10.191.53.85:50010
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* InvalidateBlocks: add blk_1073741931_1107 to 10.191.53.85:50010
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* processReport: blk_1073741955_1131 on node 10.191.53.85:50010 size 130276 does not belong to any file
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* processReport: blk_1073741962_1138 on node 10.191.53.85:50010 size 46532 does not belong to any file
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* processReport: blk_1073741836_1012 on node 10.191.53.85:50010 size 46928 does not belong to any file
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* processReport: blk_1073741974_1150 on node 10.191.53.85:50010 size 46519 does not belong to any file
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* processReport: blk_1073741876_1052 on node 10.191.53.85:50010 size 357169 does not belong to any file
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* processReport: blk_1073741887_1063 on node 10.191.53.85:50010 size 48073 does not belong to any file
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* processReport: blk_1073741912_1088 on node 10.191.53.85:50010 size 130786 does not belong to any file
2021-06-20 21:42:32,696 INFO BlockStateChange: BLOCK* processReport: blk_1073741919_1095 on node 10.191.53.85:50010 size 46666 does not belong to any file
2021-06-20 21:42:32,697 INFO BlockStateChange: BLOCK* processReport: blk_1073741931_1107 on node 10.191.53.85:50010 size 46807 does not belong to any file
2021-06-20 21:42:32,697 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 53, hasStaleStorage: false, processing time: 4 msecs
2021-06-20 21:42:33,847 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741955_1131, blk_1073741876_1052, blk_1073741974_1150, blk_1073741912_1088, blk_1073741962_1138, blk_1073741931_1107, blk_1073741836_1012, blk_1073741919_1095, blk_1073741887_1063]
2021-06-20 21:43:38,110 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 28 Total time for transactions(ms): 174 Number of transactions batched in Syncs: 0 Number of syncs: 23 SyncTimes(ms): 110 
2021-06-20 21:43:38,112 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741975_1151 10.191.53.85:50010 
2021-06-20 21:43:40,008 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741975_1151]
2021-06-20 21:44:10,992 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-20 21:44:10,997 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-21 18:40:29,933 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-21 18:40:30,009 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-21 18:40:30,018 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-21 18:40:30,507 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-21 18:40:30,829 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-21 18:40:30,829 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-21 18:40:30,832 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-06-21 18:40:30,833 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-06-21 18:40:31,144 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-06-21 18:40:31,254 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-21 18:40:31,263 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-21 18:40:31,311 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-21 18:40:31,318 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-21 18:40:31,322 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-21 18:40:31,322 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-21 18:40:31,322 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-21 18:40:31,383 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-21 18:40:31,385 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-21 18:40:31,440 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-06-21 18:40:31,440 INFO org.mortbay.log: jetty-6.1.26
2021-06-21 18:40:31,955 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-06-21 18:40:32,047 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-21 18:40:32,047 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-21 18:40:32,114 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-06-21 18:40:32,114 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-06-21 18:40:32,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-06-21 18:40:32,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-21 18:40:32,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-21 18:40:32,269 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 21 18:40:32
2021-06-21 18:40:32,272 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-21 18:40:32,273 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-21 18:40:32,275 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-06-21 18:40:32,275 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-21 18:40:32,283 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-06-21 18:40:32,283 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-21 18:40:32,283 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-21 18:40:32,283 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-21 18:40:32,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-21 18:40:32,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-06-21 18:40:32,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-21 18:40:32,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-21 18:40:32,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-06-21 18:40:32,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-21 18:40:32,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-21 18:40:32,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-21 18:40:32,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-06-21 18:40:32,854 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-21 18:40:32,854 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-21 18:40:32,855 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-06-21 18:40:32,855 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-21 18:40:32,855 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-21 18:40:32,855 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-21 18:40:32,855 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-06-21 18:40:32,855 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-06-21 18:40:32,863 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-21 18:40:32,863 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-21 18:40:32,863 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-06-21 18:40:32,863 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-21 18:40:32,864 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-21 18:40:32,864 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-06-21 18:40:32,864 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-06-21 18:40:32,869 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-21 18:40:32,869 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-21 18:40:32,869 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-21 18:40:32,871 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-21 18:40:32,871 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-21 18:40:32,876 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-21 18:40:32,876 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-21 18:40:32,876 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-06-21 18:40:32,876 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-21 18:40:32,948 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 202@DESKTOP-TSQQRSN
2021-06-21 18:40:33,020 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-06-21 18:40:33,293 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001218 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001218-0000000000000001245
2021-06-21 18:40:33,410 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 71 INodes.
2021-06-21 18:40:33,532 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-21 18:40:33,532 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1217 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001217
2021-06-21 18:40:33,532 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@655ef322 expecting start txid #1218
2021-06-21 18:40:33,532 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001218-0000000000000001245
2021-06-21 18:40:33,536 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001218-0000000000000001245' to transaction ID 1218
2021-06-21 18:40:33,644 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001218-0000000000000001245 of size 1048576 edits # 28 loaded in 0 seconds
2021-06-21 18:40:33,645 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-06-21 18:40:33,645 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-06-21 18:40:33,770 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1217
2021-06-21 18:40:33,770 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001215, cpktTxId=0000000000000001215)
2021-06-21 18:40:33,782 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1246
2021-06-21 18:40:33,926 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-21 18:40:33,926 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1043 msecs
2021-06-21 18:40:34,323 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-06-21 18:40:34,332 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-21 18:40:34,348 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-21 18:40:34,431 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-06-21 18:40:34,486 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-21 18:40:34,486 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-21 18:40:34,487 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 43 blocks to reach the threshold 0.9990 of total blocks 43.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-06-21 18:40:34,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-21 18:40:34,574 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-21 18:40:34,574 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-21 18:40:34,578 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-21 18:40:34,579 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-21 18:40:34,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-21 18:40:38,410 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-21 18:40:38,410 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-21 18:40:38,411 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-06-21 18:40:38,556 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-21 18:40:38,556 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-06-21 18:40:38,639 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 42 has reached the threshold 0.9990 of total blocks 43. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-06-21 18:40:38,639 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-06-21 18:40:38,640 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 43, hasStaleStorage: false, processing time: 10 msecs
2021-06-21 18:40:38,642 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 43
2021-06-21 18:40:38,642 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-21 18:40:38,642 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-21 18:40:38,642 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-21 18:40:38,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-21 18:40:38,643 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2021-06-21 18:40:58,699 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 43 has reached the threshold 0.9990 of total blocks 43. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-06-21 18:41:08,741 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 36 secs
2021-06-21 18:41:08,742 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-06-21 18:41:08,742 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-06-21 18:41:08,742 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-21 18:59:55,258 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2021-06-21 18:59:55,333 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741978_1155{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /love._COPYING_
2021-06-21 18:59:55,659 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741978_1155{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /love._COPYING_
2021-06-21 18:59:55,659 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-06-21 18:59:55,694 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741978_1155{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 4
2021-06-21 18:59:56,078 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /love._COPYING_ is closed by DFSClient_NONMAPREDUCE_330630287_1
2021-06-21 19:00:06,514 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-06-21 19:00:06,519 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-21 19:00:50,815 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741978_1155, newGS=1156, newLength=4, newNodes=[10.191.53.85:50010], client=DFSClient_NONMAPREDUCE_-1201173458_1)
2021-06-21 19:00:50,816 INFO BlockStateChange: BLOCK* Removing stale replica from location: [DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010
2021-06-21 19:00:50,817 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741978_1155 => blk_1073741978_1156) success
2021-06-21 19:00:50,832 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741978_1156{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 4
2021-06-21 19:00:50,835 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /love is closed by DFSClient_NONMAPREDUCE_-1201173458_1
2021-06-21 19:03:29,398 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 12 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 0 Number of syncs: 11 SyncTimes(ms): 13 
2021-06-21 19:04:30,254 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 14 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 0 Number of syncs: 13 SyncTimes(ms): 351 
2021-06-21 19:04:30,286 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741979_1157{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /name._COPYING_
2021-06-21 19:04:30,415 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741979_1157{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-21 19:04:30,419 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /name._COPYING_ is closed by DFSClient_NONMAPREDUCE_-616012894_1
2021-06-21 19:07:47,290 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 20 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 17 SyncTimes(ms): 355 
2021-06-21 19:07:47,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1158{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /test/love._COPYING_
2021-06-21 19:07:47,527 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741980_1158{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-21 19:07:47,531 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/love._COPYING_ is closed by DFSClient_NONMAPREDUCE_446297674_1
2021-06-21 19:08:24,390 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1159{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /test/name._COPYING_
2021-06-21 19:08:24,489 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741981_1159{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-21 19:08:24,493 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/name._COPYING_ is closed by DFSClient_NONMAPREDUCE_-747635998_1
2021-06-21 19:09:03,959 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 32 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 25 SyncTimes(ms): 406 
2021-06-21 19:09:03,960 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741980_1158 10.191.53.85:50010 
2021-06-21 19:09:06,883 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741980_1158]
2021-06-21 19:21:34,320 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 37 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 27 SyncTimes(ms): 408 
2021-06-21 19:21:34,357 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741978_1156 10.191.53.85:50010 
2021-06-21 19:21:34,357 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741981_1159 10.191.53.85:50010 
2021-06-21 19:21:35,094 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741978_1156, blk_1073741981_1159]
2021-06-21 19:23:39,694 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 38 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 28 SyncTimes(ms): 445 
2021-06-21 19:28:21,366 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 2 for /hosts
2021-06-21 19:28:21,367 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 39 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 29 SyncTimes(ms): 448 
2021-06-21 19:29:17,151 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Decreasing replication from 2 to 1 for /hosts
2021-06-21 19:39:44,781 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-21 19:39:44,782 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-21 19:39:44,782 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1246
2021-06-21 19:39:44,782 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 41 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 31 SyncTimes(ms): 451 
2021-06-21 19:39:44,783 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 41 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 32 SyncTimes(ms): 452 
2021-06-21 19:39:44,785 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001246 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001246-0000000000000001286
2021-06-21 19:39:44,785 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1287
2021-06-21 19:39:46,208 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 116.28 KB/s
2021-06-21 19:39:46,208 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001286 size 5362 bytes.
2021-06-21 19:39:46,268 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1245
2021-06-21 19:39:46,268 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001217, cpktTxId=0000000000000001217)
2021-06-21 19:44:47,239 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 45 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2021-06-21 19:44:47,240 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741932_1108 10.191.53.85:50010 
2021-06-21 19:44:47,240 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741933_1109 10.191.53.85:50010 
2021-06-21 19:44:47,240 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741934_1110 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741935_1111 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741936_1112 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741937_1113 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741938_1114 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741939_1115 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741940_1116 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741837_1013 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741838_1014 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741839_1015 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741840_1016 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741841_1017 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741842_1018 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741843_1019 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741844_1020 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741845_1021 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741846_1022 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741847_1023 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741848_1024 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741849_1025 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741850_1026 10.191.53.85:50010 
2021-06-21 19:44:47,241 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741851_1027 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741852_1028 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741853_1029 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741854_1030 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741855_1031 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741856_1032 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741857_1033 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741858_1034 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741859_1035 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741860_1036 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741861_1037 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741862_1038 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741863_1039 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741864_1040 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741865_1041 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741958_1134 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741872_1048 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741963_1139 10.191.53.85:50010 
2021-06-21 19:44:47,242 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741970_1146 10.191.53.85:50010 
2021-06-21 19:44:49,906 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741958_1134, blk_1073741963_1139, blk_1073741837_1013, blk_1073741838_1014, blk_1073741839_1015, blk_1073741840_1016, blk_1073741841_1017, blk_1073741970_1146, blk_1073741842_1018, blk_1073741843_1019, blk_1073741844_1020, blk_1073741845_1021, blk_1073741846_1022, blk_1073741847_1023, blk_1073741848_1024, blk_1073741849_1025, blk_1073741850_1026, blk_1073741851_1027, blk_1073741852_1028, blk_1073741853_1029, blk_1073741854_1030, blk_1073741855_1031, blk_1073741856_1032, blk_1073741857_1033, blk_1073741858_1034, blk_1073741859_1035, blk_1073741860_1036, blk_1073741861_1037, blk_1073741862_1038, blk_1073741863_1039, blk_1073741864_1040, blk_1073741865_1041, blk_1073741932_1108, blk_1073741933_1109, blk_1073741934_1110, blk_1073741935_1111, blk_1073741872_1048, blk_1073741936_1112, blk_1073741937_1113, blk_1073741938_1114, blk_1073741939_1115, blk_1073741940_1116]
2021-06-21 19:57:25,043 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 47 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 752 
2021-06-21 19:58:48,528 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 50 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 755 
2021-06-21 19:59:52,405 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 51 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 756 
2021-06-21 20:08:19,415 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 52 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 757 
2021-06-21 20:12:36,425 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 53 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 9 SyncTimes(ms): 758 
2021-06-21 20:12:36,426 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741977_1154 10.191.53.85:50010 
2021-06-21 20:12:38,462 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741977_1154]
2021-06-21 20:15:10,797 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 54 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 10 SyncTimes(ms): 759 
2021-06-21 20:15:10,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1160{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /hosts._COPYING_
2021-06-21 20:15:11,104 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741982_1160{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-21 20:15:11,112 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hosts._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1906973481_1
2021-06-21 20:24:18,539 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 61 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 14 SyncTimes(ms): 770 
2021-06-21 20:25:34,444 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 65 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 16 SyncTimes(ms): 772 
2021-06-21 20:28:13,453 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 66 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 17 SyncTimes(ms): 773 
2021-06-21 20:28:13,454 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741982_1160 10.191.53.85:50010 
2021-06-21 20:28:13,514 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741982_1160]
2021-06-21 20:30:34,474 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 68 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 19 SyncTimes(ms): 775 
2021-06-21 20:30:34,829 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741979_1157, newGS=1161, newLength=34, newNodes=[10.191.53.85:50010], client=DFSClient_NONMAPREDUCE_-512586312_1)
2021-06-21 20:30:34,829 INFO BlockStateChange: BLOCK* Removing stale replica from location: [DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010
2021-06-21 20:30:34,830 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741979_1157 => blk_1073741979_1161) success
2021-06-21 20:30:34,847 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741979_1161{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 34
2021-06-21 20:30:34,850 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /README.md is closed by DFSClient_NONMAPREDUCE_-512586312_1
2021-06-21 20:31:33,011 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741979_1161 10.191.53.85:50010 
2021-06-21 20:31:35,078 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741979_1161]
2021-06-21 20:34:13,244 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 73 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 24 SyncTimes(ms): 778 
2021-06-21 20:35:06,772 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1162{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /README.md._COPYING_
2021-06-21 20:35:06,917 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741983_1162{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-21 20:35:06,921 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /README.md._COPYING_ is closed by DFSClient_NONMAPREDUCE_25175107_1
2021-06-21 20:35:30,429 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 80 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 29 SyncTimes(ms): 782 
2021-06-21 20:39:47,128 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-21 20:39:47,128 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-21 20:39:47,128 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1287
2021-06-21 20:39:47,129 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 81 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 30 SyncTimes(ms): 783 
2021-06-21 20:39:47,129 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 81 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 31 SyncTimes(ms): 784 
2021-06-21 20:39:47,130 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001287 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001287-0000000000000001367
2021-06-21 20:39:47,131 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1368
2021-06-21 20:39:47,734 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 27.03 KB/s
2021-06-21 20:39:47,735 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001367 size 1501 bytes.
2021-06-21 20:39:47,794 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1286
2021-06-21 20:39:47,795 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001245, cpktTxId=0000000000000001245)
2021-06-21 21:38:18,973 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-21 21:38:18,981 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-22 11:02:36,981 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-22 11:02:37,001 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-22 11:02:37,008 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-22 11:02:37,334 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-22 11:02:37,420 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-22 11:02:37,420 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-22 11:02:37,422 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-06-22 11:02:37,423 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-06-22 11:02:37,669 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-06-22 11:02:37,755 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-22 11:02:37,764 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-22 11:02:37,780 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-22 11:02:37,785 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-22 11:02:37,787 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-22 11:02:37,787 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-22 11:02:37,787 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-22 11:02:37,830 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-22 11:02:37,832 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-22 11:02:37,850 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-06-22 11:02:37,850 INFO org.mortbay.log: jetty-6.1.26
2021-06-22 11:02:37,994 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-06-22 11:02:38,044 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-22 11:02:38,044 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-22 11:02:38,091 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-06-22 11:02:38,091 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-06-22 11:02:38,140 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-06-22 11:02:38,141 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-22 11:02:38,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-22 11:02:38,143 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 22 11:02:38
2021-06-22 11:02:38,146 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-22 11:02:38,146 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-22 11:02:38,148 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-06-22 11:02:38,148 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-22 11:02:38,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-06-22 11:02:38,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-22 11:02:38,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-22 11:02:38,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-22 11:02:38,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-22 11:02:38,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-06-22 11:02:38,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-22 11:02:38,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-22 11:02:38,164 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-06-22 11:02:38,164 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-22 11:02:38,164 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-22 11:02:38,164 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-22 11:02:38,166 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-06-22 11:02:38,364 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-22 11:02:38,365 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-22 11:02:38,365 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-06-22 11:02:38,365 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-22 11:02:38,366 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-22 11:02:38,366 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-22 11:02:38,366 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-06-22 11:02:38,366 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-06-22 11:02:38,374 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-22 11:02:38,374 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-22 11:02:38,374 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-06-22 11:02:38,374 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-22 11:02:38,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-22 11:02:38,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-06-22 11:02:38,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-06-22 11:02:38,379 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-22 11:02:38,379 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-22 11:02:38,379 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-22 11:02:38,381 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-22 11:02:38,381 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-22 11:02:38,404 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-22 11:02:38,404 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-22 11:02:38,404 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-06-22 11:02:38,404 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-22 11:02:38,426 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 1674@DESKTOP-TSQQRSN
2021-06-22 11:02:38,535 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-06-22 11:02:38,612 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001368 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001368-0000000000000001368
2021-06-22 11:02:38,680 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 19 INodes.
2021-06-22 11:02:38,840 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-22 11:02:38,840 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1367 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001367
2021-06-22 11:02:38,841 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2807bdeb expecting start txid #1368
2021-06-22 11:02:38,841 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001368-0000000000000001368
2021-06-22 11:02:38,843 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001368-0000000000000001368' to transaction ID 1368
2021-06-22 11:02:38,846 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001368-0000000000000001368 of size 1048576 edits # 1 loaded in 0 seconds
2021-06-22 11:02:38,853 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-06-22 11:02:38,853 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-06-22 11:02:38,979 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1367
2021-06-22 11:02:38,979 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001286, cpktTxId=0000000000000001286)
2021-06-22 11:02:39,016 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1369
2021-06-22 11:02:39,165 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-22 11:02:39,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 753 msecs
2021-06-22 11:02:39,494 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-06-22 11:02:39,502 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-22 11:02:39,513 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-22 11:02:39,537 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-06-22 11:02:39,599 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-22 11:02:39,599 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-22 11:02:39,599 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-06-22 11:02:39,600 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2021-06-22 11:02:39,600 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-06-22 11:02:39,600 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-22 11:02:39,613 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-22 11:02:39,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 1
2021-06-22 11:02:39,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-22 11:02:39,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 1
2021-06-22 11:02:39,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-22 11:02:39,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-22 11:02:39,629 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 29 msec
2021-06-22 11:02:39,658 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-22 11:02:39,658 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-22 11:02:39,663 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-22 11:02:39,663 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-22 11:02:39,668 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-22 11:02:45,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-22 11:02:45,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-22 11:02:45,268 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-06-22 11:02:45,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-22 11:02:45,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-06-22 11:02:45,457 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 1, hasStaleStorage: false, processing time: 3 msecs
2021-06-22 11:48:06,722 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-06-22 11:48:06,722 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2021-06-22 11:48:06,722 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2021-06-22 11:48:06,722 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-06-22 11:48:06,723 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-22 11:48:06,725 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-22 11:48:06,725 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-06-22 11:48:06,725 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-22 11:48:06,725 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-22 11:48:17,838 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 31 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-22 11:58:51,945 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-22 11:58:51,945 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-22 11:58:51,945 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1369
2021-06-22 11:58:51,946 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 31 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2021-06-22 11:58:51,946 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 31 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 7 
2021-06-22 11:58:51,954 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001369 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001369-0000000000000001371
2021-06-22 11:58:51,957 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1372
2021-06-22 11:58:54,079 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 18.18 KB/s
2021-06-22 11:58:54,079 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001371 size 1555 bytes.
2021-06-22 11:58:54,128 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1368
2021-06-22 11:58:54,129 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001367, cpktTxId=0000000000000001367)
2021-06-22 12:03:12,187 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2021-06-22 12:58:54,863 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-22 12:58:54,863 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-22 12:58:54,863 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1372
2021-06-22 12:58:54,863 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 11 
2021-06-22 12:58:54,882 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 29 
2021-06-22 12:58:54,883 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001372 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001372-0000000000000001375
2021-06-22 12:58:54,885 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1376
2021-06-22 12:58:55,440 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.19s at 5.21 KB/s
2021-06-22 12:58:55,440 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001375 size 1555 bytes.
2021-06-22 12:58:55,492 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1371
2021-06-22 12:58:55,492 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001368, cpktTxId=0000000000000001368)
2021-06-22 13:44:11,013 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 1, hasStaleStorage: false, processing time: 358 msecs
2021-06-22 13:46:41,027 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-22 13:46:41,135 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1163{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /root/hosts
2021-06-22 13:46:41,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741984_1163{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /root/hosts
2021-06-22 13:46:41,612 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-06-22 13:46:41,667 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741984_1163{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 404
2021-06-22 13:46:42,034 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /root/hosts is closed by DFSClient_NONMAPREDUCE_648353265_1
2021-06-22 13:46:56,303 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-22 13:46:56,303 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-06-22 13:46:56,303 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2021-06-22 13:46:56,303 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-06-22 13:46:56,303 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-22 13:46:56,304 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-06-22 13:46:56,304 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-22 13:46:56,304 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-06-22 13:46:56,304 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-22 13:46:56,305 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-06-22 13:46:56,305 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-22 13:46:56,305 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-06-22 13:46:56,305 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-22 13:46:56,306 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2021-06-22 13:46:56,306 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-22 13:46:56,306 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-06-22 13:46:56,306 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-22 13:46:56,306 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-06-22 13:57:39,297 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 8 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 9 
2021-06-22 13:57:39,317 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741985_1164{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /hosts
2021-06-22 13:57:39,435 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741985_1164{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-22 13:57:39,439 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hosts is closed by DFSClient_NONMAPREDUCE_1298327709_1
2021-06-22 13:58:17,283 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741984_1163 10.191.53.85:50010 
2021-06-22 13:58:19,433 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741984_1163]
2021-06-22 13:58:30,572 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741985_1164 10.191.53.85:50010 
2021-06-22 13:58:31,466 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741985_1164]
2021-06-22 13:58:56,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-22 13:58:56,385 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-22 13:58:56,386 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1376
2021-06-22 13:58:56,386 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 15 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 11 SyncTimes(ms): 12 
2021-06-22 13:58:56,388 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 15 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 12 SyncTimes(ms): 14 
2021-06-22 13:58:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001376 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001376-0000000000000001390
2021-06-22 13:58:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1391
2021-06-22 13:58:56,841 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 21.28 KB/s
2021-06-22 13:58:56,842 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001390 size 1555 bytes.
2021-06-22 13:58:56,892 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1375
2021-06-22 13:58:56,892 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001371, cpktTxId=0000000000000001371)
2021-06-22 14:58:57,791 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-22 14:58:57,792 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-22 14:58:57,792 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1391
2021-06-22 14:58:57,792 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 25 
2021-06-22 14:58:57,795 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 28 
2021-06-22 14:58:57,796 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001391 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001391-0000000000000001392
2021-06-22 14:58:57,797 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1393
2021-06-22 14:58:58,152 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 27.03 KB/s
2021-06-22 14:58:58,153 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001392 size 1555 bytes.
2021-06-22 14:58:58,211 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1390
2021-06-22 14:58:58,211 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001375, cpktTxId=0000000000000001375)
2021-06-22 15:19:33,788 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 129245ms
No GCs detected
2021-06-22 15:59:31,136 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-22 15:59:31,136 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-22 15:59:31,137 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1393
2021-06-22 15:59:31,137 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-22 15:59:31,141 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 
2021-06-22 15:59:31,142 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001393 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001393-0000000000000001394
2021-06-22 15:59:31,145 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1395
2021-06-22 15:59:31,518 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 30.30 KB/s
2021-06-22 15:59:31,518 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001394 size 1555 bytes.
2021-06-22 15:59:31,567 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1392
2021-06-22 15:59:31,567 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001390, cpktTxId=0000000000000001390)
2021-06-22 16:59:32,683 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-22 16:59:32,684 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-22 16:59:32,684 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1395
2021-06-22 16:59:32,685 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-22 16:59:32,689 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 
2021-06-22 16:59:32,691 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001395 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001395-0000000000000001396
2021-06-22 16:59:32,693 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1397
2021-06-22 16:59:33,416 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 22.73 KB/s
2021-06-22 16:59:33,416 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001396 size 1555 bytes.
2021-06-22 16:59:33,554 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1394
2021-06-22 16:59:33,554 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001392, cpktTxId=0000000000000001392)
2021-06-22 17:48:18,426 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 23 
2021-06-22 17:50:16,141 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 24 
2021-06-22 17:52:45,002 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 84 
2021-06-22 17:55:36,571 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 6 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 87 
2021-06-22 17:59:35,127 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-22 17:59:35,127 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-22 17:59:35,127 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1397
2021-06-22 17:59:35,128 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 7 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 87 
2021-06-22 17:59:35,130 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 7 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 88 
2021-06-22 17:59:35,131 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001397 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001397-0000000000000001403
2021-06-22 17:59:35,134 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1404
2021-06-22 17:59:35,824 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 30.30 KB/s
2021-06-22 17:59:35,825 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001403 size 1558 bytes.
2021-06-22 17:59:35,901 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1396
2021-06-22 17:59:35,901 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001394, cpktTxId=0000000000000001394)
2021-06-22 18:08:23,707 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-22 18:08:23,770 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741986_1165{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /pom.xml
2021-06-22 18:08:23,975 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741986_1165{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-22 18:08:23,977 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /pom.xml is closed by DFSClient_NONMAPREDUCE_367191016_1
2021-06-22 18:59:37,054 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-22 18:59:37,054 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-22 18:59:37,054 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1404
2021-06-22 18:59:37,054 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 7 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 10 
2021-06-22 18:59:37,056 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 7 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 11 
2021-06-22 18:59:37,056 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001404 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001404-0000000000000001410
2021-06-22 18:59:37,057 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1411
2021-06-22 18:59:37,684 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 55.56 KB/s
2021-06-22 18:59:37,684 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001410 size 1625 bytes.
2021-06-22 18:59:37,746 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1403
2021-06-22 18:59:37,747 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001396, cpktTxId=0000000000000001396)
2021-06-22 19:44:12,459 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 2, hasStaleStorage: false, processing time: 1 msecs
2021-06-22 19:59:38,853 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-22 19:59:38,853 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-22 19:59:38,853 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1411
2021-06-22 19:59:38,853 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-22 19:59:38,856 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2021-06-22 19:59:38,858 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001411 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001411-0000000000000001412
2021-06-22 19:59:38,860 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1413
2021-06-22 19:59:39,490 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 28.57 KB/s
2021-06-22 19:59:39,490 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001412 size 1625 bytes.
2021-06-22 19:59:39,551 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1410
2021-06-22 19:59:39,551 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001403, cpktTxId=0000000000000001403)
2021-06-22 20:45:11,674 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-22 20:59:40,983 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-22 20:59:40,984 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-22 20:59:40,984 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1413
2021-06-22 20:59:40,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 10 
2021-06-22 20:59:40,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 10 
2021-06-22 20:59:40,988 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001413 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001413-0000000000000001417
2021-06-22 20:59:41,013 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1418
2021-06-22 20:59:41,425 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 25.00 KB/s
2021-06-22 20:59:41,425 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001417 size 1625 bytes.
2021-06-22 20:59:41,521 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1412
2021-06-22 20:59:41,521 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001410, cpktTxId=0000000000000001410)
2021-06-22 21:01:53,091 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 16 
2021-06-22 21:01:53,111 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test.txt is closed by DFSClient_NONMAPREDUCE_-496895318_1
2021-06-22 21:06:20,570 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 20 
2021-06-22 21:12:09,055 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 7 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 21 
2021-06-22 21:12:09,101 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741987_1166{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /README.md._COPYING_
2021-06-22 21:12:09,371 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741987_1166{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /README.md._COPYING_
2021-06-22 21:12:09,372 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741987_1166{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 34
2021-06-22 21:12:09,790 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /README.md._COPYING_ is closed by DFSClient_NONMAPREDUCE_-296689884_1
2021-06-22 21:12:39,304 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741987_1166, newGS=1167, newLength=34, newNodes=[10.191.53.85:50010], client=DFSClient_NONMAPREDUCE_-560418414_1)
2021-06-22 21:12:39,304 INFO BlockStateChange: BLOCK* Removing stale replica from location: [DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010
2021-06-22 21:12:39,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741987_1166 => blk_1073741987_1167) success
2021-06-22 21:12:39,336 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741987_1167{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 34
2021-06-22 21:12:39,339 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /README.md is closed by DFSClient_NONMAPREDUCE_-560418414_1
2021-06-22 21:14:26,559 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 17 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 1 Number of syncs: 14 SyncTimes(ms): 31 
2021-06-22 21:14:26,566 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741987_1167 10.191.53.85:50010 
2021-06-22 21:14:26,617 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741987_1167]
2021-06-22 21:15:23,879 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741983_1162 10.191.53.85:50010 
2021-06-22 21:15:26,806 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741983_1162]
2021-06-22 21:17:07,357 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 19 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 1 Number of syncs: 16 SyncTimes(ms): 33 
2021-06-22 21:22:14,206 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-22 21:22:14,219 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-26 08:52:42,330 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-26 08:52:42,649 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-26 08:52:42,693 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-26 08:52:43,421 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-26 08:52:44,411 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-26 08:52:44,411 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-26 08:52:44,414 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-06-26 08:52:44,415 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-06-26 08:52:45,113 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-06-26 08:52:45,387 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-26 08:52:45,399 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-26 08:52:45,559 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-26 08:52:45,569 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-26 08:52:45,573 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-26 08:52:45,573 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-26 08:52:45,573 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-26 08:52:45,825 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-26 08:52:45,827 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-26 08:52:46,006 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-06-26 08:52:46,006 INFO org.mortbay.log: jetty-6.1.26
2021-06-26 08:52:46,952 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-06-26 08:52:47,259 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-26 08:52:47,259 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-26 08:52:47,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-06-26 08:52:47,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-06-26 08:52:47,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-06-26 08:52:47,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-26 08:52:47,634 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-26 08:52:47,636 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 26 08:52:47
2021-06-26 08:52:47,688 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-26 08:52:47,688 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-26 08:52:47,692 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-06-26 08:52:47,692 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-26 08:52:47,704 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-06-26 08:52:47,704 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-26 08:52:47,704 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-26 08:52:47,704 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-26 08:52:47,704 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-26 08:52:47,704 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-06-26 08:52:47,704 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-26 08:52:47,704 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-26 08:52:47,716 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-06-26 08:52:47,716 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-26 08:52:47,716 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-26 08:52:47,716 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-26 08:52:47,724 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-06-26 08:52:49,037 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-26 08:52:49,037 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-26 08:52:49,037 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-06-26 08:52:49,037 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-26 08:52:49,038 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-26 08:52:49,038 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-26 08:52:49,038 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-06-26 08:52:49,038 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-06-26 08:52:49,050 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-26 08:52:49,051 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-26 08:52:49,051 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-06-26 08:52:49,051 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-26 08:52:49,053 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-26 08:52:49,053 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-06-26 08:52:49,053 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-06-26 08:52:49,120 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-26 08:52:49,120 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-26 08:52:49,121 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-26 08:52:49,126 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-26 08:52:49,126 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-26 08:52:49,164 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-26 08:52:49,164 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-26 08:52:49,164 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-06-26 08:52:49,164 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-26 08:52:49,269 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 352@DESKTOP-TSQQRSN
2021-06-26 08:52:49,519 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-06-26 08:52:50,082 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001418 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001418-0000000000000001437
2021-06-26 08:52:50,163 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 21 INodes.
2021-06-26 08:52:50,408 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-26 08:52:50,408 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1417 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001417
2021-06-26 08:52:50,409 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@655ef322 expecting start txid #1418
2021-06-26 08:52:50,409 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001418-0000000000000001437
2021-06-26 08:52:50,413 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001418-0000000000000001437' to transaction ID 1418
2021-06-26 08:52:50,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001418-0000000000000001437 of size 1048576 edits # 20 loaded in 0 seconds
2021-06-26 08:52:50,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-06-26 08:52:50,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-06-26 08:52:51,152 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1417
2021-06-26 08:52:51,152 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001412, cpktTxId=0000000000000001412)
2021-06-26 08:52:51,216 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1438
2021-06-26 08:52:51,533 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-26 08:52:51,534 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 2363 msecs
2021-06-26 08:52:52,075 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-06-26 08:52:52,090 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-26 08:52:52,119 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-26 08:52:52,193 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-06-26 08:52:52,458 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 1
2021-06-26 08:52:52,458 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 1
2021-06-26 08:52:52,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-06-26 08:52:52,459 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 4 secs
2021-06-26 08:52:52,459 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-06-26 08:52:52,459 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-26 08:52:52,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-26 08:52:52,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 1
2021-06-26 08:52:52,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-26 08:52:52,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2021-06-26 08:52:52,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-26 08:52:52,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 1
2021-06-26 08:52:52,479 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 20 msec
2021-06-26 08:52:52,520 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-26 08:52:52,521 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-26 08:52:52,528 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-26 08:52:52,528 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-26 08:52:52,540 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-26 08:52:52,840 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.versionRequest from 10.191.53.85:65080 Call#0 Retry#0
org.apache.hadoop.ipc.RetriableException: NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:1904)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.versionRequest(NameNodeRpcServer.java:1390)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.versionRequest(DatanodeProtocolServerSideTranslatorPB.java:255)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:28764)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)
2021-06-26 08:52:53,978 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-26 08:52:53,978 INFO org.apache.hadoop.fs.TrashPolicyDefault: The configured checkpoint interval is 0 minutes. Using an interval of 1 minutes that is used for deletion instead
2021-06-26 08:52:59,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-26 08:52:59,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-26 08:52:59,442 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-06-26 08:52:59,615 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-26 08:52:59,615 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-06-26 08:52:59,705 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 1, hasStaleStorage: false, processing time: 4 msecs
2021-06-26 09:46:01,252 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-26 09:46:01,252 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-26 09:46:01,252 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1438
2021-06-26 09:46:01,253 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-26 09:46:01,255 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2021-06-26 09:46:01,263 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001438 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001438-0000000000000001439
2021-06-26 09:46:01,264 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1440
2021-06-26 09:46:03,274 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 23.26 KB/s
2021-06-26 09:46:03,275 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001439 size 1573 bytes.
2021-06-26 09:46:03,332 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1437
2021-06-26 09:46:03,332 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001417, cpktTxId=0000000000000001417)
2021-06-26 09:52:51,558 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: [Lease.  Holder: DFSClient_NONMAPREDUCE_-409488197_1, pendingcreates: 1] has expired hard limit
2021-06-26 09:52:51,558 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-409488197_1, pendingcreates: 1], src=/user/pom.xml
2021-06-26 09:52:51,565 INFO BlockStateChange: BLOCK* blk_1073741986_1165{UCState=UNDER_RECOVERY, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|FINALIZED]]} recovery started, primary=ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|FINALIZED]
2021-06-26 09:52:51,566 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /user/pom.xml has not been closed. Lease recovery is in progress. RecoveryId = 1168 for block blk_1073741986_1165{UCState=UNDER_RECOVERY, truncateBlock=null, primaryNodeIndex=0, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|FINALIZED]]}
2021-06-26 09:52:51,566 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2021-06-26 09:52:53,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-1542253369-10.191.53.85-1622264819009:blk_1073741986_1165, newgenerationstamp=1168, newlength=2239, newtargets=[10.191.53.85:50010], closeFile=true, deleteBlock=false)
2021-06-26 09:52:53,809 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(oldBlock=BP-1542253369-10.191.53.85-1622264819009:blk_1073741986_1165, file=/user/pom.xml, newgenerationstamp=1168, newlength=2239, newtargets=[10.191.53.85:50010]) successful
2021-06-26 10:37:08,153 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-26 10:37:08,325 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-26 17:16:53,182 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-26 17:16:53,219 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-26 17:16:53,226 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-26 17:16:53,584 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-26 17:16:53,694 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-26 17:16:53,694 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-26 17:16:53,697 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-06-26 17:16:53,697 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-06-26 17:16:53,932 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-06-26 17:16:54,005 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-26 17:16:54,014 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-26 17:16:54,032 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-26 17:16:54,037 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-26 17:16:54,039 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-26 17:16:54,039 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-26 17:16:54,039 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-26 17:16:54,066 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-26 17:16:54,067 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-26 17:16:54,084 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-06-26 17:16:54,084 INFO org.mortbay.log: jetty-6.1.26
2021-06-26 17:16:54,458 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-06-26 17:16:59,514 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-26 17:16:59,514 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-26 17:16:59,577 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-06-26 17:16:59,577 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-06-26 17:16:59,635 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-06-26 17:16:59,635 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-26 17:16:59,636 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-26 17:16:59,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 26 17:16:59
2021-06-26 17:16:59,641 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-26 17:16:59,641 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-26 17:16:59,643 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-06-26 17:16:59,643 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-26 17:16:59,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-06-26 17:16:59,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-26 17:16:59,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-26 17:16:59,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-26 17:16:59,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-26 17:16:59,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-06-26 17:16:59,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-26 17:16:59,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-26 17:16:59,662 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-06-26 17:16:59,662 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-26 17:16:59,662 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-26 17:16:59,662 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-26 17:16:59,665 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-06-26 17:16:59,955 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-26 17:16:59,955 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-26 17:16:59,956 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-06-26 17:16:59,956 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-26 17:16:59,957 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-26 17:16:59,957 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-26 17:16:59,957 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-06-26 17:16:59,957 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-06-26 17:16:59,967 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-26 17:16:59,967 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-26 17:16:59,967 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-06-26 17:16:59,968 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-26 17:16:59,969 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-26 17:16:59,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-06-26 17:16:59,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-06-26 17:16:59,976 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-26 17:16:59,976 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-26 17:16:59,976 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-26 17:16:59,979 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-26 17:16:59,979 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-26 17:16:59,982 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-26 17:16:59,982 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-26 17:16:59,983 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-06-26 17:16:59,983 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-26 17:16:59,995 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 1920@DESKTOP-TSQQRSN
2021-06-26 17:17:00,100 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-06-26 17:17:00,192 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001440 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001440-0000000000000001443
2021-06-26 17:17:00,267 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 19 INodes.
2021-06-26 17:17:00,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-26 17:17:00,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1439 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001439
2021-06-26 17:17:00,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@71cf1b07 expecting start txid #1440
2021-06-26 17:17:00,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001440-0000000000000001443
2021-06-26 17:17:00,437 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001440-0000000000000001443' to transaction ID 1440
2021-06-26 17:17:00,449 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001440-0000000000000001443 of size 1048576 edits # 4 loaded in 0 seconds
2021-06-26 17:17:00,456 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-06-26 17:17:00,456 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-06-26 17:17:00,886 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1439
2021-06-26 17:17:00,886 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001437, cpktTxId=0000000000000001437)
2021-06-26 17:17:00,942 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1444
2021-06-26 17:17:01,097 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-26 17:17:01,097 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1111 msecs
2021-06-26 17:17:01,305 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-06-26 17:17:01,312 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-26 17:17:01,324 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-26 17:17:01,350 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-06-26 17:17:01,401 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-26 17:17:01,401 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-26 17:17:01,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-06-26 17:17:01,401 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2021-06-26 17:17:01,402 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2021-06-26 17:17:01,402 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2021-06-26 17:17:01,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-26 17:17:01,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 1
2021-06-26 17:17:01,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-26 17:17:01,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 1
2021-06-26 17:17:01,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-26 17:17:01,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-26 17:17:01,423 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 21 msec
2021-06-26 17:17:01,443 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-26 17:17:01,444 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-26 17:17:01,450 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-26 17:17:01,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-26 17:17:01,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-26 17:17:01,656 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9000, call org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.versionRequest from 10.191.53.85:51585 Call#0 Retry#0
org.apache.hadoop.ipc.RetriableException: NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:1904)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.versionRequest(NameNodeRpcServer.java:1390)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.versionRequest(DatanodeProtocolServerSideTranslatorPB.java:255)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:28764)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)
2021-06-26 17:17:01,892 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-26 17:17:01,893 INFO org.apache.hadoop.fs.TrashPolicyDefault: The configured checkpoint interval is 0 minutes. Using an interval of 1 minutes that is used for deletion instead
2021-06-26 17:17:07,356 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-26 17:17:07,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-26 17:17:07,357 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-06-26 17:17:07,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-26 17:17:07,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-06-26 17:17:07,502 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 1, hasStaleStorage: false, processing time: 2 msecs
2021-06-26 17:18:07,077 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-26 17:18:07,077 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-26 17:18:07,077 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1444
2021-06-26 17:18:07,078 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-26 17:18:07,080 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2021-06-26 17:18:07,082 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001444 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001444-0000000000000001445
2021-06-26 17:18:07,083 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1446
2021-06-26 17:18:08,614 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 55.56 KB/s
2021-06-26 17:18:08,614 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001445 size 1500 bytes.
2021-06-26 17:18:08,672 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1443
2021-06-26 17:18:08,672 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001439, cpktTxId=0000000000000001439)
2021-06-26 17:22:32,079 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-06-26 17:22:32,079 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2021-06-26 17:22:32,079 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2021-06-26 17:22:32,079 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-06-26 17:22:32,080 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-26 17:22:32,082 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-26 17:22:32,082 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-26 17:22:32,082 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-26 17:22:32,082 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-26 18:18:09,849 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-26 18:18:09,849 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-26 18:18:09,850 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1446
2021-06-26 18:18:09,850 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2021-06-26 18:18:09,854 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2021-06-26 18:18:09,856 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001446 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001446-0000000000000001447
2021-06-26 18:18:09,857 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1448
2021-06-26 18:18:10,227 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 22.73 KB/s
2021-06-26 18:18:10,228 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001447 size 1500 bytes.
2021-06-26 18:18:10,277 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1445
2021-06-26 18:18:10,277 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001443, cpktTxId=0000000000000001443)
2021-06-26 18:20:00,870 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-26 18:20:01,034 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741988_1169{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0001/job.jar
2021-06-26 18:20:01,809 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741988_1169{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0001/job.jar
2021-06-26 18:20:01,809 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-06-26 18:20:01,835 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741988_1169{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 42041257
2021-06-26 18:20:02,229 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0001/job.jar is closed by DFSClient_NONMAPREDUCE_1954729058_1
2021-06-26 18:20:02,241 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0001/job.jar
2021-06-26 18:20:02,325 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741988_1169 10.191.53.85:50010 
2021-06-26 18:20:04,858 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741988_1169]
2021-06-26 18:24:22,343 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 12 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 11 SyncTimes(ms): 20 
2021-06-26 18:24:22,430 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741989_1170{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /input/fail2ban.log._COPYING_
2021-06-26 18:24:22,794 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741989_1170{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-26 18:24:22,797 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /input/fail2ban.log._COPYING_ is closed by DFSClient_NONMAPREDUCE_1444622251_1
2021-06-26 18:24:30,668 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-26 18:24:30,669 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-06-26 18:24:30,669 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2021-06-26 18:24:30,669 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-26 18:24:30,669 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-06-26 18:24:30,669 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-26 18:24:30,669 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2021-06-26 18:24:30,669 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 1
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2021-06-26 18:24:30,670 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-26 18:24:30,671 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2021-06-26 18:24:30,671 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-26 18:24:30,671 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 1
2021-06-26 18:24:30,672 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 1
2021-06-26 18:24:30,672 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2021-06-26 18:25:17,787 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741990_1171{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job.jar
2021-06-26 18:25:18,121 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741990_1171{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-26 18:25:18,125 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job.jar is closed by DFSClient_NONMAPREDUCE_-1733834173_1
2021-06-26 18:25:18,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job.jar
2021-06-26 18:25:21,338 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job.split
2021-06-26 18:25:21,430 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741991_1172{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job.split
2021-06-26 18:25:21,483 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741991_1172{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-26 18:25:21,485 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job.split is closed by DFSClient_NONMAPREDUCE_-1733834173_1
2021-06-26 18:25:21,504 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741992_1173{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job.splitmetainfo
2021-06-26 18:25:21,535 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741992_1173{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-26 18:25:21,563 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1733834173_1
2021-06-26 18:25:22,008 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741993_1174{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job.xml
2021-06-26 18:25:22,029 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741993_1174{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-26 18:25:22,031 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job.xml is closed by DFSClient_NONMAPREDUCE_-1733834173_1
2021-06-26 18:25:27,053 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 47 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 36 SyncTimes(ms): 408 
2021-06-26 18:25:47,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741994_1175{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job_1624699033715_0002_1_conf.xml
2021-06-26 18:25:47,314 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741994_1175{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-26 18:25:47,318 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job_1624699033715_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_622841612_1
2021-06-26 18:25:55,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741995_1176{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job_1624699033715_0002_1.jhist
2021-06-26 18:25:55,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job_1624699033715_0002_1.jhist for DFSClient_NONMAPREDUCE_622841612_1
2021-06-26 18:26:05,519 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741996_1177{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /output/_temporary/1/_temporary/attempt_1624699033715_0002_r_000000_0/part-r-00000
2021-06-26 18:26:05,673 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741996_1177{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-26 18:26:05,676 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /output/_temporary/1/_temporary/attempt_1624699033715_0002_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1624699033715_0002_r_000000_0_1499355771_1
2021-06-26 18:26:05,784 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_622841612_1
2021-06-26 18:26:05,911 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_622841612_1
2021-06-26 18:26:05,929 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_622841612_1
2021-06-26 18:26:05,960 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741995_1176{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 13136
2021-06-26 18:26:05,962 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624699033715_0002/job_1624699033715_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_622841612_1
2021-06-26 18:26:05,967 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741997_1178{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624699033715_0002.summary_tmp
2021-06-26 18:26:05,978 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741997_1178{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-26 18:26:05,980 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624699033715_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_622841612_1
2021-06-26 18:26:06,020 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741998_1179{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624699033715_0002-1624703123423-root-hadoop%2Dmapreduce%2Dcode%2D1.0%2DSNAPSHOT%2Djar%2Dwith%2Ddepend-1624703165930-1-1-SUCCEEDED-default-1624703146992.jhist_tmp
2021-06-26 18:26:06,032 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741998_1179{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-26 18:26:06,033 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624699033715_0002-1624703123423-root-hadoop%2Dmapreduce%2Dcode%2D1.0%2DSNAPSHOT%2Djar%2Dwith%2Ddepend-1624703165930-1-1-SUCCEEDED-default-1624703146992.jhist_tmp is closed by DFSClient_NONMAPREDUCE_622841612_1
2021-06-26 18:26:06,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741999_1180{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624699033715_0002_conf.xml_tmp
2021-06-26 18:26:06,056 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073741999_1180{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-26 18:26:06,057 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624699033715_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_622841612_1
2021-06-26 18:26:07,104 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741990_1171 10.191.53.85:50010 
2021-06-26 18:26:07,104 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741991_1172 10.191.53.85:50010 
2021-06-26 18:26:07,104 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741992_1173 10.191.53.85:50010 
2021-06-26 18:26:07,104 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741993_1174 10.191.53.85:50010 
2021-06-26 18:26:07,104 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741995_1176 10.191.53.85:50010 
2021-06-26 18:26:07,104 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741994_1175 10.191.53.85:50010 
2021-06-26 18:26:08,789 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741990_1171, blk_1073741991_1172, blk_1073741992_1173, blk_1073741993_1174, blk_1073741994_1175, blk_1073741995_1176]
2021-06-26 18:26:12,990 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742000_1181{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/logs/root/logs/application_1624699033715_0002/DESKTOP-TSQQRSN_50176.tmp
2021-06-26 18:26:13,125 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742000_1181{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-26 18:26:13,128 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/logs/root/logs/application_1624699033715_0002/DESKTOP-TSQQRSN_50176.tmp is closed by DFSClient_NONMAPREDUCE_-2110363590_105
2021-06-26 18:26:30,001 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 107 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 0 Number of syncs: 78 SyncTimes(ms): 707 
2021-06-26 18:26:30,010 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741997_1178 10.191.53.85:50010 
2021-06-26 18:26:32,848 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073741997_1178]
2021-06-26 19:18:12,000 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-26 19:18:12,000 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-26 19:18:12,000 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1448
2021-06-26 19:18:12,000 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 113 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 82 SyncTimes(ms): 2627 
2021-06-26 19:18:12,003 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 113 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 83 SyncTimes(ms): 2629 
2021-06-26 19:18:12,004 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001448 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001448-0000000000000001560
2021-06-26 19:18:12,005 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1561
2021-06-26 19:18:12,547 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 74.07 KB/s
2021-06-26 19:18:12,547 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001560 size 2511 bytes.
2021-06-26 19:18:12,609 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1447
2021-06-26 19:18:12,609 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001445, cpktTxId=0000000000000001445)
2021-06-26 20:18:14,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-26 20:18:14,201 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-26 20:18:14,201 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1561
2021-06-26 20:18:14,201 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 
2021-06-26 20:18:14,203 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 6 
2021-06-26 20:18:14,204 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001561 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001561-0000000000000001562
2021-06-26 20:18:14,206 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1563
2021-06-26 20:18:14,559 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 83.33 KB/s
2021-06-26 20:18:14,559 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001562 size 2511 bytes.
2021-06-26 20:18:14,620 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1560
2021-06-26 20:18:14,620 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001447, cpktTxId=0000000000000001447)
2021-06-26 20:27:02,268 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-26 20:27:02,451 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
2021-06-27 13:13:52,641 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = DESKTOP-TSQQRSN/10.191.53.85
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /opt/hadoop-2.7.2/etc/hadoop:/opt/hadoop-2.7.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/common/hadoop-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/opt/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_144
************************************************************/
2021-06-27 13:13:52,732 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-06-27 13:13:52,737 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2021-06-27 13:13:53,357 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-06-27 13:13:53,926 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-06-27 13:13:53,927 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2021-06-27 13:13:53,930 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://DESKTOP-TSQQRSN:9000
2021-06-27 13:13:53,930 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use DESKTOP-TSQQRSN:9000 to access this namenode/service.
2021-06-27 13:13:54,283 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2021-06-27 13:13:54,425 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-06-27 13:13:54,434 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-06-27 13:13:54,465 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2021-06-27 13:13:54,470 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-06-27 13:13:54,472 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2021-06-27 13:13:54,473 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-06-27 13:13:54,473 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-06-27 13:13:54,564 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2021-06-27 13:13:54,565 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2021-06-27 13:13:54,651 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2021-06-27 13:13:54,652 INFO org.mortbay.log: jetty-6.1.26
2021-06-27 13:13:55,224 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2021-06-27 13:13:55,308 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-27 13:13:55,308 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2021-06-27 13:13:55,380 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2021-06-27 13:13:55,380 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2021-06-27 13:13:55,523 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2021-06-27 13:13:55,523 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2021-06-27 13:13:55,524 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2021-06-27 13:13:55,526 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2021 Jun 27 13:13:55
2021-06-27 13:13:55,529 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2021-06-27 13:13:55,530 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-27 13:13:55,532 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2021-06-27 13:13:55,532 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2021-06-27 13:13:55,540 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2021-06-27 13:13:55,540 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2021-06-27 13:13:55,540 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2021-06-27 13:13:55,540 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2021-06-27 13:13:55,540 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2021-06-27 13:13:55,540 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2021-06-27 13:13:55,540 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2021-06-27 13:13:55,541 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2021-06-27 13:13:55,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2021-06-27 13:13:55,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2021-06-27 13:13:55,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2021-06-27 13:13:55,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2021-06-27 13:13:55,552 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2021-06-27 13:13:56,170 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2021-06-27 13:13:56,170 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-27 13:13:56,170 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2021-06-27 13:13:56,170 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2021-06-27 13:13:56,171 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2021-06-27 13:13:56,171 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2021-06-27 13:13:56,171 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2021-06-27 13:13:56,171 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2021-06-27 13:13:56,181 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2021-06-27 13:13:56,181 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-27 13:13:56,181 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2021-06-27 13:13:56,181 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2021-06-27 13:13:56,182 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2021-06-27 13:13:56,182 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2021-06-27 13:13:56,182 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2021-06-27 13:13:56,187 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2021-06-27 13:13:56,187 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2021-06-27 13:13:56,187 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2021-06-27 13:13:56,189 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2021-06-27 13:13:56,189 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2021-06-27 13:13:56,232 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2021-06-27 13:13:56,233 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2021-06-27 13:13:56,233 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2021-06-27 13:13:56,233 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2021-06-27 13:13:56,297 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop-2.7.2/data/tmp/dfs/name/in_use.lock acquired by nodename 204@DESKTOP-TSQQRSN
2021-06-27 13:13:56,465 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop-2.7.2/data/tmp/dfs/name/current
2021-06-27 13:13:56,538 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001563 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001563-0000000000000001563
2021-06-27 13:13:56,639 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 31 INodes.
2021-06-27 13:13:56,846 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2021-06-27 13:13:56,846 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1562 from /opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001562
2021-06-27 13:13:56,846 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2807bdeb expecting start txid #1563
2021-06-27 13:13:56,846 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001563-0000000000000001563
2021-06-27 13:13:56,849 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001563-0000000000000001563' to transaction ID 1563
2021-06-27 13:13:56,853 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001563-0000000000000001563 of size 1048576 edits # 1 loaded in 0 seconds
2021-06-27 13:13:56,863 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? true (staleImage=true, haEnabled=false, isRollingUpgrade=false)
2021-06-27 13:13:56,863 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Save namespace ...
2021-06-27 13:13:57,022 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1562
2021-06-27 13:13:57,022 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001560, cpktTxId=0000000000000001560)
2021-06-27 13:13:57,058 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1564
2021-06-27 13:13:57,224 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2021-06-27 13:13:57,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 987 msecs
2021-06-27 13:13:57,672 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to DESKTOP-TSQQRSN:9000
2021-06-27 13:13:57,687 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-06-27 13:13:57,706 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2021-06-27 13:13:57,781 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2021-06-27 13:13:57,848 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-27 13:13:57,849 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2021-06-27 13:13:57,849 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 6 blocks to reach the threshold 0.9990 of total blocks 6.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2021-06-27 13:13:57,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-27 13:13:58,242 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-06-27 13:13:58,242 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2021-06-27 13:13:58,246 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: DESKTOP-TSQQRSN/10.191.53.85:9000
2021-06-27 13:13:58,247 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2021-06-27 13:13:58,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2021-06-27 13:13:59,217 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-27 13:13:59,221 INFO org.apache.hadoop.fs.TrashPolicyDefault: The configured checkpoint interval is 0 minutes. Using an interval of 1 minutes that is used for deletion instead
2021-06-27 13:14:01,300 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0) storage 5f668bc6-8b0c-4ca6-8124-5cf5f977ec52
2021-06-27 13:14:01,300 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-27 13:14:01,301 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.191.53.85:50010
2021-06-27 13:14:01,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2021-06-27 13:14:01,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-77177884-7e39-4105-ae4c-bdc787c546af for DN 10.191.53.85:50010
2021-06-27 13:14:01,505 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 6. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2021-06-27 13:14:01,505 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2021-06-27 13:14:01,507 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 6, hasStaleStorage: false, processing time: 18 msecs
2021-06-27 13:14:01,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 6
2021-06-27 13:14:01,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2021-06-27 13:14:01,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 1
2021-06-27 13:14:01,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2021-06-27 13:14:01,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2021-06-27 13:14:01,508 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3 msec
2021-06-27 13:14:21,593 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 6 has reached the threshold 0.9990 of total blocks 6. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2021-06-27 13:14:31,663 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 36 secs
2021-06-27 13:14:31,663 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2021-06-27 13:14:31,663 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2021-06-27 13:14:31,663 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 1 blocks
2021-06-27 14:14:07,869 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-27 14:14:07,869 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-27 14:14:07,870 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1564
2021-06-27 14:14:07,871 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-27 14:14:07,873 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2021-06-27 14:14:07,881 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001564 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001564-0000000000000001565
2021-06-27 14:14:07,883 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1566
2021-06-27 14:14:09,582 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 74.07 KB/s
2021-06-27 14:14:09,582 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001565 size 2511 bytes.
2021-06-27 14:14:09,643 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1563
2021-06-27 14:14:09,643 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001562, cpktTxId=0000000000000001562)
2021-06-27 15:14:10,663 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-27 15:14:10,664 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-27 15:14:10,664 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1566
2021-06-27 15:14:10,664 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2021-06-27 15:14:10,667 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 9 
2021-06-27 15:14:10,667 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001566 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001566-0000000000000001567
2021-06-27 15:14:10,669 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1568
2021-06-27 15:14:11,010 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 52.63 KB/s
2021-06-27 15:14:11,010 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001567 size 2511 bytes.
2021-06-27 15:14:11,070 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1565
2021-06-27 15:14:11,070 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001563, cpktTxId=0000000000000001563)
2021-06-27 16:14:12,179 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.191.53.85
2021-06-27 16:14:12,179 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2021-06-27 16:14:12,179 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1568
2021-06-27 16:14:12,180 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2021-06-27 16:14:12,392 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 219 
2021-06-27 16:14:12,394 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_inprogress_0000000000000001568 -> /opt/hadoop-2.7.2/data/tmp/dfs/name/current/edits_0000000000000001568-0000000000000001569
2021-06-27 16:14:12,396 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1570
2021-06-27 16:14:12,653 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 100.00 KB/s
2021-06-27 16:14:12,653 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001569 size 2511 bytes.
2021-06-27 16:14:12,712 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1567
2021-06-27 16:14:12,712 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop-2.7.2/data/tmp/dfs/name/current/fsimage_0000000000000001565, cpktTxId=0000000000000001565)
2021-06-27 16:17:53,711 INFO BlockStateChange: BLOCK* processReport: from storage DS-77177884-7e39-4105-ae4c-bdc787c546af node DatanodeRegistration(10.191.53.85:50010, datanodeUuid=5f668bc6-8b0c-4ca6-8124-5cf5f977ec52, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-f52f4b91-6613-4b07-a646-fa592e48f0b7;nsid=2005162102;c=0), blocks: 6, hasStaleStorage: false, processing time: 23 msecs
2021-06-27 16:28:27,969 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-06-27 16:28:27,969 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2021-06-27 16:28:27,969 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2021-06-27 16:28:27,969 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-06-27 16:28:27,975 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-27 16:28:27,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-27 16:28:27,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2021-06-27 16:28:27,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2021-06-27 16:28:27,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2021-06-27 16:29:08,244 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 23 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2021-06-27 16:29:08,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742001_1182{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /input1/nums.txt._COPYING_
2021-06-27 16:29:08,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742001_1182{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /input1/nums.txt._COPYING_
2021-06-27 16:29:08,646 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2021-06-27 16:29:08,666 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742001_1182{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 476
2021-06-27 16:29:09,062 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /input1/nums.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1626260172_1
2021-06-27 16:31:24,487 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 9 Total time for transactions(ms): 27 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 11 
2021-06-27 16:31:24,680 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742002_1183{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job.jar
2021-06-27 16:31:27,812 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742002_1183{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:31:27,849 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job.jar is closed by DFSClient_NONMAPREDUCE_1809074416_1
2021-06-27 16:31:27,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job.jar
2021-06-27 16:31:28,838 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job.split
2021-06-27 16:31:28,869 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742003_1184{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job.split
2021-06-27 16:31:29,033 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742003_1184{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:31:29,035 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job.split is closed by DFSClient_NONMAPREDUCE_1809074416_1
2021-06-27 16:31:29,043 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742004_1185{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job.splitmetainfo
2021-06-27 16:31:29,054 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742004_1185{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:31:29,060 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1809074416_1
2021-06-27 16:31:31,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742005_1186{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job.xml
2021-06-27 16:31:32,046 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742005_1186{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:31:32,099 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job.xml is closed by DFSClient_NONMAPREDUCE_1809074416_1
2021-06-27 16:32:09,998 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742006_1187{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job_1624770853360_0001_1_conf.xml
2021-06-27 16:32:10,176 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742006_1187{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:32:10,180 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job_1624770853360_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_250030457_1
2021-06-27 16:32:16,427 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742007_1188{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job_1624770853360_0001_1.jhist
2021-06-27 16:32:16,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job_1624770853360_0001_1.jhist for DFSClient_NONMAPREDUCE_250030457_1
2021-06-27 16:32:22,471 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742008_1189{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /output1/_temporary/1/_temporary/attempt_1624770853360_0001_r_000000_0/part-r-00000
2021-06-27 16:32:22,643 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742008_1189{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:32:22,648 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /output1/_temporary/1/_temporary/attempt_1624770853360_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1624770853360_0001_r_000000_0_343884960_1
2021-06-27 16:32:22,739 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_250030457_1
2021-06-27 16:32:22,795 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /output1/_SUCCESS is closed by DFSClient_NONMAPREDUCE_250030457_1
2021-06-27 16:32:22,802 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_250030457_1
2021-06-27 16:32:22,823 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742007_1188{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 13091
2021-06-27 16:32:22,825 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0001/job_1624770853360_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_250030457_1
2021-06-27 16:32:22,833 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742009_1190{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624770853360_0001.summary_tmp
2021-06-27 16:32:22,845 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742009_1190{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:32:22,847 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624770853360_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_250030457_1
2021-06-27 16:32:22,898 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742010_1191{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624770853360_0001-1624782694713-root-hadoop%2Dmapreduce%2Dcode%2D1.0%2DSNAPSHOT%2Djar%2Dwith%2Ddepend-1624782742804-1-1-SUCCEEDED-default-1624782729671.jhist_tmp
2021-06-27 16:32:22,909 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742010_1191{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:32:22,910 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624770853360_0001-1624782694713-root-hadoop%2Dmapreduce%2Dcode%2D1.0%2DSNAPSHOT%2Djar%2Dwith%2Ddepend-1624782742804-1-1-SUCCEEDED-default-1624782729671.jhist_tmp is closed by DFSClient_NONMAPREDUCE_250030457_1
2021-06-27 16:32:22,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742011_1192{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624770853360_0001_conf.xml_tmp
2021-06-27 16:32:22,932 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742011_1192{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:32:22,934 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624770853360_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_250030457_1
2021-06-27 16:32:24,159 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742002_1183 10.191.53.85:50010 
2021-06-27 16:32:24,160 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742003_1184 10.191.53.85:50010 
2021-06-27 16:32:24,160 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742004_1185 10.191.53.85:50010 
2021-06-27 16:32:24,160 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742005_1186 10.191.53.85:50010 
2021-06-27 16:32:24,160 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742007_1188 10.191.53.85:50010 
2021-06-27 16:32:24,160 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742006_1187 10.191.53.85:50010 
2021-06-27 16:32:25,381 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073742002_1183, blk_1073742003_1184, blk_1073742004_1185, blk_1073742005_1186, blk_1073742006_1187, blk_1073742007_1188]
2021-06-27 16:32:29,701 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 91 Total time for transactions(ms): 34 Number of transactions batched in Syncs: 0 Number of syncs: 66 SyncTimes(ms): 425 
2021-06-27 16:32:29,702 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742009_1190 10.191.53.85:50010 
2021-06-27 16:32:29,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742012_1193{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/logs/root/logs/application_1624770853360_0001/DESKTOP-TSQQRSN_61350.tmp
2021-06-27 16:32:30,057 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742012_1193{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:32:30,058 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/logs/root/logs/application_1624770853360_0001/DESKTOP-TSQQRSN_61350.tmp is closed by DFSClient_NONMAPREDUCE_-1864795007_107
2021-06-27 16:32:31,401 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073742009_1190]
2021-06-27 16:36:37,554 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 104 Total time for transactions(ms): 37 Number of transactions batched in Syncs: 0 Number of syncs: 74 SyncTimes(ms): 429 
2021-06-27 16:37:00,026 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-27 16:37:00,037 INFO org.apache.hadoop.fs.TrashPolicyDefault: Created trash checkpoint: /user/root/.Trash/210627163700
2021-06-27 16:38:00,030 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-27 16:38:00,038 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 107 Total time for transactions(ms): 37 Number of transactions batched in Syncs: 0 Number of syncs: 77 SyncTimes(ms): 431 
2021-06-27 16:38:00,039 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742008_1189 10.191.53.85:50010 
2021-06-27 16:38:00,040 INFO org.apache.hadoop.fs.TrashPolicyDefault: Deleted trash checkpoint: /user/root/.Trash/210627163700
2021-06-27 16:38:01,861 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073742008_1189]
2021-06-27 16:38:12,681 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742013_1194{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job.jar
2021-06-27 16:38:13,687 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742013_1194{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job.jar
2021-06-27 16:38:13,688 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742013_1194{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 42044318
2021-06-27 16:38:14,123 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job.jar is closed by DFSClient_NONMAPREDUCE_-1122264192_1
2021-06-27 16:38:14,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job.jar
2021-06-27 16:38:14,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job.split
2021-06-27 16:38:14,330 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742014_1195{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job.split
2021-06-27 16:38:14,342 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742014_1195{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:38:14,344 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job.split is closed by DFSClient_NONMAPREDUCE_-1122264192_1
2021-06-27 16:38:14,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742015_1196{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job.splitmetainfo
2021-06-27 16:38:14,364 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742015_1196{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:38:14,366 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1122264192_1
2021-06-27 16:38:14,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742016_1197{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job.xml
2021-06-27 16:38:14,902 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742016_1197{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:38:14,904 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job.xml is closed by DFSClient_NONMAPREDUCE_-1122264192_1
2021-06-27 16:38:33,916 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742017_1198{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job_1624770853360_0002_1_conf.xml
2021-06-27 16:38:34,087 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742017_1198{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:38:34,091 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job_1624770853360_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1882075384_1
2021-06-27 16:38:39,767 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742018_1199{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job_1624770853360_0002_1.jhist
2021-06-27 16:38:40,281 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job_1624770853360_0002_1.jhist for DFSClient_NONMAPREDUCE_-1882075384_1
2021-06-27 16:38:56,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742019_1200{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /output1/_temporary/1/_temporary/attempt_1624770853360_0002_r_000000_0/part-r-00000
2021-06-27 16:38:56,807 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742019_1200{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:38:56,812 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /output1/_temporary/1/_temporary/attempt_1624770853360_0002_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1624770853360_0002_r_000000_0_-832361867_1
2021-06-27 16:38:56,939 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1882075384_1
2021-06-27 16:38:56,974 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /output1/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1882075384_1
2021-06-27 16:38:57,324 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1882075384_1
2021-06-27 16:38:57,381 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742018_1199{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 13096
2021-06-27 16:38:57,397 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/root/.staging/job_1624770853360_0002/job_1624770853360_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_-1882075384_1
2021-06-27 16:38:57,404 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742020_1201{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624770853360_0002.summary_tmp
2021-06-27 16:38:57,416 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742020_1201{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:38:57,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624770853360_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1882075384_1
2021-06-27 16:38:57,521 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742021_1202{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624770853360_0002-1624783095164-root-hadoop%2Dmapreduce%2Dcode%2D1.0%2DSNAPSHOT%2Djar%2Dwith%2Ddepend-1624783137327-1-1-SUCCEEDED-default-1624783112010.jhist_tmp
2021-06-27 16:38:57,531 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742021_1202{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:38:58,171 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624770853360_0002-1624783095164-root-hadoop%2Dmapreduce%2Dcode%2D1.0%2DSNAPSHOT%2Djar%2Dwith%2Ddepend-1624783137327-1-1-SUCCEEDED-default-1624783112010.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1882075384_1
2021-06-27 16:38:58,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742022_1203{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624770853360_0002_conf.xml_tmp
2021-06-27 16:38:58,586 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742022_1203{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:38:58,593 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/root/job_1624770853360_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1882075384_1
2021-06-27 16:38:59,640 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742013_1194 10.191.53.85:50010 
2021-06-27 16:38:59,641 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742014_1195 10.191.53.85:50010 
2021-06-27 16:38:59,641 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742015_1196 10.191.53.85:50010 
2021-06-27 16:38:59,641 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742016_1197 10.191.53.85:50010 
2021-06-27 16:38:59,641 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742018_1199 10.191.53.85:50010 
2021-06-27 16:38:59,641 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742017_1198 10.191.53.85:50010 
2021-06-27 16:39:00,031 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-27 16:39:01,951 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073742016_1197, blk_1073742017_1198, blk_1073742018_1199, blk_1073742013_1194, blk_1073742014_1195, blk_1073742015_1196]
2021-06-27 16:39:06,074 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 190 Total time for transactions(ms): 38 Number of transactions batched in Syncs: 1 Number of syncs: 136 SyncTimes(ms): 4327 
2021-06-27 16:39:06,095 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742023_1204{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} for /tmp/logs/root/logs/application_1624770853360_0002/DESKTOP-TSQQRSN_61350.tmp
2021-06-27 16:39:06,109 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.191.53.85:50010 is added to blk_1073742023_1204{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-77177884-7e39-4105-ae4c-bdc787c546af:NORMAL:10.191.53.85:50010|RBW]]} size 0
2021-06-27 16:39:06,111 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/logs/root/logs/application_1624770853360_0002/DESKTOP-TSQQRSN_61350.tmp is closed by DFSClient_NONMAPREDUCE_-1184093088_163
2021-06-27 16:40:00,022 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-27 16:41:00,018 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-27 16:41:29,302 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 196 Total time for transactions(ms): 38 Number of transactions batched in Syncs: 1 Number of syncs: 140 SyncTimes(ms): 4330 
2021-06-27 16:41:29,304 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742020_1201 10.191.53.85:50010 
2021-06-27 16:41:32,120 INFO BlockStateChange: BLOCK* BlockManager: ask 10.191.53.85:50010 to delete [blk_1073742020_1201]
2021-06-27 16:42:00,030 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-27 16:43:00,025 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-27 16:44:00,023 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-27 16:45:00,020 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-27 16:46:00,020 INFO org.apache.hadoop.fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 1 minutes, Emptier interval = 0 minutes.
2021-06-27 16:46:11,899 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2021-06-27 16:46:11,913 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at DESKTOP-TSQQRSN/10.191.53.85
************************************************************/
